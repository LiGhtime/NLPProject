{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# import json\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import transformers\n",
    "from transformers import RobertaModel, RobertaTokenizer, RobertaForMultipleChoice\n",
    "from torch import cuda\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asks-for</th>\n",
       "      <th>most-plausible-alternative</th>\n",
       "      <th>p</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>My body cast a shadow over the grass.</td>\n",
       "      <td>The sun was rising.</td>\n",
       "      <td>The grass was cut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>The woman tolerated her friend's difficult beh...</td>\n",
       "      <td>The woman knew her friend was going through a ...</td>\n",
       "      <td>The woman felt that her friend took advantage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The women met for coffee.</td>\n",
       "      <td>The cafe reopened in a new location.</td>\n",
       "      <td>They wanted to catch up with each other.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>The runner wore shorts.</td>\n",
       "      <td>The forecast predicted high temperatures.</td>\n",
       "      <td>She planned to run along the beach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>The guests of the party hid behind the couch.</td>\n",
       "      <td>It was a surprise party.</td>\n",
       "      <td>It was a birthday party.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The politician lost the election.</td>\n",
       "      <td>He ran negative campaign ads.</td>\n",
       "      <td>No one voted for him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The stain came out of the shirt.</td>\n",
       "      <td>I patched the shirt.</td>\n",
       "      <td>I bleached the shirt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The man got a discount on his groceries.</td>\n",
       "      <td>He greeted the cashier.</td>\n",
       "      <td>He used a coupon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>effect</td>\n",
       "      <td>1</td>\n",
       "      <td>The physician misdiagnosed the patient.</td>\n",
       "      <td>The patient filed a malpractice lawsuit agains...</td>\n",
       "      <td>The patient disclosed confidential information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The customer filed a complaint with the store ...</td>\n",
       "      <td>The sales associate undercharged the customer.</td>\n",
       "      <td>The sales associate acted rude to the customer.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id asks-for  most-plausible-alternative  \\\n",
       "0   1    cause                           1   \n",
       "1   2    cause                           1   \n",
       "2   3    cause                           2   \n",
       "3   4    cause                           1   \n",
       "4   5    cause                           1   \n",
       "5   6    cause                           2   \n",
       "6   7    cause                           2   \n",
       "7   8    cause                           2   \n",
       "8   9   effect                           1   \n",
       "9  10    cause                           2   \n",
       "\n",
       "                                                   p  \\\n",
       "0              My body cast a shadow over the grass.   \n",
       "1  The woman tolerated her friend's difficult beh...   \n",
       "2                          The women met for coffee.   \n",
       "3                            The runner wore shorts.   \n",
       "4      The guests of the party hid behind the couch.   \n",
       "5                  The politician lost the election.   \n",
       "6                   The stain came out of the shirt.   \n",
       "7           The man got a discount on his groceries.   \n",
       "8            The physician misdiagnosed the patient.   \n",
       "9  The customer filed a complaint with the store ...   \n",
       "\n",
       "                                                  a1  \\\n",
       "0                                The sun was rising.   \n",
       "1  The woman knew her friend was going through a ...   \n",
       "2               The cafe reopened in a new location.   \n",
       "3          The forecast predicted high temperatures.   \n",
       "4                           It was a surprise party.   \n",
       "5                      He ran negative campaign ads.   \n",
       "6                               I patched the shirt.   \n",
       "7                            He greeted the cashier.   \n",
       "8  The patient filed a malpractice lawsuit agains...   \n",
       "9     The sales associate undercharged the customer.   \n",
       "\n",
       "                                                  a2  \n",
       "0                                 The grass was cut.  \n",
       "1  The woman felt that her friend took advantage ...  \n",
       "2           They wanted to catch up with each other.  \n",
       "3                She planned to run along the beach.  \n",
       "4                           It was a birthday party.  \n",
       "5                              No one voted for him.  \n",
       "6                              I bleached the shirt.  \n",
       "7                                  He used a coupon.  \n",
       "8  The patient disclosed confidential information...  \n",
       "9    The sales associate acted rude to the customer.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "test_raw_data = pd.read_xml('data/COPA-resources/datasets/copa-test.xml')\n",
    "dev_raw_data = pd.read_xml('data/COPA-resources/datasets/copa-dev.xml') # train-test-split 400-100\n",
    "dev_raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sequence is:  {cause}The frozen food thawed.\n",
      "{'input_ids': [0, 45152, 27037, 24303, 133, 9214, 689, 3553, 32211, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['{', 'cause', '}', 'The', 'Ġfrozen', 'Ġfood', 'Ġth', 'awed', '.']\n",
      "test_sequence is:  {effect}I emptied my pockets.\n",
      "{'input_ids': [0, 45152, 26715, 24303, 100, 35371, 127, 12189, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['{', 'effect', '}', 'I', 'Ġemptied', 'Ġmy', 'Ġpockets', '.']\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# test_sequence = \"{\" + \"effect\" + \"}\" + \"I ran the ice cube under warm water.\"\n",
    "test_sequence = \"{\"+ test_raw_data.iloc[28]['asks-for'] + \"}\" + test_raw_data.iloc[28]['p']\n",
    "print(\"test_sequence is: \", test_sequence)\n",
    "print(tokenizer(test_sequence))\n",
    "print(tokenizer.tokenize(test_sequence))\n",
    "# test 2\n",
    "test_sequence = \"{\"+ test_raw_data.iloc[1]['asks-for'] + \"}\" + test_raw_data.iloc[1]['p']\n",
    "print(\"test_sequence is: \", test_sequence)\n",
    "print(tokenizer(test_sequence))\n",
    "print(tokenizer.tokenize(test_sequence))\n",
    "\n",
    "print(test_raw_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(rawdata):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    \n",
    "    # for i in range(0, rawdata.shape[0]):\n",
    "    for i in range(2, 5):\n",
    "        prompt = rawdata.iloc[i]['asks-for'] + \".\" + rawdata.iloc[i]['p']\n",
    "        choice0 = rawdata.iloc[i]['a1']\n",
    "        choice1 = rawdata.iloc[i]['a2']\n",
    "        label = torch.tensor(rawdata.iloc[i]['most-plausible-alternative'] - 1)\n",
    "        # label = torch.tensor(rawdata.iloc[i]['label']).unsqueeze(0).to(device)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True)\n",
    "        print(\"encoding['input_ids']: \", encoding['input_ids'])\n",
    "        print(\"encoding['input_ids'] with size of : \", encoding['input_ids'].size())\n",
    "        print(\"encoding['attention_mask']: \", encoding['attention_mask'])\n",
    "        print(\"label: \", label)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(dev_raw_data.shape[0])\n",
    "print(test_raw_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding['input_ids']:  tensor([[    0, 27037,     4,   133,   390,  1145,    13,  3895,     4,     2,\n",
      "             2,   133, 16381, 14015,    11,    10,    92,  2259,     4,     2,\n",
      "             1],\n",
      "        [    0, 27037,     4,   133,   390,  1145,    13,  3895,     4,     2,\n",
      "             2,  1213,   770,     7,  2916,    62,    19,   349,    97,     4,\n",
      "             2]])\n",
      "encoding['input_ids'] with size of :  torch.Size([2, 21])\n",
      "encoding['attention_mask']:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "label:  tensor(1)\n",
      "encoding['input_ids']:  tensor([[    0, 27037,     4,   133,  7449,  5328, 13344,     4,     2,     2,\n",
      "           133,  1914,  6126,   239,  3971,     4,     2,     1,     1],\n",
      "        [    0, 27037,     4,   133,  7449,  5328, 13344,     4,     2,     2,\n",
      "          2515,  1904,     7,   422,   552,     5,  4105,     4,     2]])\n",
      "encoding['input_ids'] with size of :  torch.Size([2, 19])\n",
      "encoding['attention_mask']:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "label:  tensor(0)\n",
      "encoding['input_ids']:  tensor([[    0, 27037,     4,   133,  3958,     9,     5,   537, 20119,   639,\n",
      "             5, 16433,     4,     2,     2,   243,    21,    10,  2755,   537,\n",
      "             4,     2],\n",
      "        [    0, 27037,     4,   133,  3958,     9,     5,   537, 20119,   639,\n",
      "             5, 16433,     4,     2,     2,   243,    21,    10,  4115,   537,\n",
      "             4,     2]])\n",
      "encoding['input_ids'] with size of :  torch.Size([2, 22])\n",
      "encoding['attention_mask']:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "label:  tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# tokenize data tests\n",
    "dev_data = load_data(dev_raw_data)\n",
    "# print(f'Training data loaded (length {len(train_data)})')\n",
    "# dev_data = load_data('data/dev.jsonl')\n",
    "# print(f'Dev data loaded (length {len(dev_data)})')\n",
    "# test_data = load_data('data/test.jsonl')\n",
    "# print(f'Test data loaded (length {len(test_data)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_3, use only the very last hidden layer from Roberta.\n",
    "from torch import nn\n",
    "from transformers import RobertaConfig, RobertaModel\n",
    "\n",
    "class OurRobertaCOPA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OurRobertaCOPA, self).__init__()\n",
    "        # self.configuration = RobertaConfig()\n",
    "        # self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "        # self.l1 = RobertaModel(self.configuration)\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.l1.requires_grad = True\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 512)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        # self.classifier = torch.nn.Linear(768, 5)\n",
    "        # hidden_dim=32 for later trials.\n",
    "        # self.lstm = nn.LSTM(768, 32, 1, bias=False)\n",
    "        self.output_layer = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, sequence_1, sequence_2):\n",
    "        # Two input here\n",
    "        token_1 = tokenizer(sequence_1)\n",
    "        token_2 = tokenizer(sequence_2)\n",
    "        output_1 = self.l1(input_ids=torch.tensor(token_1[\"input_ids\"]).unsqueeze(0), attention_mask=torch.tensor(token_1[\"attention_mask\"]).unsqueeze(0))[0]\n",
    "        output_2 = self.l1(input_ids=torch.tensor(token_2[\"input_ids\"]).unsqueeze(0), attention_mask=torch.tensor(token_2[\"attention_mask\"]).unsqueeze(0))[0]\n",
    "        # RobertaModel(RobertaConfig())\n",
    "\n",
    "        # _, (hidden_rep_1, _) = self.lstm(output_1.unsqueeze(0))\n",
    "        # _, (hidden_rep_2, _) = self.lstm(output_2.unsqueeze(0))\n",
    "        # _, (hidden_rep_1, _) = self.lstm(output_1)\n",
    "        # _, (hidden_rep_2, _) = self.lstm(output_2)\n",
    "\n",
    "        hidden_rep_1 = torch.nn.ReLU()(self.pre_classifier(output_1[0])).squeeze(0)\n",
    "        hidden_rep_2 = torch.nn.ReLU()(self.pre_classifier(output_2[0])).squeeze(0)\n",
    "        pooler_1 = hidden_rep_1[:, 0]\n",
    "        pooler_2 = hidden_rep_2[:, 0]\n",
    "        # hidden_rep_1 = self.pre_classifier(output_1[0]).squeeze(0)\n",
    "        # hidden_rep_2 = self.pre_classifier(output_2[0]).squeeze(0)\n",
    "        # print(\"-------hidden_rep_1:\")\n",
    "        # print(hidden_rep_1)\n",
    "        # print(hidden_rep_1.size())\n",
    "        # print(\"-------hidden_rep_2:\")\n",
    "        # print(hidden_rep_2)\n",
    "        # print(hidden_rep_2.size())\n",
    "        \n",
    "        # hidden_rep = torch.cat((hidden_rep_1.unsqueeze(1), hidden_rep_2.unsqueeze(1)), 1)\n",
    "        # hidden_rep = self.dropout(torch.cat((hidden_rep_1, hidden_rep_2), 0))\n",
    "        hidden_rep = self.dropout(torch.cat((pooler_1, pooler_2), 0))\n",
    "\n",
    "        print(\"-------hidden_rep:\")\n",
    "        # print(hidden_rep)\n",
    "        print(hidden_rep.size())\n",
    "\n",
    "        output = self.output_layer(hidden_rep.unsqueeze(0))\n",
    "        print(\"-------output:\")\n",
    "        # print(output)\n",
    "        print(output.size())\n",
    "        print(\"--------------\")\n",
    "\n",
    "        output_squezzed = output.squeeze(0).squeeze(0)\n",
    "        print(\"-------output_squezzed:\")\n",
    "        print(output_squezzed)\n",
    "        print(output_squezzed.size())\n",
    "        print(\"--------------\")\n",
    "        \n",
    "        # y_hat = softmax(output_squezzed)\n",
    "        # y_sum =  torch.sum(y_hat, 0)\n",
    "        # col1= torch.sum(y_hat, 0)[0]\n",
    "        # col2 = torch.sum(y_hat, 0)[1]\n",
    "        # y_result = torch.tensor(torch.argmax(y_sum)).type(torch.FloatTensor)\n",
    "        # y_result = torch.tensor(y_sum)\n",
    "        \n",
    "        return output_squezzed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForMultipleChoice(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# model = OurRobertaCOPA()\n",
    "model = RobertaForMultipleChoice.from_pretrained('roberta-base')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Epoch: 1--------------\n",
      "Training for epoch 1.......\n",
      "train_loss:  tensor(1.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2321, -6.6679]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(2.1292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.3377, -5.3351]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.093465805053711\n",
      ".......Validating for epoch 1\n",
      "dev_loss:  tensor(0.2771, device='cuda:0')\n",
      "dev_logits:  tensor([[-4.4653, -3.3236]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_loss:  tensor(0.9445, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.1815, -5.6335]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  54.0\n",
      "--------------Epoch: 2--------------\n",
      "Training for epoch 2.......\n",
      "train_loss:  tensor(0.7258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-4.7509, -4.6866]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-4.9796, -7.7781]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.1721071004867554\n",
      ".......Validating for epoch 2\n",
      "dev_loss:  tensor(2.0170, device='cuda:0')\n",
      "dev_logits:  tensor([[-4.6715, -6.5457]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(0.0664, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.1951, -3.5165]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 3--------------\n",
      "Training for epoch 3.......\n",
      "train_loss:  tensor(2.6867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4392, -4.8230]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-4.3327, -7.9884]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.2429717779159546\n",
      ".......Validating for epoch 3\n",
      "dev_loss:  tensor(1.0223, device='cuda:0')\n",
      "dev_logits:  tensor([[-1.0750, -1.6513]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_loss:  tensor(0.3926, device='cuda:0')\n",
      "dev_logits:  tensor([[-2.3238, -1.5917]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  52.0\n",
      "--------------Epoch: 4--------------\n",
      "Training for epoch 4.......\n",
      "train_loss:  tensor(3.3987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-3.5012, -0.1366]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ 0.1935, -0.5953]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.2903330326080322\n",
      ".......Validating for epoch 4\n",
      "dev_loss:  tensor(1.0326, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.1778, -5.7702]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(0.0530, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.6206, -3.7099]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 5--------------\n",
      "Training for epoch 5.......\n",
      "train_loss:  tensor(3.7577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.0622, -3.3281]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-2.9537, -3.0167]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.2250010967254639\n",
      ".......Validating for epoch 5\n",
      "dev_loss:  tensor(0.1163, device='cuda:0')\n",
      "dev_logits:  tensor([[-3.9811, -1.8886]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_loss:  tensor(0.0354, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.6629, -3.3401]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  43.0\n",
      "--------------Epoch: 6--------------\n",
      "Training for epoch 6.......\n",
      "train_loss:  tensor(0.1351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-3.4060, -5.3394]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.1232, -7.3241]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.15818190574646\n",
      ".......Validating for epoch 6\n",
      "dev_loss:  tensor(2.4914, device='cuda:0')\n",
      "dev_logits:  tensor([[ -9.5947, -11.9997]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_loss:  tensor(0.0263, device='cuda:0')\n",
      "dev_logits:  tensor([[-10.2586,  -6.6338]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  43.0\n",
      "--------------Epoch: 7--------------\n",
      "Training for epoch 7.......\n",
      "train_loss:  tensor(3.8707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.2238, -4.3742]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.9572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.5520, -6.7470]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.173902988433838\n",
      ".......Validating for epoch 7\n",
      "dev_loss:  tensor(1.2510, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.4386, -6.3524]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(2.2884, device='cuda:0')\n",
      "dev_logits:  tensor([[-4.6569, -6.8383]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  47.0\n",
      "--------------Epoch: 8--------------\n",
      "Training for epoch 8.......\n",
      "train_loss:  tensor(1.2080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.5913, -6.7383]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2029, -8.1088]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.1467746496200562\n",
      ".......Validating for epoch 8\n",
      "dev_loss:  tensor(0.0329, device='cuda:0')\n",
      "dev_logits:  tensor([[-9.4285, -6.0299]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_loss:  tensor(0.6732, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3134, -7.2731]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 9--------------\n",
      "Training for epoch 9.......\n",
      "train_loss:  tensor(0.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.6943, -6.7532]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.9101, -8.2991]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.0407772064208984\n",
      ".......Validating for epoch 9\n",
      "dev_loss:  tensor(1.1727, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.1714, -8.9736]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(1.2766, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.0350, -7.9844]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 10--------------\n",
      "Training for epoch 10.......\n",
      "train_loss:  tensor(0.6376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.9890, -6.1034]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.5469, -9.0916]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9895613789558411\n",
      ".......Validating for epoch 10\n",
      "dev_loss:  tensor(0.3310, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.1371, -5.2016]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(0.0376, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7408, -4.4785]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 11--------------\n",
      "Training for epoch 11.......\n",
      "train_loss:  tensor(0.5812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.1057, -6.3437]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.4295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.7222, -7.5664]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9894933700561523\n",
      ".......Validating for epoch 11\n",
      "dev_loss:  tensor(0.4250, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.6095, -5.9738]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_loss:  tensor(0.9675, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8983, -7.3878]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 12--------------\n",
      "Training for epoch 12.......\n",
      "train_loss:  tensor(1.9728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.1491, -5.3261]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.8282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.4109, -5.1569]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9458529949188232\n",
      ".......Validating for epoch 12\n",
      "dev_loss:  tensor(0.2779, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.2402, -5.1019]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(0.0366, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.2777, -4.9896]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 13--------------\n",
      "Training for epoch 13.......\n",
      "train_loss:  tensor(0.2559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.6029, -6.8350]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-4.9134, -5.8201]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9291983842849731\n",
      ".......Validating for epoch 13\n",
      "dev_loss:  tensor(1.0596, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4861, -8.1201]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(0.6701, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.2852, -8.2386]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 14--------------\n",
      "Training for epoch 14.......\n",
      "train_loss:  tensor(4.4508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-10.3076,  -5.8686]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.2514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-9.2243, -8.3100]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9405280351638794\n",
      ".......Validating for epoch 14\n",
      "dev_loss:  tensor(0.3756, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.6005, -7.8151]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.6886, device='cuda:0')\n",
      "dev_logits:  tensor([[-10.1946, -10.1856]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  54.0\n",
      "--------------Epoch: 15--------------\n",
      "Training for epoch 15.......\n",
      "train_loss:  tensor(1.3952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-10.6107,  -9.5002]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ -8.8253, -10.0435]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9213146567344666\n",
      ".......Validating for epoch 15\n",
      "dev_loss:  tensor(1.3565, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.2438, -9.3025]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_loss:  tensor(0.1561, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8347, -6.0565]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  46.0\n",
      "--------------Epoch: 16--------------\n",
      "Training for epoch 16.......\n",
      "train_loss:  tensor(1.3832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.7077, -7.6132]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ -8.5922, -10.1212]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9412047266960144\n",
      ".......Validating for epoch 16\n",
      "dev_loss:  tensor(1.7100, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5194, -9.0299]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_loss:  tensor(0.7339, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5996, -7.6794]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  45.0\n",
      "--------------Epoch: 17--------------\n",
      "Training for epoch 17.......\n",
      "train_loss:  tensor(0.1894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.0297, -8.5973]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.3592, -8.3685]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.886634349822998\n",
      ".......Validating for epoch 17\n",
      "dev_loss:  tensor(0.3563, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8554, -7.0069]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(1.3865, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.1417, -8.2406]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 18--------------\n",
      "Training for epoch 18.......\n",
      "train_loss:  tensor(0.9722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8583, -7.3613]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.8283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.1563, -7.9022]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8542928695678711\n",
      ".......Validating for epoch 18\n",
      "dev_loss:  tensor(0.0814, device='cuda:0')\n",
      "dev_logits:  tensor([[-9.0063, -6.5391]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_loss:  tensor(0.7888, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.5074, -8.6904]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  44.0\n",
      "--------------Epoch: 19--------------\n",
      "Training for epoch 19.......\n",
      "train_loss:  tensor(0.9701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.2991, -7.8055]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.5243, -9.0771]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9035339951515198\n",
      ".......Validating for epoch 19\n",
      "dev_loss:  tensor(2.7315, device='cuda:0')\n",
      "dev_logits:  tensor([[ -8.2340, -10.8982]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_loss:  tensor(0.7426, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8421, -7.9386]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  37.0\n",
      "--------------Epoch: 20--------------\n",
      "Training for epoch 20.......\n",
      "train_loss:  tensor(0.0968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ -7.9393, -10.2256]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.8029, -8.7757]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8388018608093262\n",
      ".......Validating for epoch 20\n",
      "dev_loss:  tensor(1.7041, device='cuda:0')\n",
      "dev_logits:  tensor([[ -9.2144, -10.7177]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.4162, device='cuda:0')\n",
      "dev_logits:  tensor([[-9.0738, -8.4126]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  54.0\n",
      "--------------Epoch: 21--------------\n",
      "Training for epoch 21.......\n",
      "train_loss:  tensor(0.8405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-9.7960, -9.5202]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.3907, -7.9350]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8593012094497681\n",
      ".......Validating for epoch 21\n",
      "dev_loss:  tensor(0.3167, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7165, -6.7292]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_loss:  tensor(0.1416, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.1639, -6.2809]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  57.0\n",
      "--------------Epoch: 22--------------\n",
      "Training for epoch 22.......\n",
      "train_loss:  tensor(0.4350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.7853, -7.3923]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4943, -8.8795]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8220749497413635\n",
      ".......Validating for epoch 22\n",
      "dev_loss:  tensor(0.2473, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.2311, -6.9603]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_loss:  tensor(1.4917, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.1181, -8.3550]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 23--------------\n",
      "Training for epoch 23.......\n",
      "train_loss:  tensor(0.2115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.8376, -7.2837]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9592, -6.5175]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8045014142990112\n",
      ".......Validating for epoch 23\n",
      "dev_loss:  tensor(0.5032, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6817, -7.2571]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_loss:  tensor(0.5959, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4311, -7.2261]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  47.0\n",
      "--------------Epoch: 24--------------\n",
      "Training for epoch 24.......\n",
      "train_loss:  tensor(0.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.6461, -8.3101]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8509, -7.9497]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8160671591758728\n",
      ".......Validating for epoch 24\n",
      "dev_loss:  tensor(0.7121, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.6578, -6.6954]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_loss:  tensor(0.8947, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8065, -7.1757]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  54.0\n",
      "--------------Epoch: 25--------------\n",
      "Training for epoch 25.......\n",
      "train_loss:  tensor(1.8029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8265, -6.2037]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9037, -7.0766]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8415746688842773\n",
      ".......Validating for epoch 25\n",
      "dev_loss:  tensor(0.9125, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.0658, -6.4650]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_loss:  tensor(0.4770, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.7560, -6.2636]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  47.0\n",
      "--------------Epoch: 26--------------\n",
      "Training for epoch 26.......\n",
      "train_loss:  tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.0903, -8.2730]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.3052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.8552, -5.8664]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8107126355171204\n",
      ".......Validating for epoch 26\n",
      "dev_loss:  tensor(0.9148, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8101, -7.2131]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_loss:  tensor(1.3365, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.0950, -7.1267]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  40.0\n",
      "--------------Epoch: 27--------------\n",
      "Training for epoch 27.......\n",
      "train_loss:  tensor(1.2126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4453, -6.5858]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.7086, -6.6769]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7702555656433105\n",
      ".......Validating for epoch 27\n",
      "dev_loss:  tensor(0.8932, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.9273, -6.2939]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(0.3752, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.5141, -5.7273]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 28--------------\n",
      "Training for epoch 28.......\n",
      "train_loss:  tensor(0.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.2402, -6.6220]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.0965, -5.6331]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7573811411857605\n",
      ".......Validating for epoch 28\n",
      "dev_loss:  tensor(0.8258, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.4490, -6.6988]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  59.0\n",
      "dev_loss:  tensor(0.8121, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.7432, -5.9684]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  59.0\n",
      "--------------Epoch: 29--------------\n",
      "Training for epoch 29.......\n",
      "train_loss:  tensor(0.9191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4666, -6.0565]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.3081, -6.2827]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8136330842971802\n",
      ".......Validating for epoch 29\n",
      "dev_loss:  tensor(0.6185, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.1596, -6.0043]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_loss:  tensor(0.5315, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.9137, -6.5591]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 30--------------\n",
      "Training for epoch 30.......\n",
      "train_loss:  tensor(0.5975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4794, -6.6808]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.3309, -5.8175]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8074605464935303\n",
      ".......Validating for epoch 30\n",
      "dev_loss:  tensor(1.4040, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.5925, -6.7146]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(0.1866, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.0988, -5.5145]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 31--------------\n",
      "Training for epoch 31.......\n",
      "train_loss:  tensor(0.7377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.9452, -5.8580]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.6111, -5.0362]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7986893057823181\n",
      ".......Validating for epoch 31\n",
      "dev_loss:  tensor(0.3279, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4549, -6.5082]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_loss:  tensor(0.1608, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3599, -5.6140]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  47.0\n",
      "--------------Epoch: 32--------------\n",
      "Training for epoch 32.......\n",
      "train_loss:  tensor(0.2063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4225, -7.8962]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(2.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.2922, -6.4282]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7506538033485413\n",
      ".......Validating for epoch 32\n",
      "dev_loss:  tensor(1.3502, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.1454, -8.1956]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.7330, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.0753, -6.1536]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  53.0\n",
      "--------------Epoch: 33--------------\n",
      "Training for epoch 33.......\n",
      "train_loss:  tensor(1.8808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8529, -6.1375]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.4839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2131, -7.6873]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.768488347530365\n",
      ".......Validating for epoch 33\n",
      "dev_loss:  tensor(0.5291, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4435, -7.0830]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_loss:  tensor(1.2957, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.9201, -7.8960]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  55.0\n",
      "--------------Epoch: 34--------------\n",
      "Training for epoch 34.......\n",
      "train_loss:  tensor(0.6967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4828, -7.4758]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.0712, -7.2581]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7533155679702759\n",
      ".......Validating for epoch 34\n",
      "dev_loss:  tensor(1.2560, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.0244, -7.9452]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_loss:  tensor(1.3850, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.7306, -7.8275]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  42.0\n",
      "--------------Epoch: 35--------------\n",
      "Training for epoch 35.......\n",
      "train_loss:  tensor(0.9977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.6662, -7.1285]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9946, -6.9523]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7745379209518433\n",
      ".......Validating for epoch 35\n",
      "dev_loss:  tensor(0.6684, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4275, -7.3775]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_loss:  tensor(0.7002, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5611, -7.5751]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 36--------------\n",
      "Training for epoch 36.......\n",
      "train_loss:  tensor(1.5071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9582, -5.7016]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.2667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.7649, -6.8292]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7636578679084778\n",
      ".......Validating for epoch 36\n",
      "dev_loss:  tensor(0.8413, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6554, -7.9326]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_loss:  tensor(0.8966, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.2578, -7.6301]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  38.0\n",
      "--------------Epoch: 37--------------\n",
      "Training for epoch 37.......\n",
      "train_loss:  tensor(0.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4635, -7.9269]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.0642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.0130, -7.3720]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7201663851737976\n",
      ".......Validating for epoch 37\n",
      "dev_loss:  tensor(0.2634, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.9715, -6.7718]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_loss:  tensor(0.5999, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8534, -7.6574]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  46.0\n",
      "--------------Epoch: 38--------------\n",
      "Training for epoch 38.......\n",
      "train_loss:  tensor(0.8941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.7498, -7.3816]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4279, -6.8270]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7546659111976624\n",
      ".......Validating for epoch 38\n",
      "dev_loss:  tensor(1.3306, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8725, -7.8961]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_loss:  tensor(0.8026, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3090, -7.5170]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  58.0\n",
      "--------------Epoch: 39--------------\n",
      "Training for epoch 39.......\n",
      "train_loss:  tensor(1.2053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.9321, -7.0829]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2668, -7.6150]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7398672103881836\n",
      ".......Validating for epoch 39\n",
      "dev_loss:  tensor(0.2580, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6552, -6.4321]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(0.6073, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8631, -7.6834]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 40--------------\n",
      "Training for epoch 40.......\n",
      "train_loss:  tensor(1.4637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.4488, -7.2482]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.8185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.3017, -7.0651]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7582509517669678\n",
      ".......Validating for epoch 40\n",
      "dev_loss:  tensor(0.3914, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8587, -7.1226]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  59.0\n",
      "dev_acc[j]:  60.0\n",
      "dev_loss:  tensor(0.6218, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5025, -7.3544]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  61.0\n",
      "--------------Epoch: 41--------------\n",
      "Training for epoch 41.......\n",
      "train_loss:  tensor(0.5279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.1667, -7.5299]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.0527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8726, -7.2491]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7351158857345581\n",
      ".......Validating for epoch 41\n",
      "dev_loss:  tensor(1.2791, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3199, -8.2728]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(0.3222, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7713, -6.8040]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 42--------------\n",
      "Training for epoch 42.......\n",
      "train_loss:  tensor(0.7809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.1110, -7.9426]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4807, -8.2639]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7270342707633972\n",
      ".......Validating for epoch 42\n",
      "dev_loss:  tensor(0.6131, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8378, -6.6709]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.8121, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6714, -7.8967]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  53.0\n",
      "--------------Epoch: 43--------------\n",
      "Training for epoch 43.......\n",
      "train_loss:  tensor(0.3751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.7498, -7.5368]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.0196, -7.1470]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7657537460327148\n",
      ".......Validating for epoch 43\n",
      "dev_loss:  tensor(0.5991, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5249, -7.3270]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_loss:  tensor(1.0419, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7947, -8.4014]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 44--------------\n",
      "Training for epoch 44.......\n",
      "train_loss:  tensor(2.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.4341, -6.5539]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.7690, -8.2934]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.719317615032196\n",
      ".......Validating for epoch 44\n",
      "dev_loss:  tensor(1.1725, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3904, -8.1925]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.8364, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.7822, -7.0507]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  53.0\n",
      "--------------Epoch: 45--------------\n",
      "Training for epoch 45.......\n",
      "train_loss:  tensor(1.5126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.3936, -7.1299]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9763, -7.3206]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7310871481895447\n",
      ".......Validating for epoch 45\n",
      "dev_loss:  tensor(0.5935, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4735, -7.2632]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(0.4480, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6018, -7.0312]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 46--------------\n",
      "Training for epoch 46.......\n",
      "train_loss:  tensor(0.4529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2063, -7.7634]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.9328, -7.4706]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7472051978111267\n",
      ".......Validating for epoch 46\n",
      "dev_loss:  tensor(0.2570, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.5357, -7.3082]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_loss:  tensor(0.6759, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.0697, -7.0349]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  57.0\n",
      "--------------Epoch: 47--------------\n",
      "Training for epoch 47.......\n",
      "train_loss:  tensor(0.7151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.6038, -7.5603]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.9657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.3168, -6.5020]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7424657344818115\n",
      ".......Validating for epoch 47\n",
      "dev_loss:  tensor(0.3832, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.9212, -7.1597]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_loss:  tensor(1.0998, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7899, -8.4848]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  55.0\n",
      "--------------Epoch: 48--------------\n",
      "Training for epoch 48.......\n",
      "train_loss:  tensor(0.7954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.0142, -7.8191]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4752, -7.7222]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7560969591140747\n",
      ".......Validating for epoch 48\n",
      "dev_loss:  tensor(0.5569, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5056, -7.2115]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(1.2381, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3725, -8.2683]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 49--------------\n",
      "Training for epoch 49.......\n",
      "train_loss:  tensor(0.3415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.7010, -7.5997]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4604, -7.7857]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7404201626777649\n",
      ".......Validating for epoch 49\n",
      "dev_loss:  tensor(0.6166, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5301, -7.3706]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(0.9606, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.2078, -7.6861]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 50--------------\n",
      "Training for epoch 50.......\n",
      "train_loss:  tensor(0.5166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2146, -7.6057]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.2192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.2806, -7.4116]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7624594569206238\n",
      ".......Validating for epoch 50\n",
      "dev_loss:  tensor(0.6064, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.2783, -7.0967]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(1.0632, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.9086, -8.5482]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 51--------------\n",
      "Training for epoch 51.......\n",
      "train_loss:  tensor(1.7949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.0139, -6.4007]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.1869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8695, -7.0467]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7553675174713135\n",
      ".......Validating for epoch 51\n",
      "dev_loss:  tensor(0.9036, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.2420, -7.6263]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_loss:  tensor(1.2197, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.9550, -7.8248]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  40.0\n",
      "--------------Epoch: 52--------------\n",
      "Training for epoch 52.......\n",
      "train_loss:  tensor(0.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.8961, -7.6535]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.1064, -7.5570]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.739622950553894\n",
      ".......Validating for epoch 52\n",
      "dev_loss:  tensor(0.7588, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4846, -7.6118]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  59.0\n",
      "dev_acc[j]:  59.0\n",
      "dev_acc[j]:  60.0\n",
      "dev_loss:  tensor(1.3966, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4250, -8.5373]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  60.0\n",
      "Training completed in 0:24:17.708705\n"
     ]
    }
   ],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "epochs = 52\n",
    "per_num_epoch = 1\n",
    "\n",
    "# train_acc = np.zeros(epochs)\n",
    "train_loss_by_epoch = np.zeros(epochs)\n",
    "dev_acc = np.zeros(epochs)\n",
    "dev_loss_by_epoch = np.zeros(epochs)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for j in range(epochs):\n",
    "    if j % per_num_epoch == 0:\n",
    "        print('--------------Epoch: ' + str(j+1) + '--------------')\n",
    "    \n",
    "    if j % per_num_epoch == 0:\n",
    "        print(f'Training for epoch {j + 1}.......')\n",
    "    \n",
    "    av_train_loss = 0\n",
    "    # print(\"av_train_loss_original: \", av_train_loss)\n",
    "    model.train()\n",
    "    for i in range(0, dev_raw_data.shape[0] - 100):\n",
    "        # print(\"av_train_loss_track: \", av_train_loss)\n",
    "        prompt = dev_raw_data.iloc[i]['asks-for'] + \". \" + dev_raw_data.iloc[i]['p']\n",
    "        choice0 = dev_raw_data.iloc[i]['a1']\n",
    "        choice1 = dev_raw_data.iloc[i]['a2']\n",
    "        label = torch.tensor(dev_raw_data.iloc[i]['most-plausible-alternative'] - 1).unsqueeze(0).to(device)\n",
    "        # print(\"label is: \", label)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        # encoding = {(prompt+choice0), (prompt+choice1)}\n",
    "        # outputs = model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "        outputs = model(**{k: v.unsqueeze(0) for k,v in encoding.items()}, labels=label)\n",
    "        # print(\"outputs: \", outputs)\n",
    "\n",
    "        train_loss = outputs.loss\n",
    "        train_logits = outputs.logits\n",
    "        av_train_loss += train_loss\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "        if i == 1:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss_by_epoch[j] = av_train_loss / (dev_raw_data.shape[0] - 100)\n",
    "    print(\"av_train_loss: \", train_loss_by_epoch[j])\n",
    "\n",
    "    # validation\n",
    "    # if (j + 1) % per_num_epoch == 0:\n",
    "    #     print(f'.......Validating for epoch {j + 1}')\n",
    "    if (j) % per_num_epoch == 0:\n",
    "        print(f'.......Validating for epoch {j + 1}')\n",
    "        av_dev_loss = 0\n",
    "        # model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(dev_raw_data.shape[0] - 99, dev_raw_data.shape[0]):\n",
    "                # print(\"av_dev_loss_track: \", av_dev_loss)\n",
    "                prompt_val = dev_raw_data.iloc[i]['asks-for'] + \". \" + dev_raw_data.iloc[i]['p']\n",
    "                choice0_val = dev_raw_data.iloc[i]['a1']\n",
    "                choice1_val = dev_raw_data.iloc[i]['a2']\n",
    "                label_val = torch.tensor(dev_raw_data.iloc[i]['most-plausible-alternative'] - 1).unsqueeze(0).to(device)\n",
    "\n",
    "                encoding_val = tokenizer([prompt_val, prompt_val], [choice0_val, choice1_val], return_tensors='pt', padding=True).to(device)\n",
    "                # outputs = model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "                outputs_val = model(**{k: v.unsqueeze(0) for k,v in encoding_val.items()}, labels=label_val)\n",
    "                \n",
    "                dev_loss = outputs_val.loss\n",
    "                dev_logits = outputs_val.logits\n",
    "                av_dev_loss += dev_loss\n",
    "                \n",
    "                if i == dev_raw_data.shape[0] - 99:\n",
    "                    print(\"dev_loss: \", dev_loss)\n",
    "                    print(\"dev_logits: \", dev_logits)\n",
    "                    print(\"label: \", label_val)\n",
    "                if i == dev_raw_data.shape[0] - 1:\n",
    "                    print(\"dev_loss: \", dev_loss)\n",
    "                    print(\"dev_logits: \", dev_logits)\n",
    "                    print(\"label: \", label_val)\n",
    "\n",
    "                #calculate accuracy\n",
    "                y_pred = 1 if outputs_val.logits[0][1] > outputs_val.logits[0][0] else 0\n",
    "                y_pred = torch.tensor(y_pred).unsqueeze(0).to(device)\n",
    "                # print(\"y_pred: \", y_pred)\n",
    "                # print(\"label: \", label)\n",
    "                # print(\"y_pred =? label: \", y_pred == label)\n",
    "                if y_pred == label_val:\n",
    "                    dev_acc[j] += 1\n",
    "                \n",
    "        dev_acc[j] /= 100\n",
    "        print(\"dev_acc[j]: \", dev_acc[j])\n",
    "        dev_loss_by_epoch[j] = av_dev_loss / 100\n",
    "        \n",
    "    # learning rate decay\n",
    "    # if j == 5:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    # elif j == 15:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    # elif j == 20:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    # elif j == 40:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "    # elif j == 50:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-7)    \n",
    "    scheduler.step()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f'Training completed in {str(end_time - start_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title(\"Loss VS Epoch\")\n",
    "\n",
    "plt.plot(train_loss_by_epoch, label=\"train_loss\")\n",
    "plt.plot(dev_loss_by_epoch, label=\"dev_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title(\"acc VS Epoch\")\n",
    "\n",
    "plt.plot(dev_acc, label=\"dev_acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, 'RoBERTa.pth')# epochs = 100, lr=1e-2 -> scheular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = torch.load('RoBERTa.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18952/1819011883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mchoice0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_raw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mchoice1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_raw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mlabel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_raw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'most-plausible-alternative'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mencoding_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchoice0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchoice1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "test_model.eval()\n",
    "num_correct_pred = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, test_raw_data.shape[0]):\n",
    "        prompt = test_raw_data.iloc[i]['asks-for'] + \". \" + test_raw_data.iloc[i]['p']\n",
    "        choice0 = test_raw_data.iloc[i]['a1']\n",
    "        choice1 = test_raw_data.iloc[i]['a2']\n",
    "        label_test = torch.tensor(test_raw_data.iloc[i]['most-plausible-alternative']).unsqueeze(0).to(device)\n",
    "\n",
    "        encoding_test = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        # outputs = test_model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "        outputs_test = test_model(**{k: v.unsqueeze(0) for k,v in encoding_test.items()}, labels=label_test)\n",
    "        print(\"outputs_test.logits: \", outputs_test.logits)\n",
    "        # test_logits = outputs_test.logits\n",
    "\n",
    "        #calculate accuracy\n",
    "        y_pred_test = 1 if outputs_test.logits[0][1] > outputs_test.logits[0][0] else 0\n",
    "        y_pred_test = torch.tensor(y_pred_test).unsqueeze(0).to(device)\n",
    "\n",
    "        if y_pred_test == label_test:\n",
    "            print(\"test_logits: \", outputs_test.logits)\n",
    "            print(\"y_pred: \", y_pred_test)\n",
    "            print(\"label: \", label_test)\n",
    "            num_correct_pred += 1\n",
    "\n",
    "acc = num_correct_pred / test_raw_data.shape[0]\n",
    "print(\"test_accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_logits:  tensor([[1193.0547, 1193.0547]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "test_accuracy =  0.55\n"
     ]
    }
   ],
   "source": [
    "# test_model.eval()\n",
    "num_correct_pred = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, test_raw_data.shape[0]):\n",
    "        prompt = test_raw_data.iloc[i]['question'] + \". \" + test_raw_data.iloc[i]['premise']\n",
    "        choice0 = test_raw_data.iloc[i]['choice1']\n",
    "        choice1 = test_raw_data.iloc[i]['choice2']\n",
    "        label = torch.tensor(test_raw_data.iloc[i]['label']).unsqueeze(0).to(device)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        outputs = test_model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "\n",
    "        test_logits = outputs.logits\n",
    "\n",
    "        #calculate accuracy\n",
    "        y_pred = 1 if outputs.logits[0][1] > outputs.logits[0][0] else 0\n",
    "        y_pred = torch.tensor(y_pred).unsqueeze(0).to(device)\n",
    "\n",
    "        if y_pred == label:\n",
    "            print(\"test_logits: \", test_logits)\n",
    "            print(\"y_pred: \", y_pred)\n",
    "            print(\"label: \", label)\n",
    "            num_correct_pred += 1\n",
    "\n",
    "acc = num_correct_pred / test_raw_data.shape[0]\n",
    "print(\"test_accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revise\n",
    "# Training\n",
    "ce = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "epochs = 100\n",
    "per_num_epoch = 1\n",
    "\n",
    "# train_acc = np.zeros(epochs)\n",
    "train_loss_by_epoch = np.zeros(epochs)\n",
    "dev_acc = np.zeros(epochs)\n",
    "dev_loss_by_epoch = np.zeros(epochs)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for j in range(epochs):\n",
    "    if j % per_num_epoch == 0:\n",
    "        print('--------------Epoch: ' + str(j+1) + '--------------')\n",
    "    \n",
    "    if j % per_num_epoch == 0:\n",
    "        print(f'Training for epoch {j + 1}.......')\n",
    "    av_train_loss = 0\n",
    "    # print(\"av_train_loss_original: \", av_train_loss)\n",
    "    model.train()\n",
    "    for i in range(0, train_raw_data.shape[0]):\n",
    "        # print(\"av_train_loss_track: \", av_train_loss)\n",
    "        prompt = train_raw_data.iloc[i]['question'] + \". \" + train_raw_data.iloc[i]['premise']\n",
    "        choice0 = train_raw_data.iloc[i]['choice1']\n",
    "        choice1 = train_raw_data.iloc[i]['choice2']\n",
    "        label = torch.tensor(train_raw_data.iloc[i]['label']).unsqueeze(0).to(device)\n",
    "        # print(\"label is: \", label)\n",
    "        # label = torch.tensor(rawdata.iloc[i]['label']).unsqueeze(0).to(device)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        # outputs = model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "        \n",
    "        outputs = model(**{k: v.unsqueeze(0) for k,v in encoding.items()}, labels=label)\n",
    "        \n",
    "        train_loss = outputs.loss\n",
    "        train_logits = outputs.logits\n",
    "        av_train_loss += train_loss\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "        if i == 1:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # learning rate decay\n",
    "        if j == 25:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "        elif j == 50:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=1e-7)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss_by_epoch[j] = av_train_loss / train_raw_data.shape[0]\n",
    "    print(\"av_train_loss: \", train_loss_by_epoch[j])\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f'Training completed in {str(end_time - start_time)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "1. Ask about whether the very last output of RoBERTaMultipleChoice is the possibility score for one input embedding.\n",
    "\n",
    "(pooler): RobertaPooler(\n",
    "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "      (activation): Tanh()\n",
    "    )\n",
    "  )\n",
    "  (dropout): Dropout(p=0.1, inplace=False)\n",
    "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
    "\n",
    "\n",
    "2. What's wrong with the model.eval()?\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a411169b02b4f5d985b282c4f140db7a58e4cacae7bbcf8f29fd937be3ae09c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('NLP_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
