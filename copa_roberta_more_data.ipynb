{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# import json\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import transformers\n",
    "from transformers import RobertaModel, RobertaTokenizer, RobertaForMultipleChoice\n",
    "from torch import cuda\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asks-for</th>\n",
       "      <th>most-plausible-alternative</th>\n",
       "      <th>p</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>My body cast a shadow over the grass.</td>\n",
       "      <td>The sun was rising.</td>\n",
       "      <td>The grass was cut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>The woman tolerated her friend's difficult beh...</td>\n",
       "      <td>The woman knew her friend was going through a ...</td>\n",
       "      <td>The woman felt that her friend took advantage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The women met for coffee.</td>\n",
       "      <td>The cafe reopened in a new location.</td>\n",
       "      <td>They wanted to catch up with each other.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>The runner wore shorts.</td>\n",
       "      <td>The forecast predicted high temperatures.</td>\n",
       "      <td>She planned to run along the beach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>The guests of the party hid behind the couch.</td>\n",
       "      <td>It was a surprise party.</td>\n",
       "      <td>It was a birthday party.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The politician lost the election.</td>\n",
       "      <td>He ran negative campaign ads.</td>\n",
       "      <td>No one voted for him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The stain came out of the shirt.</td>\n",
       "      <td>I patched the shirt.</td>\n",
       "      <td>I bleached the shirt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The man got a discount on his groceries.</td>\n",
       "      <td>He greeted the cashier.</td>\n",
       "      <td>He used a coupon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>effect</td>\n",
       "      <td>1</td>\n",
       "      <td>The physician misdiagnosed the patient.</td>\n",
       "      <td>The patient filed a malpractice lawsuit agains...</td>\n",
       "      <td>The patient disclosed confidential information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>cause</td>\n",
       "      <td>2</td>\n",
       "      <td>The customer filed a complaint with the store ...</td>\n",
       "      <td>The sales associate undercharged the customer.</td>\n",
       "      <td>The sales associate acted rude to the customer.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id asks-for  most-plausible-alternative  \\\n",
       "0   1    cause                           1   \n",
       "1   2    cause                           1   \n",
       "2   3    cause                           2   \n",
       "3   4    cause                           1   \n",
       "4   5    cause                           1   \n",
       "5   6    cause                           2   \n",
       "6   7    cause                           2   \n",
       "7   8    cause                           2   \n",
       "8   9   effect                           1   \n",
       "9  10    cause                           2   \n",
       "\n",
       "                                                   p  \\\n",
       "0              My body cast a shadow over the grass.   \n",
       "1  The woman tolerated her friend's difficult beh...   \n",
       "2                          The women met for coffee.   \n",
       "3                            The runner wore shorts.   \n",
       "4      The guests of the party hid behind the couch.   \n",
       "5                  The politician lost the election.   \n",
       "6                   The stain came out of the shirt.   \n",
       "7           The man got a discount on his groceries.   \n",
       "8            The physician misdiagnosed the patient.   \n",
       "9  The customer filed a complaint with the store ...   \n",
       "\n",
       "                                                  a1  \\\n",
       "0                                The sun was rising.   \n",
       "1  The woman knew her friend was going through a ...   \n",
       "2               The cafe reopened in a new location.   \n",
       "3          The forecast predicted high temperatures.   \n",
       "4                           It was a surprise party.   \n",
       "5                      He ran negative campaign ads.   \n",
       "6                               I patched the shirt.   \n",
       "7                            He greeted the cashier.   \n",
       "8  The patient filed a malpractice lawsuit agains...   \n",
       "9     The sales associate undercharged the customer.   \n",
       "\n",
       "                                                  a2  \n",
       "0                                 The grass was cut.  \n",
       "1  The woman felt that her friend took advantage ...  \n",
       "2           They wanted to catch up with each other.  \n",
       "3                She planned to run along the beach.  \n",
       "4                           It was a birthday party.  \n",
       "5                              No one voted for him.  \n",
       "6                              I bleached the shirt.  \n",
       "7                                  He used a coupon.  \n",
       "8  The patient disclosed confidential information...  \n",
       "9    The sales associate acted rude to the customer.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "test_raw_data = pd.read_xml('data/COPA-resources/datasets/copa-test.xml')\n",
    "dev_raw_data = pd.read_xml('data/COPA-resources/datasets/copa-dev.xml') # train-test-split 400-100\n",
    "dev_raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sequence is:  {cause}The frozen food thawed.\n",
      "{'input_ids': [0, 45152, 27037, 24303, 133, 9214, 689, 3553, 32211, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['{', 'cause', '}', 'The', 'Ġfrozen', 'Ġfood', 'Ġth', 'awed', '.']\n",
      "test_sequence is:  {effect}I emptied my pockets.\n",
      "{'input_ids': [0, 45152, 26715, 24303, 100, 35371, 127, 12189, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['{', 'effect', '}', 'I', 'Ġemptied', 'Ġmy', 'Ġpockets', '.']\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# test_sequence = \"{\" + \"effect\" + \"}\" + \"I ran the ice cube under warm water.\"\n",
    "test_sequence = \"{\"+ test_raw_data.iloc[28]['asks-for'] + \"}\" + test_raw_data.iloc[28]['p']\n",
    "print(\"test_sequence is: \", test_sequence)\n",
    "print(tokenizer(test_sequence))\n",
    "print(tokenizer.tokenize(test_sequence))\n",
    "# test 2\n",
    "test_sequence = \"{\"+ test_raw_data.iloc[1]['asks-for'] + \"}\" + test_raw_data.iloc[1]['p']\n",
    "print(\"test_sequence is: \", test_sequence)\n",
    "print(tokenizer(test_sequence))\n",
    "print(tokenizer.tokenize(test_sequence))\n",
    "\n",
    "print(test_raw_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(rawdata):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    \n",
    "    # for i in range(0, rawdata.shape[0]):\n",
    "    for i in range(2, 5):\n",
    "        prompt = rawdata.iloc[i]['asks-for'] + \".\" + rawdata.iloc[i]['p']\n",
    "        choice0 = rawdata.iloc[i]['a1']\n",
    "        choice1 = rawdata.iloc[i]['a2']\n",
    "        label = torch.tensor(rawdata.iloc[i]['most-plausible-alternative'] - 1)\n",
    "        # label = torch.tensor(rawdata.iloc[i]['label']).unsqueeze(0).to(device)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True)\n",
    "        print(\"encoding['input_ids']: \", encoding['input_ids'])\n",
    "        print(\"encoding['input_ids'] with size of : \", encoding['input_ids'].size())\n",
    "        print(\"encoding['attention_mask']: \", encoding['attention_mask'])\n",
    "        print(\"label: \", label)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(dev_raw_data.shape[0])\n",
    "print(test_raw_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding['input_ids']:  tensor([[    0, 27037,     4,   133,   390,  1145,    13,  3895,     4,     2,\n",
      "             2,   133, 16381, 14015,    11,    10,    92,  2259,     4,     2,\n",
      "             1],\n",
      "        [    0, 27037,     4,   133,   390,  1145,    13,  3895,     4,     2,\n",
      "             2,  1213,   770,     7,  2916,    62,    19,   349,    97,     4,\n",
      "             2]])\n",
      "encoding['input_ids'] with size of :  torch.Size([2, 21])\n",
      "encoding['attention_mask']:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "label:  tensor(1)\n",
      "encoding['input_ids']:  tensor([[    0, 27037,     4,   133,  7449,  5328, 13344,     4,     2,     2,\n",
      "           133,  1914,  6126,   239,  3971,     4,     2,     1,     1],\n",
      "        [    0, 27037,     4,   133,  7449,  5328, 13344,     4,     2,     2,\n",
      "          2515,  1904,     7,   422,   552,     5,  4105,     4,     2]])\n",
      "encoding['input_ids'] with size of :  torch.Size([2, 19])\n",
      "encoding['attention_mask']:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "label:  tensor(0)\n",
      "encoding['input_ids']:  tensor([[    0, 27037,     4,   133,  3958,     9,     5,   537, 20119,   639,\n",
      "             5, 16433,     4,     2,     2,   243,    21,    10,  2755,   537,\n",
      "             4,     2],\n",
      "        [    0, 27037,     4,   133,  3958,     9,     5,   537, 20119,   639,\n",
      "             5, 16433,     4,     2,     2,   243,    21,    10,  4115,   537,\n",
      "             4,     2]])\n",
      "encoding['input_ids'] with size of :  torch.Size([2, 22])\n",
      "encoding['attention_mask']:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "label:  tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# tokenize data tests\n",
    "dev_data = load_data(dev_raw_data)\n",
    "# print(f'Training data loaded (length {len(train_data)})')\n",
    "# dev_data = load_data('data/dev.jsonl')\n",
    "# print(f'Dev data loaded (length {len(dev_data)})')\n",
    "# test_data = load_data('data/test.jsonl')\n",
    "# print(f'Test data loaded (length {len(test_data)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_3, use only the very last hidden layer from Roberta.\n",
    "from torch import nn\n",
    "from transformers import RobertaConfig, RobertaModel\n",
    "\n",
    "class OurRobertaCOPA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OurRobertaCOPA, self).__init__()\n",
    "        # self.configuration = RobertaConfig()\n",
    "        # self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "        # self.l1 = RobertaModel(self.configuration)\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.l1.requires_grad = True\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 512)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        # self.classifier = torch.nn.Linear(768, 5)\n",
    "        # hidden_dim=32 for later trials.\n",
    "        # self.lstm = nn.LSTM(768, 32, 1, bias=False)\n",
    "        self.output_layer = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, sequence_1, sequence_2):\n",
    "        # Two input here\n",
    "        token_1 = tokenizer(sequence_1)\n",
    "        token_2 = tokenizer(sequence_2)\n",
    "        output_1 = self.l1(input_ids=torch.tensor(token_1[\"input_ids\"]).unsqueeze(0), attention_mask=torch.tensor(token_1[\"attention_mask\"]).unsqueeze(0))[0]\n",
    "        output_2 = self.l1(input_ids=torch.tensor(token_2[\"input_ids\"]).unsqueeze(0), attention_mask=torch.tensor(token_2[\"attention_mask\"]).unsqueeze(0))[0]\n",
    "        # RobertaModel(RobertaConfig())\n",
    "\n",
    "        # _, (hidden_rep_1, _) = self.lstm(output_1.unsqueeze(0))\n",
    "        # _, (hidden_rep_2, _) = self.lstm(output_2.unsqueeze(0))\n",
    "        # _, (hidden_rep_1, _) = self.lstm(output_1)\n",
    "        # _, (hidden_rep_2, _) = self.lstm(output_2)\n",
    "\n",
    "        hidden_rep_1 = torch.nn.ReLU()(self.pre_classifier(output_1[0])).squeeze(0)\n",
    "        hidden_rep_2 = torch.nn.ReLU()(self.pre_classifier(output_2[0])).squeeze(0)\n",
    "        pooler_1 = hidden_rep_1[:, 0]\n",
    "        pooler_2 = hidden_rep_2[:, 0]\n",
    "        # hidden_rep_1 = self.pre_classifier(output_1[0]).squeeze(0)\n",
    "        # hidden_rep_2 = self.pre_classifier(output_2[0]).squeeze(0)\n",
    "        # print(\"-------hidden_rep_1:\")\n",
    "        # print(hidden_rep_1)\n",
    "        # print(hidden_rep_1.size())\n",
    "        # print(\"-------hidden_rep_2:\")\n",
    "        # print(hidden_rep_2)\n",
    "        # print(hidden_rep_2.size())\n",
    "        \n",
    "        # hidden_rep = torch.cat((hidden_rep_1.unsqueeze(1), hidden_rep_2.unsqueeze(1)), 1)\n",
    "        # hidden_rep = self.dropout(torch.cat((hidden_rep_1, hidden_rep_2), 0))\n",
    "        hidden_rep = self.dropout(torch.cat((pooler_1, pooler_2), 0))\n",
    "\n",
    "        print(\"-------hidden_rep:\")\n",
    "        # print(hidden_rep)\n",
    "        print(hidden_rep.size())\n",
    "\n",
    "        output = self.output_layer(hidden_rep.unsqueeze(0))\n",
    "        print(\"-------output:\")\n",
    "        # print(output)\n",
    "        print(output.size())\n",
    "        print(\"--------------\")\n",
    "\n",
    "        output_squezzed = output.squeeze(0).squeeze(0)\n",
    "        print(\"-------output_squezzed:\")\n",
    "        print(output_squezzed)\n",
    "        print(output_squezzed.size())\n",
    "        print(\"--------------\")\n",
    "        \n",
    "        # y_hat = softmax(output_squezzed)\n",
    "        # y_sum =  torch.sum(y_hat, 0)\n",
    "        # col1= torch.sum(y_hat, 0)[0]\n",
    "        # col2 = torch.sum(y_hat, 0)[1]\n",
    "        # y_result = torch.tensor(torch.argmax(y_sum)).type(torch.FloatTensor)\n",
    "        # y_result = torch.tensor(y_sum)\n",
    "        \n",
    "        return output_squezzed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForMultipleChoice(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# model = OurRobertaCOPA()\n",
    "model = RobertaForMultipleChoice.from_pretrained('roberta-base')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Epoch: 1--------------\n",
      "Training for epoch 1.......\n",
      "train_loss:  tensor(1.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2321, -6.6679]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(2.1292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.3377, -5.3351]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.093465805053711\n",
      ".......Validating for epoch 1\n",
      "dev_loss:  tensor(0.2771, device='cuda:0')\n",
      "dev_logits:  tensor([[-4.4653, -3.3236]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_loss:  tensor(0.9445, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.1815, -5.6335]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  54.0\n",
      "--------------Epoch: 2--------------\n",
      "Training for epoch 2.......\n",
      "train_loss:  tensor(0.7258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-4.7509, -4.6866]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-4.9796, -7.7781]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.1721071004867554\n",
      ".......Validating for epoch 2\n",
      "dev_loss:  tensor(2.0170, device='cuda:0')\n",
      "dev_logits:  tensor([[-4.6715, -6.5457]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(0.0664, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.1951, -3.5165]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 3--------------\n",
      "Training for epoch 3.......\n",
      "train_loss:  tensor(2.6867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4392, -4.8230]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-4.3327, -7.9884]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.2429717779159546\n",
      ".......Validating for epoch 3\n",
      "dev_loss:  tensor(1.0223, device='cuda:0')\n",
      "dev_logits:  tensor([[-1.0750, -1.6513]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_loss:  tensor(0.3926, device='cuda:0')\n",
      "dev_logits:  tensor([[-2.3238, -1.5917]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  52.0\n",
      "--------------Epoch: 4--------------\n",
      "Training for epoch 4.......\n",
      "train_loss:  tensor(3.3987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-3.5012, -0.1366]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ 0.1935, -0.5953]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.2903330326080322\n",
      ".......Validating for epoch 4\n",
      "dev_loss:  tensor(1.0326, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.1778, -5.7702]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(0.0530, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.6206, -3.7099]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 5--------------\n",
      "Training for epoch 5.......\n",
      "train_loss:  tensor(3.7577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.0622, -3.3281]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-2.9537, -3.0167]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.2250010967254639\n",
      ".......Validating for epoch 5\n",
      "dev_loss:  tensor(0.1163, device='cuda:0')\n",
      "dev_logits:  tensor([[-3.9811, -1.8886]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_loss:  tensor(0.0354, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.6629, -3.3401]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  43.0\n",
      "--------------Epoch: 6--------------\n",
      "Training for epoch 6.......\n",
      "train_loss:  tensor(0.1351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-3.4060, -5.3394]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.1232, -7.3241]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.15818190574646\n",
      ".......Validating for epoch 6\n",
      "dev_loss:  tensor(2.4914, device='cuda:0')\n",
      "dev_logits:  tensor([[ -9.5947, -11.9997]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_loss:  tensor(0.0263, device='cuda:0')\n",
      "dev_logits:  tensor([[-10.2586,  -6.6338]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  43.0\n",
      "--------------Epoch: 7--------------\n",
      "Training for epoch 7.......\n",
      "train_loss:  tensor(3.8707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.2238, -4.3742]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.9572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.5520, -6.7470]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.173902988433838\n",
      ".......Validating for epoch 7\n",
      "dev_loss:  tensor(1.2510, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.4386, -6.3524]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(2.2884, device='cuda:0')\n",
      "dev_logits:  tensor([[-4.6569, -6.8383]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  47.0\n",
      "--------------Epoch: 8--------------\n",
      "Training for epoch 8.......\n",
      "train_loss:  tensor(1.2080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.5913, -6.7383]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2029, -8.1088]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.1467746496200562\n",
      ".......Validating for epoch 8\n",
      "dev_loss:  tensor(0.0329, device='cuda:0')\n",
      "dev_logits:  tensor([[-9.4285, -6.0299]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_loss:  tensor(0.6732, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3134, -7.2731]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 9--------------\n",
      "Training for epoch 9.......\n",
      "train_loss:  tensor(0.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.6943, -6.7532]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.9101, -8.2991]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  1.0407772064208984\n",
      ".......Validating for epoch 9\n",
      "dev_loss:  tensor(1.1727, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.1714, -8.9736]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(1.2766, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.0350, -7.9844]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 10--------------\n",
      "Training for epoch 10.......\n",
      "train_loss:  tensor(0.6376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.9890, -6.1034]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.5469, -9.0916]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9895613789558411\n",
      ".......Validating for epoch 10\n",
      "dev_loss:  tensor(0.3310, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.1371, -5.2016]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(0.0376, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7408, -4.4785]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 11--------------\n",
      "Training for epoch 11.......\n",
      "train_loss:  tensor(0.5812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.1057, -6.3437]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.4295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.7222, -7.5664]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9894933700561523\n",
      ".......Validating for epoch 11\n",
      "dev_loss:  tensor(0.4250, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.6095, -5.9738]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_loss:  tensor(0.9675, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8983, -7.3878]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 12--------------\n",
      "Training for epoch 12.......\n",
      "train_loss:  tensor(1.9728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.1491, -5.3261]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.8282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.4109, -5.1569]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9458529949188232\n",
      ".......Validating for epoch 12\n",
      "dev_loss:  tensor(0.2779, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.2402, -5.1019]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(0.0366, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.2777, -4.9896]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 13--------------\n",
      "Training for epoch 13.......\n",
      "train_loss:  tensor(0.2559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.6029, -6.8350]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-4.9134, -5.8201]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9291983842849731\n",
      ".......Validating for epoch 13\n",
      "dev_loss:  tensor(1.0596, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4861, -8.1201]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(0.6701, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.2852, -8.2386]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 14--------------\n",
      "Training for epoch 14.......\n",
      "train_loss:  tensor(4.4508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-10.3076,  -5.8686]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.2514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-9.2243, -8.3100]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9405280351638794\n",
      ".......Validating for epoch 14\n",
      "dev_loss:  tensor(0.3756, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.6005, -7.8151]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.6886, device='cuda:0')\n",
      "dev_logits:  tensor([[-10.1946, -10.1856]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  54.0\n",
      "--------------Epoch: 15--------------\n",
      "Training for epoch 15.......\n",
      "train_loss:  tensor(1.3952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-10.6107,  -9.5002]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ -8.8253, -10.0435]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9213146567344666\n",
      ".......Validating for epoch 15\n",
      "dev_loss:  tensor(1.3565, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.2438, -9.3025]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_loss:  tensor(0.1561, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8347, -6.0565]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  46.0\n",
      "--------------Epoch: 16--------------\n",
      "Training for epoch 16.......\n",
      "train_loss:  tensor(1.3832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.7077, -7.6132]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ -8.5922, -10.1212]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9412047266960144\n",
      ".......Validating for epoch 16\n",
      "dev_loss:  tensor(1.7100, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5194, -9.0299]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_loss:  tensor(0.7339, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5996, -7.6794]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  45.0\n",
      "--------------Epoch: 17--------------\n",
      "Training for epoch 17.......\n",
      "train_loss:  tensor(0.1894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.0297, -8.5973]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.3592, -8.3685]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.886634349822998\n",
      ".......Validating for epoch 17\n",
      "dev_loss:  tensor(0.3563, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8554, -7.0069]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(1.3865, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.1417, -8.2406]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 18--------------\n",
      "Training for epoch 18.......\n",
      "train_loss:  tensor(0.9722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8583, -7.3613]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.8283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.1563, -7.9022]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8542928695678711\n",
      ".......Validating for epoch 18\n",
      "dev_loss:  tensor(0.0814, device='cuda:0')\n",
      "dev_logits:  tensor([[-9.0063, -6.5391]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_loss:  tensor(0.7888, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.5074, -8.6904]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  44.0\n",
      "--------------Epoch: 19--------------\n",
      "Training for epoch 19.......\n",
      "train_loss:  tensor(0.9701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.2991, -7.8055]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.5243, -9.0771]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.9035339951515198\n",
      ".......Validating for epoch 19\n",
      "dev_loss:  tensor(2.7315, device='cuda:0')\n",
      "dev_logits:  tensor([[ -8.2340, -10.8982]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_loss:  tensor(0.7426, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8421, -7.9386]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  37.0\n",
      "--------------Epoch: 20--------------\n",
      "Training for epoch 20.......\n",
      "train_loss:  tensor(0.0968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ -7.9393, -10.2256]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.8029, -8.7757]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8388018608093262\n",
      ".......Validating for epoch 20\n",
      "dev_loss:  tensor(1.7041, device='cuda:0')\n",
      "dev_logits:  tensor([[ -9.2144, -10.7177]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.4162, device='cuda:0')\n",
      "dev_logits:  tensor([[-9.0738, -8.4126]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  54.0\n",
      "--------------Epoch: 21--------------\n",
      "Training for epoch 21.......\n",
      "train_loss:  tensor(0.8405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-9.7960, -9.5202]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.3907, -7.9350]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8593012094497681\n",
      ".......Validating for epoch 21\n",
      "dev_loss:  tensor(0.3167, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7165, -6.7292]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_loss:  tensor(0.1416, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.1639, -6.2809]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  57.0\n",
      "--------------Epoch: 22--------------\n",
      "Training for epoch 22.......\n",
      "train_loss:  tensor(0.4350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.7853, -7.3923]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4943, -8.8795]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8220749497413635\n",
      ".......Validating for epoch 22\n",
      "dev_loss:  tensor(0.2473, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.2311, -6.9603]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_loss:  tensor(1.4917, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.1181, -8.3550]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 23--------------\n",
      "Training for epoch 23.......\n",
      "train_loss:  tensor(0.2115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.8376, -7.2837]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9592, -6.5175]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8045014142990112\n",
      ".......Validating for epoch 23\n",
      "dev_loss:  tensor(0.5032, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6817, -7.2571]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_loss:  tensor(0.5959, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4311, -7.2261]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  47.0\n",
      "--------------Epoch: 24--------------\n",
      "Training for epoch 24.......\n",
      "train_loss:  tensor(0.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.6461, -8.3101]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8509, -7.9497]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8160671591758728\n",
      ".......Validating for epoch 24\n",
      "dev_loss:  tensor(0.7121, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.6578, -6.6954]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_loss:  tensor(0.8947, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8065, -7.1757]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  54.0\n",
      "--------------Epoch: 25--------------\n",
      "Training for epoch 25.......\n",
      "train_loss:  tensor(1.8029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8265, -6.2037]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9037, -7.0766]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8415746688842773\n",
      ".......Validating for epoch 25\n",
      "dev_loss:  tensor(0.9125, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.0658, -6.4650]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_loss:  tensor(0.4770, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.7560, -6.2636]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  47.0\n",
      "--------------Epoch: 26--------------\n",
      "Training for epoch 26.......\n",
      "train_loss:  tensor(0.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.0903, -8.2730]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.3052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.8552, -5.8664]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8107126355171204\n",
      ".......Validating for epoch 26\n",
      "dev_loss:  tensor(0.9148, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8101, -7.2131]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_loss:  tensor(1.3365, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.0950, -7.1267]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  40.0\n",
      "--------------Epoch: 27--------------\n",
      "Training for epoch 27.......\n",
      "train_loss:  tensor(1.2126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4453, -6.5858]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.7086, -6.6769]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7702555656433105\n",
      ".......Validating for epoch 27\n",
      "dev_loss:  tensor(0.8932, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.9273, -6.2939]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(0.3752, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.5141, -5.7273]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 28--------------\n",
      "Training for epoch 28.......\n",
      "train_loss:  tensor(0.5204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.2402, -6.6220]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.0965, -5.6331]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7573811411857605\n",
      ".......Validating for epoch 28\n",
      "dev_loss:  tensor(0.8258, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.4490, -6.6988]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  59.0\n",
      "dev_loss:  tensor(0.8121, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.7432, -5.9684]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  59.0\n",
      "--------------Epoch: 29--------------\n",
      "Training for epoch 29.......\n",
      "train_loss:  tensor(0.9191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4666, -6.0565]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.3081, -6.2827]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8136330842971802\n",
      ".......Validating for epoch 29\n",
      "dev_loss:  tensor(0.6185, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.1596, -6.0043]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_loss:  tensor(0.5315, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.9137, -6.5591]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 30--------------\n",
      "Training for epoch 30.......\n",
      "train_loss:  tensor(0.5975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4794, -6.6808]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.3309, -5.8175]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.8074605464935303\n",
      ".......Validating for epoch 30\n",
      "dev_loss:  tensor(1.4040, device='cuda:0')\n",
      "dev_logits:  tensor([[-5.5925, -6.7146]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(0.1866, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.0988, -5.5145]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 31--------------\n",
      "Training for epoch 31.......\n",
      "train_loss:  tensor(0.7377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.9452, -5.8580]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-5.6111, -5.0362]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7986893057823181\n",
      ".......Validating for epoch 31\n",
      "dev_loss:  tensor(0.3279, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4549, -6.5082]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_loss:  tensor(0.1608, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3599, -5.6140]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  47.0\n",
      "--------------Epoch: 32--------------\n",
      "Training for epoch 32.......\n",
      "train_loss:  tensor(0.2063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4225, -7.8962]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(2.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.2922, -6.4282]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7506538033485413\n",
      ".......Validating for epoch 32\n",
      "dev_loss:  tensor(1.3502, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.1454, -8.1956]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.7330, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.0753, -6.1536]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  53.0\n",
      "--------------Epoch: 33--------------\n",
      "Training for epoch 33.......\n",
      "train_loss:  tensor(1.8808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8529, -6.1375]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.4839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2131, -7.6873]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.768488347530365\n",
      ".......Validating for epoch 33\n",
      "dev_loss:  tensor(0.5291, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4435, -7.0830]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_loss:  tensor(1.2957, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.9201, -7.8960]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  55.0\n",
      "--------------Epoch: 34--------------\n",
      "Training for epoch 34.......\n",
      "train_loss:  tensor(0.6967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4828, -7.4758]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.0712, -7.2581]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7533155679702759\n",
      ".......Validating for epoch 34\n",
      "dev_loss:  tensor(1.2560, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.0244, -7.9452]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_loss:  tensor(1.3850, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.7306, -7.8275]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  42.0\n",
      "--------------Epoch: 35--------------\n",
      "Training for epoch 35.......\n",
      "train_loss:  tensor(0.9977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.6662, -7.1285]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9946, -6.9523]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7745379209518433\n",
      ".......Validating for epoch 35\n",
      "dev_loss:  tensor(0.6684, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4275, -7.3775]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_loss:  tensor(0.7002, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5611, -7.5751]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 36--------------\n",
      "Training for epoch 36.......\n",
      "train_loss:  tensor(1.5071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9582, -5.7016]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.2667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.7649, -6.8292]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7636578679084778\n",
      ".......Validating for epoch 36\n",
      "dev_loss:  tensor(0.8413, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6554, -7.9326]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_loss:  tensor(0.8966, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.2578, -7.6301]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  38.0\n",
      "--------------Epoch: 37--------------\n",
      "Training for epoch 37.......\n",
      "train_loss:  tensor(0.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4635, -7.9269]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.0642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.0130, -7.3720]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7201663851737976\n",
      ".......Validating for epoch 37\n",
      "dev_loss:  tensor(0.2634, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.9715, -6.7718]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_loss:  tensor(0.5999, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8534, -7.6574]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  46.0\n",
      "--------------Epoch: 38--------------\n",
      "Training for epoch 38.......\n",
      "train_loss:  tensor(0.8941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.7498, -7.3816]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.4279, -6.8270]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7546659111976624\n",
      ".......Validating for epoch 38\n",
      "dev_loss:  tensor(1.3306, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8725, -7.8961]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_loss:  tensor(0.8026, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3090, -7.5170]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  58.0\n",
      "--------------Epoch: 39--------------\n",
      "Training for epoch 39.......\n",
      "train_loss:  tensor(1.2053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.9321, -7.0829]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2668, -7.6150]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7398672103881836\n",
      ".......Validating for epoch 39\n",
      "dev_loss:  tensor(0.2580, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6552, -6.4321]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(0.6073, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8631, -7.6834]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 40--------------\n",
      "Training for epoch 40.......\n",
      "train_loss:  tensor(1.4637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.4488, -7.2482]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.8185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.3017, -7.0651]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7582509517669678\n",
      ".......Validating for epoch 40\n",
      "dev_loss:  tensor(0.3914, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.8587, -7.1226]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  59.0\n",
      "dev_acc[j]:  60.0\n",
      "dev_loss:  tensor(0.6218, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5025, -7.3544]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  61.0\n",
      "--------------Epoch: 41--------------\n",
      "Training for epoch 41.......\n",
      "train_loss:  tensor(0.5279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.1667, -7.5299]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.0527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8726, -7.2491]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7351158857345581\n",
      ".......Validating for epoch 41\n",
      "dev_loss:  tensor(1.2791, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3199, -8.2728]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(0.3222, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7713, -6.8040]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 42--------------\n",
      "Training for epoch 42.......\n",
      "train_loss:  tensor(0.7809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.1110, -7.9426]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.3763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4807, -8.2639]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7270342707633972\n",
      ".......Validating for epoch 42\n",
      "dev_loss:  tensor(0.6131, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.8378, -6.6709]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.8121, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6714, -7.8967]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  53.0\n",
      "--------------Epoch: 43--------------\n",
      "Training for epoch 43.......\n",
      "train_loss:  tensor(0.3751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.7498, -7.5368]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.0196, -7.1470]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7657537460327148\n",
      ".......Validating for epoch 43\n",
      "dev_loss:  tensor(0.5991, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5249, -7.3270]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_loss:  tensor(1.0419, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7947, -8.4014]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  51.0\n",
      "--------------Epoch: 44--------------\n",
      "Training for epoch 44.......\n",
      "train_loss:  tensor(2.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.4341, -6.5539]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.1970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.7690, -8.2934]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.719317615032196\n",
      ".......Validating for epoch 44\n",
      "dev_loss:  tensor(1.1725, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3904, -8.1925]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_loss:  tensor(0.8364, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.7822, -7.0507]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  53.0\n",
      "--------------Epoch: 45--------------\n",
      "Training for epoch 45.......\n",
      "train_loss:  tensor(1.5126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.3936, -7.1299]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.9763, -7.3206]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7310871481895447\n",
      ".......Validating for epoch 45\n",
      "dev_loss:  tensor(0.5935, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4735, -7.2632]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_loss:  tensor(0.4480, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.6018, -7.0312]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  48.0\n",
      "--------------Epoch: 46--------------\n",
      "Training for epoch 46.......\n",
      "train_loss:  tensor(0.4529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2063, -7.7634]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.9507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.9328, -7.4706]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7472051978111267\n",
      ".......Validating for epoch 46\n",
      "dev_loss:  tensor(0.2570, device='cuda:0')\n",
      "dev_logits:  tensor([[-8.5357, -7.3082]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_loss:  tensor(0.6759, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.0697, -7.0349]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  57.0\n",
      "--------------Epoch: 47--------------\n",
      "Training for epoch 47.......\n",
      "train_loss:  tensor(0.7151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.6038, -7.5603]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.9657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.3168, -6.5020]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7424657344818115\n",
      ".......Validating for epoch 47\n",
      "dev_loss:  tensor(0.3832, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.9212, -7.1597]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_loss:  tensor(1.0998, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.7899, -8.4848]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  55.0\n",
      "--------------Epoch: 48--------------\n",
      "Training for epoch 48.......\n",
      "train_loss:  tensor(0.7954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.0142, -7.8191]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4752, -7.7222]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7560969591140747\n",
      ".......Validating for epoch 48\n",
      "dev_loss:  tensor(0.5569, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5056, -7.2115]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(1.2381, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.3725, -8.2683]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 49--------------\n",
      "Training for epoch 49.......\n",
      "train_loss:  tensor(0.3415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.7010, -7.5997]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.4604, -7.7857]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7404201626777649\n",
      ".......Validating for epoch 49\n",
      "dev_loss:  tensor(0.6166, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.5301, -7.3706]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_loss:  tensor(0.9606, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.2078, -7.6861]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  49.0\n",
      "--------------Epoch: 50--------------\n",
      "Training for epoch 50.......\n",
      "train_loss:  tensor(0.5166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.2146, -7.6057]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.2192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.2806, -7.4116]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7624594569206238\n",
      ".......Validating for epoch 50\n",
      "dev_loss:  tensor(0.6064, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.2783, -7.0967]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_loss:  tensor(1.0632, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.9086, -8.5482]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  50.0\n",
      "--------------Epoch: 51--------------\n",
      "Training for epoch 51.......\n",
      "train_loss:  tensor(1.7949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.0139, -6.4007]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.1869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-7.8695, -7.0467]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7553675174713135\n",
      ".......Validating for epoch 51\n",
      "dev_loss:  tensor(0.9036, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.2420, -7.6263]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_loss:  tensor(1.2197, device='cuda:0')\n",
      "dev_logits:  tensor([[-6.9550, -7.8248]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  40.0\n",
      "--------------Epoch: 52--------------\n",
      "Training for epoch 52.......\n",
      "train_loss:  tensor(0.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-6.8961, -7.6535]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(1.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-8.1064, -7.5570]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.739622950553894\n",
      ".......Validating for epoch 52\n",
      "dev_loss:  tensor(0.7588, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4846, -7.6118]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  0.0\n",
      "dev_acc[j]:  1.0\n",
      "dev_acc[j]:  2.0\n",
      "dev_acc[j]:  3.0\n",
      "dev_acc[j]:  4.0\n",
      "dev_acc[j]:  5.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  6.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  7.0\n",
      "dev_acc[j]:  8.0\n",
      "dev_acc[j]:  9.0\n",
      "dev_acc[j]:  10.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  11.0\n",
      "dev_acc[j]:  12.0\n",
      "dev_acc[j]:  13.0\n",
      "dev_acc[j]:  14.0\n",
      "dev_acc[j]:  15.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  16.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  17.0\n",
      "dev_acc[j]:  18.0\n",
      "dev_acc[j]:  19.0\n",
      "dev_acc[j]:  20.0\n",
      "dev_acc[j]:  21.0\n",
      "dev_acc[j]:  22.0\n",
      "dev_acc[j]:  23.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  24.0\n",
      "dev_acc[j]:  25.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  26.0\n",
      "dev_acc[j]:  27.0\n",
      "dev_acc[j]:  28.0\n",
      "dev_acc[j]:  29.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  30.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  31.0\n",
      "dev_acc[j]:  32.0\n",
      "dev_acc[j]:  33.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  34.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  35.0\n",
      "dev_acc[j]:  36.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  37.0\n",
      "dev_acc[j]:  38.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  39.0\n",
      "dev_acc[j]:  40.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  41.0\n",
      "dev_acc[j]:  42.0\n",
      "dev_acc[j]:  43.0\n",
      "dev_acc[j]:  44.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  45.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  46.0\n",
      "dev_acc[j]:  47.0\n",
      "dev_acc[j]:  48.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  49.0\n",
      "dev_acc[j]:  50.0\n",
      "dev_acc[j]:  51.0\n",
      "dev_acc[j]:  52.0\n",
      "dev_acc[j]:  53.0\n",
      "dev_acc[j]:  54.0\n",
      "dev_acc[j]:  55.0\n",
      "dev_acc[j]:  56.0\n",
      "dev_acc[j]:  57.0\n",
      "dev_acc[j]:  58.0\n",
      "dev_acc[j]:  59.0\n",
      "dev_acc[j]:  59.0\n",
      "dev_acc[j]:  60.0\n",
      "dev_loss:  tensor(1.3966, device='cuda:0')\n",
      "dev_logits:  tensor([[-7.4250, -8.5373]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  60.0\n",
      "Training completed in 0:24:17.708705\n"
     ]
    }
   ],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "epochs = 52\n",
    "per_num_epoch = 1\n",
    "\n",
    "# train_acc = np.zeros(epochs)\n",
    "train_loss_by_epoch = np.zeros(epochs)\n",
    "dev_acc = np.zeros(epochs)\n",
    "dev_loss_by_epoch = np.zeros(epochs)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for j in range(epochs):\n",
    "    if j % per_num_epoch == 0:\n",
    "        print('--------------Epoch: ' + str(j+1) + '--------------')\n",
    "    \n",
    "    if j % per_num_epoch == 0:\n",
    "        print(f'Training for epoch {j + 1}.......')\n",
    "    \n",
    "    av_train_loss = 0\n",
    "    # print(\"av_train_loss_original: \", av_train_loss)\n",
    "    model.train()\n",
    "    for i in range(0, dev_raw_data.shape[0] - 100):\n",
    "        # print(\"av_train_loss_track: \", av_train_loss)\n",
    "        prompt = dev_raw_data.iloc[i]['asks-for'] + \". \" + dev_raw_data.iloc[i]['p']\n",
    "        choice0 = dev_raw_data.iloc[i]['a1']\n",
    "        choice1 = dev_raw_data.iloc[i]['a2']\n",
    "        label = torch.tensor(dev_raw_data.iloc[i]['most-plausible-alternative'] - 1).unsqueeze(0).to(device)\n",
    "        # print(\"label is: \", label)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        # encoding = {(prompt+choice0), (prompt+choice1)}\n",
    "        # outputs = model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "        outputs = model(**{k: v.unsqueeze(0) for k,v in encoding.items()}, labels=label)\n",
    "        # print(\"outputs: \", outputs)\n",
    "\n",
    "        train_loss = outputs.loss\n",
    "        train_logits = outputs.logits\n",
    "        av_train_loss += train_loss\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "        if i == 1:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss_by_epoch[j] = av_train_loss / (dev_raw_data.shape[0] - 100)\n",
    "    print(\"av_train_loss: \", train_loss_by_epoch[j])\n",
    "\n",
    "    # validation\n",
    "    # if (j + 1) % per_num_epoch == 0:\n",
    "    #     print(f'.......Validating for epoch {j + 1}')\n",
    "    if (j) % per_num_epoch == 0:\n",
    "        print(f'.......Validating for epoch {j + 1}')\n",
    "        av_dev_loss = 0\n",
    "        # model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(dev_raw_data.shape[0] - 99, dev_raw_data.shape[0]):\n",
    "                # print(\"av_dev_loss_track: \", av_dev_loss)\n",
    "                prompt_val = dev_raw_data.iloc[i]['asks-for'] + \". \" + dev_raw_data.iloc[i]['p']\n",
    "                choice0_val = dev_raw_data.iloc[i]['a1']\n",
    "                choice1_val = dev_raw_data.iloc[i]['a2']\n",
    "                label_val = torch.tensor(dev_raw_data.iloc[i]['most-plausible-alternative'] - 1).unsqueeze(0).to(device)\n",
    "\n",
    "                encoding_val = tokenizer([prompt_val, prompt_val], [choice0_val, choice1_val], return_tensors='pt', padding=True).to(device)\n",
    "                # outputs = model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "                outputs_val = model(**{k: v.unsqueeze(0) for k,v in encoding_val.items()}, labels=label_val)\n",
    "                \n",
    "                dev_loss = outputs_val.loss\n",
    "                dev_logits = outputs_val.logits\n",
    "                av_dev_loss += dev_loss\n",
    "                \n",
    "                if i == dev_raw_data.shape[0] - 99:\n",
    "                    print(\"dev_loss: \", dev_loss)\n",
    "                    print(\"dev_logits: \", dev_logits)\n",
    "                    print(\"label: \", label_val)\n",
    "                if i == dev_raw_data.shape[0] - 1:\n",
    "                    print(\"dev_loss: \", dev_loss)\n",
    "                    print(\"dev_logits: \", dev_logits)\n",
    "                    print(\"label: \", label_val)\n",
    "\n",
    "                #calculate accuracy\n",
    "                y_pred = 1 if outputs_val.logits[0][1] > outputs_val.logits[0][0] else 0\n",
    "                y_pred = torch.tensor(y_pred).unsqueeze(0).to(device)\n",
    "                # print(\"y_pred: \", y_pred)\n",
    "                # print(\"label: \", label)\n",
    "                # print(\"y_pred =? label: \", y_pred == label)\n",
    "                if y_pred == label_val:\n",
    "                    dev_acc[j] += 1\n",
    "                \n",
    "        dev_acc[j] /= 100\n",
    "        print(\"dev_acc[j]: \", dev_acc[j])\n",
    "        dev_loss_by_epoch[j] = av_dev_loss / 100\n",
    "        \n",
    "    # learning rate decay\n",
    "    # if j == 5:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    # elif j == 15:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    # elif j == 20:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    # elif j == 40:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "    # elif j == 50:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-7)    \n",
    "    scheduler.step()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f'Training completed in {str(end_time - start_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Epoch: 1--------------\n",
      "Training for epoch 1.......\n",
      "train_loss:  tensor(0.6814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.1152, 0.0916]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.1619, 0.1128]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7059414982795715\n",
      ".......Validating for epoch 1\n",
      "dev_loss:  tensor(0.6567, device='cuda:0')\n",
      "dev_logits:  tensor([[0.8165, 0.8907]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.6797, device='cuda:0')\n",
      "dev_logits:  tensor([[0.8277, 0.8547]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.51\n",
      "--------------Epoch: 2--------------\n",
      "Training for epoch 2.......\n",
      "train_loss:  tensor(0.6953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.9133, 0.9177]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.9353, 0.8940]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7017775774002075\n",
      ".......Validating for epoch 2\n",
      "dev_loss:  tensor(0.7757, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.6843, -0.8431]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.6973, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.5967, -0.6049]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.57\n",
      "--------------Epoch: 3--------------\n",
      "Training for epoch 3.......\n",
      "train_loss:  tensor(0.6199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-0.5838, -0.7361]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-0.7151, -0.5199]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.704304039478302\n",
      ".......Validating for epoch 3\n",
      "dev_loss:  tensor(0.8463, device='cuda:0')\n",
      "dev_logits:  tensor([[ 0.0346, -0.2513]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.7018, device='cuda:0')\n",
      "dev_logits:  tensor([[0.0385, 0.0212]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.48\n",
      "--------------Epoch: 4--------------\n",
      "Training for epoch 4.......\n",
      "train_loss:  tensor(0.7736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.1478, 0.3026]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.8346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.0193, 0.2846]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7044405937194824\n",
      ".......Validating for epoch 4\n",
      "dev_loss:  tensor(0.7119, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.2213, -0.2584]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.6846, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.0272, -0.0100]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.41\n",
      "--------------Epoch: 5--------------\n",
      "Training for epoch 5.......\n",
      "train_loss:  tensor(0.9391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-0.4865, -0.0432]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.2083, 0.0207]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7065179944038391\n",
      ".......Validating for epoch 5\n",
      "dev_loss:  tensor(0.8110, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.0447, -0.2679]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.7485, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.0210, -0.1288]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.4\n",
      "--------------Epoch: 6--------------\n",
      "Training for epoch 6.......\n",
      "train_loss:  tensor(0.5928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ 0.1228, -0.0891]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-0.2762, -0.2605]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.6981273293495178\n",
      ".......Validating for epoch 6\n",
      "dev_loss:  tensor(0.9141, device='cuda:0')\n",
      "dev_logits:  tensor([[ 0.1371, -0.2646]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.8074, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.0729, -0.2897]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.51\n",
      "--------------Epoch: 7--------------\n",
      "Training for epoch 7.......\n",
      "train_loss:  tensor(0.4764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ 0.1130, -0.3808]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.5368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[ 0.2415, -0.1002]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.6943349242210388\n",
      ".......Validating for epoch 7\n",
      "dev_loss:  tensor(0.5888, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.5386, -0.3177]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.6078, device='cuda:0')\n",
      "dev_logits:  tensor([[-0.7465, -0.5678]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.59\n",
      "--------------Epoch: 8--------------\n",
      "Training for epoch 8.......\n",
      "train_loss:  tensor(0.5756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-0.3736, -0.6244]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-0.5548, -1.0254]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.6941007971763611\n",
      ".......Validating for epoch 8\n",
      "dev_loss:  tensor(0.8277, device='cuda:0')\n",
      "dev_logits:  tensor([[ 0.0238, -0.2294]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.7128, device='cuda:0')\n",
      "dev_logits:  tensor([[ 0.0113, -0.0276]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.58\n",
      "--------------Epoch: 9--------------\n",
      "Training for epoch 9.......\n",
      "train_loss:  tensor(0.8181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.0992, 0.3351]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[-0.2482, -0.1683]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.6832407712936401\n",
      ".......Validating for epoch 9\n",
      "dev_loss:  tensor(0.7770, device='cuda:0')\n",
      "dev_logits:  tensor([[0.6751, 0.5138]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.7856, device='cuda:0')\n",
      "dev_logits:  tensor([[0.5038, 0.3266]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.45\n",
      "--------------Epoch: 10--------------\n",
      "Training for epoch 10.......\n",
      "train_loss:  tensor(0.7562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.6929, 0.8153]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "train_loss:  tensor(0.7449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "train_logits:  tensor([[0.2308, 0.3317]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "label:  tensor([0], device='cuda:0')\n",
      "av_train_loss:  0.7068926692008972\n",
      ".......Validating for epoch 10\n",
      "dev_loss:  tensor(0.6539, device='cuda:0')\n",
      "dev_logits:  tensor([[0.0501, 0.1302]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_loss:  tensor(0.6992, device='cuda:0')\n",
      "dev_logits:  tensor([[0.0915, 0.0794]], device='cuda:0')\n",
      "label:  tensor([1], device='cuda:0')\n",
      "dev_acc[j]:  0.5\n",
      "Training completed in 0:04:51.613199\n"
     ]
    }
   ],
   "source": [
    "# Trial 2\n",
    "ce = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=0)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "epochs = 52\n",
    "per_num_epoch = 1\n",
    "\n",
    "# train_acc = np.zeros(epochs)\n",
    "train_loss_by_epoch = np.zeros(epochs)\n",
    "dev_acc = np.zeros(epochs)\n",
    "dev_loss_by_epoch = np.zeros(epochs)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for j in range(epochs):\n",
    "    if j % per_num_epoch == 0:\n",
    "        print('--------------Epoch: ' + str(j+1) + '--------------')\n",
    "    \n",
    "    if j % per_num_epoch == 0:\n",
    "        print(f'Training for epoch {j + 1}.......')\n",
    "    \n",
    "    av_train_loss = 0\n",
    "    # print(\"av_train_loss_original: \", av_train_loss)\n",
    "    model.train()\n",
    "    for i in range(0, dev_raw_data.shape[0] - 100):\n",
    "        # print(\"av_train_loss_track: \", av_train_loss)\n",
    "        prompt = dev_raw_data.iloc[i]['asks-for'] + \". \" + dev_raw_data.iloc[i]['p']\n",
    "        choice0 = dev_raw_data.iloc[i]['a1']\n",
    "        choice1 = dev_raw_data.iloc[i]['a2']\n",
    "        label = torch.tensor(dev_raw_data.iloc[i]['most-plausible-alternative'] - 1).unsqueeze(0).to(device)\n",
    "        # print(\"label is: \", label)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        # encoding = {(prompt+choice0), (prompt+choice1)}\n",
    "        # outputs = model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "        outputs = model(**{k: v.unsqueeze(0) for k,v in encoding.items()}, labels=label)\n",
    "        # print(\"outputs: \", outputs)\n",
    "\n",
    "        train_loss = outputs.loss\n",
    "        train_logits = outputs.logits\n",
    "        av_train_loss += train_loss\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "        if i == 1:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss_by_epoch[j] = av_train_loss / (dev_raw_data.shape[0] - 100)\n",
    "    print(\"av_train_loss: \", train_loss_by_epoch[j])\n",
    "\n",
    "    # validation\n",
    "    # if (j + 1) % per_num_epoch == 0:\n",
    "    #     print(f'.......Validating for epoch {j + 1}')\n",
    "    if (j) % per_num_epoch == 0:\n",
    "        print(f'.......Validating for epoch {j + 1}')\n",
    "        av_dev_loss = 0\n",
    "        # model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(dev_raw_data.shape[0] - 99, dev_raw_data.shape[0]):\n",
    "                # print(\"av_dev_loss_track: \", av_dev_loss)\n",
    "                prompt_val = dev_raw_data.iloc[i]['asks-for'] + \". \" + dev_raw_data.iloc[i]['p']\n",
    "                choice0_val = dev_raw_data.iloc[i]['a1']\n",
    "                choice1_val = dev_raw_data.iloc[i]['a2']\n",
    "                label_val = torch.tensor(dev_raw_data.iloc[i]['most-plausible-alternative'] - 1).unsqueeze(0).to(device)\n",
    "\n",
    "                encoding_val = tokenizer([prompt_val, prompt_val], [choice0_val, choice1_val], return_tensors='pt', padding=True).to(device)\n",
    "                # outputs = model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "                outputs_val = model(**{k: v.unsqueeze(0) for k,v in encoding_val.items()}, labels=label_val)\n",
    "                \n",
    "                dev_loss = outputs_val.loss\n",
    "                dev_logits = outputs_val.logits\n",
    "                av_dev_loss += dev_loss\n",
    "                \n",
    "                if i == dev_raw_data.shape[0] - 99:\n",
    "                    print(\"dev_loss: \", dev_loss)\n",
    "                    print(\"dev_logits: \", dev_logits)\n",
    "                    print(\"label: \", label_val)\n",
    "                if i == dev_raw_data.shape[0] - 1:\n",
    "                    print(\"dev_loss: \", dev_loss)\n",
    "                    print(\"dev_logits: \", dev_logits)\n",
    "                    print(\"label: \", label_val)\n",
    "\n",
    "                #calculate accuracy\n",
    "                y_pred = 1 if outputs_val.logits[0][1] > outputs_val.logits[0][0] else 0\n",
    "                y_pred = torch.tensor(y_pred).unsqueeze(0).to(device)\n",
    "                # print(\"y_pred: \", y_pred)\n",
    "                # print(\"label: \", label)\n",
    "                # print(\"y_pred =? label: \", y_pred == label)\n",
    "                if y_pred == label_val:\n",
    "                    dev_acc[j] += 1\n",
    "                \n",
    "        dev_acc[j] /= 100\n",
    "        print(\"dev_acc[j]: \", dev_acc[j])\n",
    "        dev_loss_by_epoch[j] = av_dev_loss / 100\n",
    "        \n",
    "    # learning rate decay\n",
    "    # if j == 5:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    # elif j == 15:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    # elif j == 20:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    # elif j == 40:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "    # elif j == 50:\n",
    "    #     optimizer = torch.optim.Adam(model.parameters(), lr=1e-7)    \n",
    "    scheduler.step()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f'Training completed in {str(end_time - start_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title(\"Loss VS Epoch\")\n",
    "\n",
    "plt.plot(train_loss_by_epoch, label=\"train_loss\")\n",
    "plt.plot(dev_loss_by_epoch, label=\"dev_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title(\"acc VS Epoch\")\n",
    "\n",
    "plt.plot(dev_acc, label=\"dev_acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, 'RoBERTa_2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = torch.load('RoBERTa_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "y_pred:  tensor([0], device='cuda:0')\n",
      "label:  tensor([0], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "outputs_test.logits:  tensor([[-7.6294, -7.6294]], device='cuda:0')\n",
      "test_accuracy =  0.5\n"
     ]
    }
   ],
   "source": [
    "# test_model.eval()\n",
    "num_correct_pred = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, test_raw_data.shape[0]):\n",
    "        prompt = test_raw_data.iloc[i]['asks-for'] + \". \" + test_raw_data.iloc[i]['p']\n",
    "        choice0 = test_raw_data.iloc[i]['a1']\n",
    "        choice1 = test_raw_data.iloc[i]['a2']\n",
    "        label_test = torch.tensor(test_raw_data.iloc[i]['most-plausible-alternative'] - 1).unsqueeze(0).to(device)\n",
    "\n",
    "        encoding_test = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        # outputs = test_model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "        outputs_test = test_model(**{k: v.unsqueeze(0) for k,v in encoding_test.items()}, labels=label_test)\n",
    "        print(\"outputs_test.logits: \", outputs_test.logits)\n",
    "        # test_logits = outputs_test.logits\n",
    "\n",
    "        #calculate accuracy\n",
    "        y_pred_test = 1 if outputs_test.logits[0][1] > outputs_test.logits[0][0] else 0\n",
    "        y_pred_test = torch.tensor(y_pred_test).unsqueeze(0).to(device)\n",
    "\n",
    "        if y_pred_test == label_test:\n",
    "            print(\"test_logits: \", outputs_test.logits)\n",
    "            print(\"y_pred: \", y_pred_test)\n",
    "            print(\"label: \", label_test)\n",
    "            num_correct_pred += 1\n",
    "\n",
    "acc = num_correct_pred / test_raw_data.shape[0]\n",
    "print(\"test_accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model.eval()\n",
    "num_correct_pred = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, test_raw_data.shape[0]):\n",
    "        prompt = test_raw_data.iloc[i]['question'] + \". \" + test_raw_data.iloc[i]['premise']\n",
    "        choice0 = test_raw_data.iloc[i]['choice1']\n",
    "        choice1 = test_raw_data.iloc[i]['choice2']\n",
    "        label = torch.tensor(test_raw_data.iloc[i]['label']).unsqueeze(0).to(device)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        outputs = test_model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "\n",
    "        test_logits = outputs.logits\n",
    "\n",
    "        #calculate accuracy\n",
    "        y_pred = 1 if outputs.logits[0][1] > outputs.logits[0][0] else 0\n",
    "        y_pred = torch.tensor(y_pred).unsqueeze(0).to(device)\n",
    "\n",
    "        if y_pred == label:\n",
    "            print(\"test_logits: \", test_logits)\n",
    "            print(\"y_pred: \", y_pred)\n",
    "            print(\"label: \", label)\n",
    "            num_correct_pred += 1\n",
    "\n",
    "acc = num_correct_pred / test_raw_data.shape[0]\n",
    "print(\"test_accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revise\n",
    "# Training\n",
    "ce = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "epochs = 100\n",
    "per_num_epoch = 1\n",
    "\n",
    "# train_acc = np.zeros(epochs)\n",
    "train_loss_by_epoch = np.zeros(epochs)\n",
    "dev_acc = np.zeros(epochs)\n",
    "dev_loss_by_epoch = np.zeros(epochs)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for j in range(epochs):\n",
    "    if j % per_num_epoch == 0:\n",
    "        print('--------------Epoch: ' + str(j+1) + '--------------')\n",
    "    \n",
    "    if j % per_num_epoch == 0:\n",
    "        print(f'Training for epoch {j + 1}.......')\n",
    "    av_train_loss = 0\n",
    "    # print(\"av_train_loss_original: \", av_train_loss)\n",
    "    model.train()\n",
    "    for i in range(0, train_raw_data.shape[0]):\n",
    "        # print(\"av_train_loss_track: \", av_train_loss)\n",
    "        prompt = train_raw_data.iloc[i]['question'] + \". \" + train_raw_data.iloc[i]['premise']\n",
    "        choice0 = train_raw_data.iloc[i]['choice1']\n",
    "        choice1 = train_raw_data.iloc[i]['choice2']\n",
    "        label = torch.tensor(train_raw_data.iloc[i]['label']).unsqueeze(0).to(device)\n",
    "        # print(\"label is: \", label)\n",
    "        # label = torch.tensor(rawdata.iloc[i]['label']).unsqueeze(0).to(device)\n",
    "\n",
    "        encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors='pt', padding=True).to(device)\n",
    "        # outputs = model(input_ids=encoding['input_ids'].unsqueeze(0), attention_mask=encoding['attention_mask'].unsqueeze(0), labels=label)\n",
    "        \n",
    "        outputs = model(**{k: v.unsqueeze(0) for k,v in encoding.items()}, labels=label)\n",
    "        \n",
    "        train_loss = outputs.loss\n",
    "        train_logits = outputs.logits\n",
    "        av_train_loss += train_loss\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "        if i == 1:\n",
    "            print(\"train_loss: \", train_loss)\n",
    "            print(\"train_logits: \", train_logits)\n",
    "            print(\"label: \", label)\n",
    "\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # learning rate decay\n",
    "        if j == 25:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "        elif j == 50:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=1e-7)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss_by_epoch[j] = av_train_loss / train_raw_data.shape[0]\n",
    "    print(\"av_train_loss: \", train_loss_by_epoch[j])\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f'Training completed in {str(end_time - start_time)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "1. Ask about whether the very last output of RoBERTaMultipleChoice is the possibility score for one input embedding.\n",
    "\n",
    "(pooler): RobertaPooler(\n",
    "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "      (activation): Tanh()\n",
    "    )\n",
    "  )\n",
    "  (dropout): Dropout(p=0.1, inplace=False)\n",
    "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
    "\n",
    "\n",
    "2. What's wrong with the model.eval()?\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a411169b02b4f5d985b282c4f140db7a58e4cacae7bbcf8f29fd937be3ae09c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('NLP_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
