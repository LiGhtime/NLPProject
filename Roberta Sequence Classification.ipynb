{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa Pretrained Sequence Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaForMultipleChoice\n",
    "from transformers import RobertaForSequenceClassification, AdamW, get_scheduler\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda' if cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopaDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        \n",
    "        with open(filename, 'r', encoding='utf8') as file:\n",
    "            raw_data = pd.read_json(file, lines=True)\n",
    "        self.data = []\n",
    "        self.masks = []\n",
    "        self.labels = []\n",
    "            \n",
    "        prompts = []\n",
    "        choices = []\n",
    "        for i, row in raw_data.iterrows():\n",
    "            prompts.append(row['premise'])\n",
    "            prompts.append(row['premise'])\n",
    "            choices.append(row['choice1'])\n",
    "            choices.append(row['choice2'])\n",
    "            self.labels.append(row['label'])\n",
    "        \n",
    "        tokenized = self.tokenizer(prompts, choices, return_tensors='pt',\n",
    "                              padding=True, truncation=True)\n",
    "        \n",
    "        for i in range(int(len(tokenized['input_ids']) / 2)):\n",
    "            idx = 2 * i\n",
    "            self.data.append(torch.stack([tokenized['input_ids'][idx], \n",
    "                                          tokenized['input_ids'][idx + 1]]).to(device))\n",
    "            self.masks.append(torch.stack([tokenized['attention_mask'][idx], \n",
    "                                           tokenized['attention_mask'][idx + 1]]).to(device))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def clear(self):\n",
    "        for elt in self.data:\n",
    "            del elt\n",
    "        for elt in self.masks:\n",
    "            del elt\n",
    "        for elt in self.labels:\n",
    "            del elt\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.to_list()\n",
    "        return ([self.data[idx], \n",
    "                 self.masks[idx]]), torch.tensor(self.labels[idx], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded (length 350)\n",
      "Dev data loaded (length 50)\n",
      "Test data loaded (length 100)\n"
     ]
    }
   ],
   "source": [
    "train_data = CopaDataset('data/train.jsonl')\n",
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "print(f'Training data loaded (length {len(train_data)})')\n",
    "dev_data = CopaDataset('data/dev.jsonl')\n",
    "dev_dataloader = DataLoader(dev_data, batch_size=50, shuffle=True)\n",
    "print(f'Dev data loaded (length {len(dev_data)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopaDatasetMoreData(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        \n",
    "        with open(filename, 'r', encoding='utf8') as file:\n",
    "            raw_data = pd.read_xml(file)\n",
    "        self.data = []\n",
    "        self.masks = []\n",
    "        self.labels = []\n",
    "            \n",
    "        prompts = []\n",
    "        choices = []\n",
    "        \n",
    "        for i, row in raw_data.iterrows():\n",
    "            prompts.append(raw_data.iloc[i]['asks-for'] + \". \" + raw_data.iloc[i]['p'])\n",
    "            prompts.append(raw_data.iloc[i]['asks-for'] + \". \" + raw_data.iloc[i]['p'])\n",
    "            choices.append(raw_data.iloc[i]['a1'])\n",
    "            choices.append(raw_data.iloc[i]['a2'])\n",
    "            self.labels.append(raw_data.iloc[i]['most-plausible-alternative'] - 1)\n",
    "        \n",
    "        tokenized = self.tokenizer(prompts, choices, return_tensors='pt',\n",
    "                              padding=True, truncation=True)\n",
    "        \n",
    "        for i in range(int(len(tokenized['input_ids']) / 2)):\n",
    "            idx = 2 * i\n",
    "            self.data.append(torch.stack([tokenized['input_ids'][idx], \n",
    "                                          tokenized['input_ids'][idx + 1]]).to(device))\n",
    "            self.masks.append(torch.stack([tokenized['attention_mask'][idx], \n",
    "                                           tokenized['attention_mask'][idx + 1]]).to(device))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def clear(self):\n",
    "        for elt in self.data:\n",
    "            del elt\n",
    "        for elt in self.masks:\n",
    "            del elt\n",
    "        for elt in self.labels:\n",
    "            del elt\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.to_list()\n",
    "        return ([self.data[idx], \n",
    "                 self.masks[idx]]), torch.tensor(self.labels[idx], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CopaDatasetMoreData('data/COPA-resources/datasets/copa-test.xml')\n",
    "train_dataloader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "dev_data = CopaDatasetMoreData('data/COPA-resources/datasets/copa-dev.xml')\n",
    "dev_dataloader = DataLoader(dev_data, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[    0, 27037,     4,    20,  6880,    21, 20605,    11, 12172, 10438,\n",
      "             4,     2,     2,   243,    21, 14283,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  6880,    21, 20605,    11, 12172, 10438,\n",
      "             4,     2,     2,   243,    21,   650,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 35371,   127, 12189,     4,     2,     2,\n",
      "           100, 29164,    10,  3682, 35672,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 35371,   127, 12189,     4,     2,     2,\n",
      "           100,   303,    10,  4876,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4, 25569,  5110, 25910,     5,   790,     4,     2,\n",
      "             2,   133,  1385,  5110,  9939,    31,     5,   790,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4, 25569,  5110, 25910,     5,   790,     4,     2,\n",
      "             2,   133,  1385,  5110, 14964,   149,     5,  5627,    11,     5,\n",
      "           790,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 11774,  1348,     5,  1424,     4,     2,\n",
      "             2,   133,  8691,  2936,  7869,    49, 22631,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 11774,  1348,     5,  1424,     4,     2,\n",
      "             2,   133,  8691,  2936,  1238,   106,     9, 17070,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   558,    21,  1367,     4,     2,     2,\n",
      "           243,    21,    10,  2317,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   558,    21,  1367,     4,     2,     2,\n",
      "           243,    21,  1035,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,  2075,    66,     9,  1007,     4,\n",
      "             2,     2,  2515,   702,  1649,   268,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,  2075,    66,     9,  1007,     4,\n",
      "             2,     2,  2515,  4262, 17434,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,   685,    69,   317,    11,   516,\n",
      "             4,     2,     2,  9690,    82,  2867,     5,   516,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,   685,    69,   317,    11,   516,\n",
      "             4,     2,     2,  2515,  4425,    66,     9,     5,   516,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,  7756,  3804,    69,  8658,     4,\n",
      "             2,     2,   133,  1928, 13868, 30304,    15,    69,   741,  1452,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,  7756,  3804,    69,  8658,     4,\n",
      "             2,     2,   133,  1928,    98,  6691,    69, 36672,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1971,   702,    49,   478,  2214,     4,\n",
      "             2,     2,   133,  2437,  3741, 11251,   552,     7,     5,   930,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1971,   702,    49,   478,  2214,     4,\n",
      "             2,     2,   133,  2437, 33615, 13165,    11,  7308,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,   770,     7,  3392,    69, 10638,\n",
      "          3254,     4,     2,     2,   133,  1816,  4711,    71,   334,    13,\n",
      "          6848,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,   770,     7,  3392,    69, 10638,\n",
      "          3254,     4,     2,     2,   133,  1816,  1146,     5,  3254,    41,\n",
      "         15162,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   664,  2205,   268,  1299,  8265,     4,\n",
      "             2,     2, 16837,  2205, 20493,   174,   106,    10, 15934,   527,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   664,  2205,   268,  1299,  8265,     4,\n",
      "             2,     2,  1213,     7, 14317, 16377,   119, 37984,    15,     5,\n",
      "          2205,  7051,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   478,    39,   471,     4,     2,\n",
      "             2,   894,   300,   685,    11,   802,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   478,    39,   471,     4,     2,\n",
      "             2,   894,   300,    10, 12752,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1649,    38,   875, 12407,     4,     2,\n",
      "             2,  2387,   827,  1316,    21,  5802,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1649,    38,   875, 12407,     4,     2,\n",
      "             2,   100,  2208,    10,   582,  1693,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,    18,  1047, 11106,    21,   455,\n",
      "             9, 28734,     4,     2,     2,   894, 13908,     5, 28734,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,    18,  1047, 11106,    21,   455,\n",
      "             9, 28734,     4,     2,     2,   894,  1051,    66,    10,  2862,\n",
      "          1047,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 34018,    21,  2677, 19112,  6158,     4,\n",
      "             2,     2,   894,    21,  4924,     7,     5,  2199,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 34018,    21,  2677, 19112,  6158,     4,\n",
      "             2,     2,   894,  4609,    31,     5,  2199,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816, 16617,  1538,     5,  3260,     4,\n",
      "             2,     2,  2515,  3872,  4560,    24,     7,  2864,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816, 16617,  1538,     5,  3260,     4,\n",
      "             2,     2,  2515, 18774,     7,  3116,    24,   159,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 13414,     5,   514,    88,     5,  4049,\n",
      "             4,     2,     2,   133,   514,  2677,   225,  3804,   127, 32351,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 13414,     5,   514,    88,     5,  4049,\n",
      "             4,     2,     2,   133,  4049,  1059,   455,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  2442,  8454,    77,    39,  1441,\n",
      "          5614,  2686,     4,     2,     2,   894,   770,     7,   904,    39,\n",
      "          1441,   323,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  2442,  8454,    77,    39,  1441,\n",
      "          5614,  2686,     4,     2,     2,   894,    21,  2053,    59,    39,\n",
      "          1441,    18,  1617,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  3213,    21,   127,  7684,     4,     2,\n",
      "             2,   100,  1299,  2181,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  3213,    21,   127,  7684,     4,     2,\n",
      "             2,   100, 11224,  1103,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3206,   376,  4102,     4,     2,     2,\n",
      "           133,  3206,    21,  8144,   198,    10, 12431,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3206,   376,  4102,     4,     2,     2,\n",
      "           970,    21,    10,  3187,  3104,    11,     5,  3206,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   891,  1276,     7,  7932,     4,     2,\n",
      "             2,  1213,  2307,  7428,     9,  7594,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   891,  1276,     7,  7932,     4,     2,\n",
      "             2,  1213,  9710,  7345,     5,   936,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,  1276,     7,   422,    13,   285,\n",
      "           558,     4,     2,     2,  2515,  4547,    10,   637,  1044,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,  1276,     7,   422,    13,   285,\n",
      "           558,     4,     2,     2,  2515,  8147,    11,   461,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,  5291,  2569,  1650,    15,    39,\n",
      "          1805,     4,     2,     2,   894,  6515,  3279,  5296,    11,    39,\n",
      "         28441,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,  5291,  2569,  1650,    15,    39,\n",
      "          1805,     4,     2,     2,   894, 11252,    19,    10,   380, 28441,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1294,  1467,     5,  1948,     7,     5,\n",
      "           864,     4,     2,     2,   894,  1179,    39,   865,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1294,  1467,     5,  1948,     7,     5,\n",
      "           864,     4,     2,     2,   894, 40504,   196,   160,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    18,  2473, 36408,     4,     2,\n",
      "             2, 44291,   300,    88,    39,  2473,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    18,  2473, 36408,     4,     2,\n",
      "             2,   894,   342, 37047,    81,    39,  2473,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   869,   351,   292,   426,    11,    10,\n",
      "          3236,     4,     2,     2, 13584,  5254,  1238,    69,     9, 14153,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   869,   351,   292,   426,    11,    10,\n",
      "          3236,     4,     2,     2, 13584,  5254,  1299,  6661,    13,    69,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3254, 17200,    62,     5,  1294,    18,\n",
      "         10743,     4,     2,     2,   894,  2037,     5,  1294, 14153,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3254, 17200,    62,     5,  1294,    18,\n",
      "         10743,     4,     2,     2,   133,  1294,    18,  5274,    58, 17401,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 28115,     7,   912,  1686,     4,     2,\n",
      "             2,   100,   685,   127,  2236,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 28115,     7,   912,  1686,     4,     2,\n",
      "             2,   100,  2075,    66,     9,  8016,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  9214,   689,  3553, 32211,     4,     2,\n",
      "             2,   100,   342,    24,    11,     5, 28562,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  9214,   689,  3553, 32211,     4,     2,\n",
      "             2,   100,  2913,    24,    19,  4136, 10438,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3200, 38040,  4736,     4,     2,     2,\n",
      "           894,    56,  9377,  3977,  9782,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3200, 38040,  4736,     4,     2,     2,\n",
      "           894,   770,    10,   183,   160,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,  5932,    11,     5,  3716,     4,\n",
      "             2,     2,  2515,  2075,    15,     5,  3716,  9124,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,  5932,    11,     5,  3716,     4,\n",
      "             2,     2,  2515,  4262,   160,     5, 12909,   792,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1569,  3308,  1088,    66,     4,     2,\n",
      "             2,   243,    21,  1273,   183,    13,     5,  1569,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1569,  3308,  1088,    66,     4,     2,\n",
      "             2,   133,  1569,   829,  2129,  6173,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   685,  2408,     4,     2,     2,\n",
      "          4763,  8067,   123,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   685,  2408,     4,     2,     2,\n",
      "          4763, 19389,   196,   123,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,    18,  1420,  1059,  3089, 43215,\n",
      "             4,     2,     2,  2515, 39990,    62,    10,  1601,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,    18,  1420,  1059,  3089, 43215,\n",
      "             4,     2,     2,  2515,  7334,    62,    10, 17434,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 20812, 12576, 23840,  1329,   150,  5793,\n",
      "            10,   542, 39943,     4,     2,     2,   133,  2437, 18643,    11,\n",
      "         44434, 16812,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 20812, 12576, 23840,  1329,   150,  5793,\n",
      "            10,   542, 39943,     4,     2,     2,   133,  4285, 41610, 21372,\n",
      "            31,    10,  8419,  2379,  2158,     4,     2,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   685,   127, 11383,     4,     2,     2,\n",
      "          2387,  1441,  1682,   162,  2445,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   685,   127, 11383,     4,     2,     2,\n",
      "          2387,  1441,  2035,    15,    86,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   997,  4506,   749,   770,  1987,     4,\n",
      "             2,     2,  1213,  2226,  1748,  2398,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   997,  4506,   749,   770,  1987,     4,\n",
      "             2,     2,  1213, 12518,    10, 11142,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   362,  8416,  8456,     4,     2,\n",
      "             2,   894,  1059,   385,  4610,  8628,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   362,  8416,  8456,     4,     2,\n",
      "             2,   894,  2075,    10, 11696,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693, 26663,    88,     5, 26711,     4,\n",
      "             2,     2,   133,  2985,     9,     5, 26711,   376,  7082,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693, 26663,    88,     5, 26711,     4,\n",
      "             2,     2,  2515, 26360,    69,  4117,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143, 21654,     5, 14930,     4,     2,\n",
      "             2,   133, 14930, 16270,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143, 21654,     5, 14930,     4,     2,\n",
      "             2,   133, 14930,  8294,   409,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,   252, 11774,  7869,    88,    49,  2303,   929,\n",
      "             4,     2,     2,  1213, 23089, 10074,    49,  3235, 28162,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,   252, 11774,  7869,    88,    49,  2303,   929,\n",
      "             4,     2,     2,  1213,   439,     7,     5,  3062,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   828,    88,     5, 34022,     4,     2,\n",
      "             2,   133, 34022, 26360,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   828,    88,     5, 34022,     4,     2,\n",
      "             2, 27324,  2463, 19932,    66,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,  1308,  1420,  1059, 25247,     4,     2,     2,\n",
      "           100, 14964,    10, 14397, 10873,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,  1308,  1420,  1059, 25247,     4,     2,     2,\n",
      "           100,    56,    10,  4045, 13495,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  3148,     5,  1883,     4,     2,     2,\n",
      "           133,  1883,  1357,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  3148,     5,  1883,     4,     2,     2,\n",
      "           133,  1883,  5930,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4, 18953,  1952,  2143,   438, 14265,     5,   785,\n",
      "             4,     2,     2,   133,   785,    58,  4776,    13,  1318, 15492,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4, 18953,  1952,  2143,   438, 14265,     5,   785,\n",
      "             4,     2,     2,   133,   785,    58, 13918,   149,   920,  4178,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 20463,    10,  4683,    11,     5,  2204,\n",
      "             4,     2,     2,   250, 18292, 38475,    66,     9,     5,  4683,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 20463,    10,  4683,    11,     5,  2204,\n",
      "             4,     2,     2, 44291, 10879,    66,     9,     5,  4683,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  1299,  1177, 24963,     9,    69,\n",
      "          2761,     4,     2,     2, 13584,  2761,    21,  1372,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  1299,  1177, 24963,     9,    69,\n",
      "          2761,     4,     2,     2, 13584,  2761,   300, 18264,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 19932,  3984,    15,   127,  6399,     4,\n",
      "             2,     2,   100,   342,    15,    41,    10, 26404,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 19932,  3984,    15,   127,  6399,     4,\n",
      "             2,     2,   100,  1714,   127,  6399,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1055,   906,  1357,     5,  1055,  5124,\n",
      "             4,     2,     2,   133,  2111, 10593,    39, 14952,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1055,   906,  1357,     5,  1055,  5124,\n",
      "             4,     2,     2,   133,  2111,  4507,    69,   418,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2014,  9613,  7671,    10,  2180,     4,\n",
      "             2,     2,  4763,   851,   123,   464,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2014,  9613,  7671,    10,  2180,     4,\n",
      "             2,     2,   894,  1051,     5,  2180,   409,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   410,  2143, 16670,     7,    39, 30976,\n",
      "          7915,     4,     2,     2,   894,  2039,    39,  1041,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   410,  2143, 16670,     7,    39, 30976,\n",
      "          7915,     4,     2,     2,   243,    21, 17687,    86,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4792,    18,  9535, 12333,    10,  2130,\n",
      "             4,     2,     2,   133,  4792, 24708,  1070,   409,    31,     5,\n",
      "          2130,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4792,    18,  9535, 12333,    10,  2130,\n",
      "             4,     2,     2,   133,  4792,  8294,   149,     5,  2130,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  3907,  7722,    63,  3607,     4,     2,\n",
      "             2,   133,  3607,  1224,  8089,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  3907,  7722,    63,  3607,     4,     2,\n",
      "             2,   133,  3607, 15323,    15,     5,  1255,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,    21,    11,    10,  3834, 17309,\n",
      "         35791,  6711,     4,     2,     2,   894,  1276,     7,   310,    10,\n",
      "          1886,   177,    19,    39,  2761,     4,     2,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,    21,    11,    10,  3834, 17309,\n",
      "         35791,  6711,     4,     2,     2,   894,  1276,     7,   310,    10,\n",
      "          7708,  8018,    15,    39,  2761,     4,     2,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   920,  7311,    14,    37,    56,     7,\n",
      "           213,     7,     5,  8080,     4,     2,     2,  9962,  1150,   851,\n",
      "           123,    10, 18833,     7,  4076,     4,     2,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   920,  7311,    14,    37,    56,     7,\n",
      "           213,     7,     5,  8080,     4,     2,     2,  9962,  1150,  2294,\n",
      "             5,   512,    23,    10,  1123,  1992,     4,     2,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   920, 38073,  3539,   689,    88,     5,\n",
      "          6013,     4,     2,     2,   133,  3539, 34042,    66,     9,     5,\n",
      "          6013,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   920, 38073,  3539,   689,    88,     5,\n",
      "          6013,     4,     2,     2,   133,  3539,  3514,   424,  1567,     5,\n",
      "           689,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,    18,   559,  2728,  1714,     4,\n",
      "             2,     2,  2515, 12012,    69,   537, 23114,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,    18,   559,  2728,  1714,     4,\n",
      "             2,     2,  2515,  4009,    11,    10,  2790,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  8080, 12045,    21,  3741, 29519,     4,\n",
      "             2,     2,   100,  1224,    15,     5,   856, 17527,   594,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  8080, 12045,    21,  3741, 29519,     4,\n",
      "             2,     2,   100, 13414, 15160, 16126,    88,    24,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3670,   300,   160,     5,  2341,     4,\n",
      "             2,     2,   133,  2341,  2035,    23,     5,  1992,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3670,   300,   160,     5,  2341,     4,\n",
      "             2,     2,   133,  2341,  3089,  6537,    63, 16867,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313, 11224,   159,    15,     5, 34257,\n",
      "         39742,     9,     5, 21035,     4,     2,     2,   894,   342,    10,\n",
      "         13236,    15,     5, 21035,     4,     2,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313, 11224,   159,    15,     5, 34257,\n",
      "         39742,     9,     5, 21035,     4,     2,     2,   894, 10497,     5,\n",
      "         21035,  2572,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   964,   685,  2842,     4,     2,     2,\n",
      "          1213,  3776,   349,    97,    18,   138,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   964,   685,  2842,     4,     2,     2,\n",
      "          1213,  1410,     7,   430,  1947,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 24408,  3834, 28770,     5,   138,    18,\n",
      "          1188,     4,     2,     2,  2515,    21,  2277,    31,    69,   737,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 24408,  3834, 28770,     5,   138,    18,\n",
      "          1188,     4,     2,     2,  2515,   439,    15, 21592,   989,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  1415,    23,     5,  6700,     4,     2,\n",
      "             2,   100,  1317,     5,  6700, 10457,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  1415,    23,     5,  6700,     4,     2,\n",
      "             2,   100,   770,     7,  1649,     5,    86,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,  1308,   865, 34270,    62,     4,     2,     2,\n",
      "           100,   875,     5, 14700,    30,   865,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,  1308,   865, 34270,    62,     4,     2,     2,\n",
      "          2387,  1141,     8,    38,   547,  1420,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 29211, 21287,     4,     2,     2,   100,\n",
      "          4209,     5, 29211,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 29211, 21287,     4,     2,     2,   100,\n",
      "         22027,     5, 34310,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   891,  1419,    10,  7792,    13,    41,\n",
      "          3537,     4,     2,     2,   133,   891,  1410,    88,     5,  3537,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   891,  1419,    10,  7792,    13,    41,\n",
      "          3537,     4,     2,     2,   133,   343,  8686,     5,  3537,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  4005,   751,    15,     5, 20609,\n",
      "             4,     2,     2,  2515,   770,     7,  1183,     5, 18820,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  4005,   751,    15,     5, 20609,\n",
      "             4,     2,     2,  2515,   802,    79,   794, 14489,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  5328,    10,   301,   267, 32561,\n",
      "            11,     5,   514,     4,     2,     2,   894,  1705,    75,  6966,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  5328,    10,   301,   267, 32561,\n",
      "            11,     5,   514,     4,     2,     2,   133,   514,    21, 16762,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,   156,    10, 31883,    11,     5,\n",
      "          2136, 10655,     4,     2,     2,  2515, 13908,     5,  3780,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,   156,    10, 31883,    11,     5,\n",
      "          2136, 10655,     4,     2,     2,  2515,   478,     5,   124, 25414,\n",
      "           762,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,  5378, 11290,     7,    69,   964,\n",
      "             4,     2,     2,  2515,   300,    10,  1099,  4978,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,  5378, 11290,     7,    69,   964,\n",
      "             4,     2,     2,  2515,   351,    10,  3096,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 11853,    21, 27891,     4,     2,     2,\n",
      "           243, 13414,  4427,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 11853,    21, 27891,     4,     2,     2,\n",
      "           243,    21,   455,     9, 28292,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693, 10981,   459,  3320,     4,     2,\n",
      "             2,  2515,  4711,     5,   363,    11,    10,  2303,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693, 10981,   459,  3320,     4,     2,\n",
      "             2,  2515, 18774,     7,   278,    69,  8054,  6700,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   342,    15, 29728,     4,     2,\n",
      "             2,   894,  4005,    11,     5, 13686,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   342,    15, 29728,     4,     2,\n",
      "             2,   894,   439,     7,     5,  4105,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2634,  4362,     5,  6680,     4,     2,\n",
      "             2,   133,  2634, 40486,     5,  6680,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2634,  4362,     5,  6680,     4,     2,\n",
      "             2, 43174,    29,  3903,     5,  6680,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   841,    23,     5,   177, 18501,   196,\n",
      "             4,     2,     2,   133,   177,   439,    88,  6120,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   841,    23,     5,   177, 18501,   196,\n",
      "             4,     2,     2,   133,  9585,   156,    10,  1099,   486,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  2867,   127,  4069,    15,     5,  7014,\n",
      "             4,     2,     2,   100,  2572,     5,  7014,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  2867,   127,  4069,    15,     5,  7014,\n",
      "             4,     2,     2,   133,  7014, 16270,   490,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2180, 17757,     4,     2,     2,   133,\n",
      "          1150,  4507,    39,   979,   103,   418,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2180, 17757,     4,     2,     2,   133,\n",
      "          1150,  7249,    39,   979,    18,   865,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1958,    21,  8890,     5, 17139,     4,\n",
      "             2,     2,   100,  4366,     5,  1958,    88,    10, 35481,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1958,    21,  8890,     5, 17139,     4,\n",
      "             2,     2,   100, 23439,   196,     5,  1958,    66,     9,     5,\n",
      "           169,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 17176,  6650, 21775,  1329,    49,  1021,\n",
      "          2726,     4,     2,     2,   133, 17176,   677,  1348,     5,  8373,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 17176,  6650, 21775,  1329,    49,  1021,\n",
      "          2726,     4,     2,     2,   133, 17176,   677,   478,    10,  4605,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,   685,   797,     9,    69,  4806,\n",
      "             4,     2,     2,  2515,   905,   213,     9,     5,  3679, 38493,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,   685,   797,     9,    69,  4806,\n",
      "             4,     2,     2,  2515,  6050,    88,    10,  8146,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  1224,    15,     5,  2378,     4,     2,\n",
      "             2, 25589, 38073,  2500,   127,  3024,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  1224,    15,     5,  2378,     4,     2,\n",
      "             2,   100,  1299,  3035,   935,  1323,    81,   162,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 11641,   268,  1835,     7,     5,  4105,\n",
      "             4,     2,     2,  1213,    58,   385, 30388,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 11641,   268,  1835,     7,     5,  4105,\n",
      "             4,     2,     2,  1213,   794,    10, 14441,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  2468,     5, 15160, 10242,    11,     5,\n",
      "         11824, 30326,     4,     2,     2,   133,   514, 23544,    66,     9,\n",
      "             5, 17465,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  2468,     5, 15160, 10242,    11,     5,\n",
      "         11824, 30326,     4,     2,     2,   133,   514, 11743,  9512,  2500,\n",
      "             5,  1929,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1623,  1299,  2181,    59, 14153,    15,\n",
      "            39,  1141,     4,     2,     2,   894,  1238,    69,     9,  4047,\n",
      "         19415,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1623,  1299,  2181,    59, 14153,    15,\n",
      "            39,  1141,     4,     2,     2,   894, 13901,    39,  4047, 19415,\n",
      "             7,    69,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 16019,    15,     5, 11566,  5278, 24845,\n",
      "             4,     2,     2,   100,  9010,    13,     5, 16019,     7,  3841,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 16019,    15,     5, 11566,  5278, 24845,\n",
      "             4,     2,     2,   100, 19932,   514,    15,     5, 11566,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   920, 13356,    62, 11347,     4,     2,\n",
      "             2,   894,    56,    10, 12808,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   920, 13356,    62, 11347,     4,     2,\n",
      "             2,   894,  7727,     5,  3267,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,   342,    39,  1730,    62,    15,\n",
      "             5,  2103,     4,     2,     2,  9962,  1150,  4005,   159,    23,\n",
      "             5,  2103,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,   342,    39,  1730,    62,    15,\n",
      "             5,  2103,     4,     2,     2,  9962,  1150, 25673,  4075,   123,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,  1308,  1441,  1224,    39,   471,    11,   127,\n",
      "          2698,     4,     2,     2,   100, 15355,    39,   766,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,  1308,  1441,  1224,    39,   471,    11,   127,\n",
      "          2698,     4,     2,     2,   100, 21017,   127,  3701,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   168, 32881,    63,  2286,     4,     2,\n",
      "             2,   133,  2286, 10899,    10, 25507,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   168, 32881,    63,  2286,     4,     2,\n",
      "             2,   133,  2286,  3382,     7,   900,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,    21,   685,    11,     5, 14193,\n",
      "             4,     2,     2,   894,  8050,    10, 10178,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,    21,   685,    11,     5, 14193,\n",
      "             4,     2,     2,   894, 24509,    13,   244,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693, 11252,  5358,     4,     2,     2,\n",
      "          2515,   770,     7,  1532,   141,     7,  2451,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693, 11252,  5358,     4,     2,     2,\n",
      "          2515,   770,     7,  1532,    59,    97, 13426,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    21, 27064,     9,    39, 37966,\n",
      "           254,     4,     2,     2,  9962, 37966,   254,   300,    10,  6174,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    21, 27064,     9,    39, 37966,\n",
      "           254,     4,     2,     2,  9962, 37966,   254,  1006,   628,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  6957, 20739,     4,     2,     2,\n",
      "           894,    21, 40510, 15647,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  6957, 20739,     4,     2,     2,\n",
      "           894,    21,  5679, 22257,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    18,  2549,  1224, 12953,     4,\n",
      "             2,     2,   894,   342, 38317,    11,    24,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    18,  2549,  1224, 12953,     4,\n",
      "             2,     2,   894,   342, 32920,    11,    24,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3025,  1412,    92,   173,     4,     2,\n",
      "             2,  2515, 28024,  9071,   196,    69,   986,   173,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3025,  1412,    92,   173,     4,     2,\n",
      "             2,  2515,  1299,    10,  8579,     9,  7125,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   979,  1410,   409,    31,   184,     4,\n",
      "             2,     2,   894,    21, 16406,    31,     5,   831,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   979,  1410,   409,    31,   184,     4,\n",
      "             2,     2,   894,    21,   164,     7,  1564,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4, 16206,  1064,    66,     9,     5,  1040, 11173,\n",
      "             4,     2,     2,   133, 14169,    58,  2913,    19,  8402,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4, 16206,  1064,    66,     9,     5,  1040, 11173,\n",
      "             4,     2,     2,  4688,  8969, 14774,     5,  1040, 11173,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4382,    11,   127,   790,  2572,   160,\n",
      "             4,     2,     2,   100,  1224,    15,    10,  1109,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4382,    11,   127,   790,  2572,   160,\n",
      "             4,     2,     2,   100, 18821,     5,  9326, 37169,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,   166, 12783,     5, 15950, 28910,     4,     2,\n",
      "             2,   243,  1415, 10222,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,   166, 12783,     5, 15950, 28910,     4,     2,\n",
      "             2,   243,  1415,  1531,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3298,     9, 26639,   880,     7,  3495,\n",
      "             4,     2,     2,   100, 13414,  9050,    88,     5,  3298,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3298,     9, 26639,   880,     7,  3495,\n",
      "             4,     2,     2,   100, 10819,    24,    11,     5, 28562,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    83,  3907,  1064,    15,     5,   476,   516,\n",
      "             4,     2,     2,   133,  4382,    11,     5,  3757,   439,    66,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    83,  3907,  1064,    15,     5,   476,   516,\n",
      "             4,     2,     2,   133,  1914,  6126,  2016,  2372,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  5385,   156,  7557, 17401,  1450,     4,\n",
      "             2,     2,   894, 23809,     5,  2437,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  5385,   156,  7557, 17401,  1450,     4,\n",
      "             2,     2,   894, 22169,     5,  2437,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  3349, 14851,  2185,    19,     5,  7756,\n",
      "             4,     2,     2,   250, 43383,     9, 14711, 13911,  5686,    31,\n",
      "           127,   652,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  3349, 14851,  2185,    19,     5,  7756,\n",
      "             4,     2,     2,   250,  1874,     9,  1925,  4829,    15,   127,\n",
      "          8411,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3539, 19387,    15,     5,  4084,     9,\n",
      "             5,  6013,     4,     2,     2,   243,    21, 11130,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3539, 19387,    15,     5,  4084,     9,\n",
      "             5,  6013,     4,     2,     2,   243,    21,  1462,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    18,  2236, 12020,  9379, 21284,\n",
      "             4,     2,     2,   894,    56,    10,  2569,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    18,  2236, 12020,  9379, 21284,\n",
      "             4,     2,     2,   894,  6602,  7893,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 20276,  4259,  1357,     4,     2,     2,\n",
      "           133, 20276,  2035,    23,     5,  8034,  1929,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 20276,  4259,  1357,     4,     2,     2,\n",
      "           133, 20276,   300,  4889,   227, 11912,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  7044,  4543,  5858,    66,     9,     5,\n",
      "           790,     4,     2,     2,   894, 15005,     7,    39,  1041,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  7044,  4543,  5858,    66,     9,     5,\n",
      "           790,     4,     2,     2,  9962,  1041, 16335,   123,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  8080, 10290,     4,     2,     2,   133,\n",
      "         11471, 41031,  9725,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  8080, 10290,     4,     2,     2,   133,\n",
      "           514, 33013,  2263,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 20830,  4711,   583,    63,  1945,     4,\n",
      "             2,     2,   133,  1945,   342,    10, 19008,    15,     5, 20830,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 20830,  4711,   583,    63,  1945,     4,\n",
      "             2,     2,   133,  1945,  1682,     5, 20830,    15,    10, 32652,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  2037,    39, 12456,     4,     2,\n",
      "             2,   894,  3359,   223,     5, 16322,  3907,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  2037,    39, 12456,     4,     2,\n",
      "             2,   894,  3359,    81,     5,  6327,  8037,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  2039,   127,  6096,    18,  1028,   486,\n",
      "             4,     2,     2,   100,   373,    69,   124,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  2039,   127,  6096,    18,  1028,   486,\n",
      "             4,     2,     2,   100,  1145,    69,    13,  3630,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   284, 10593,     5,  3757,     4,     2,\n",
      "             2, 16837,  2335,  2075,   409,    31,   184,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   284, 10593,     5,  3757,     4,     2,\n",
      "             2, 39891, 17355, 11449,    21,  1716,    31,    49,   184,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   794,   127,  8016,    77,    38, 30345,\n",
      "          9389,     4,     2,     2,   133,  1650,    21, 23141,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   794,   127,  8016,    77,    38, 30345,\n",
      "          9389,     4,     2,     2,  2387,  7050,  1299,  3229,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1321,  4829,    10,  2918,     4,     2,\n",
      "             2,  1213,   770,   357,   447,  1274,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1321,  4829,    10,  2918,     4,     2,\n",
      "             2, 16837,  8850,  1179,    49,  6729,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 17241,    41, 15162, 11637,     4,     2,\n",
      "             2,   250, 39773, 11362,  3820,     5,  4647,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 17241,    41, 15162, 11637,     4,     2,\n",
      "             2,   250,  3279, 37410,  3820,     5,  4647,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  3956,     7,  1656,     4,     2,\n",
      "             2,  2515,  5328,   239,  8872,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  3956,     7,  1656,     4,     2,\n",
      "             2,  2515,   362,   160,    69,  5582,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4, 18120,  1458,   160,     9,     5,  4728,     9,\n",
      "           514,     4,     2,     2,   133,   514, 29693,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4, 18120,  1458,   160,     9,     5,  4728,     9,\n",
      "           514,     4,     2,     2,   100,  2913,     5,  4728,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,   404,   127, 17753,    58,    11,     5, 16937,\n",
      "             4,     2,     2,   100,  5328,  6255,  1536,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,   404,   127, 17753,    58,    11,     5, 16937,\n",
      "             4,     2,     2,   100,  5328, 10317,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  8676,    18,  4795,    21,  1687, 16091,\n",
      "             4,     2,     2,   894,   685,     5,   323,     9,  1983,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  8676,    18,  4795,    21,  1687, 16091,\n",
      "             4,     2,     2,   894,    21,  1238,     9,  3198,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  7632, 36631,  5202,     9,     5,   891,    18,\n",
      "          4921,     4,     2,     2,   133,   891,   300,  5283,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  7632, 36631,  5202,     9,     5,   891,    18,\n",
      "          4921,     4,     2,     2,   133,   891,  1615, 15911,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   745,    21,  3688,     7,     5, 31541,\n",
      "             4,     2,     2,   133, 31541,   770,     5,   745,  9007,   159,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   745,    21,  3688,     7,     5, 31541,\n",
      "             4,     2,     2,   133, 31541,  3162,     5,  1188,     7,  1119,\n",
      "            24,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1392,  6754,  1238,     5,  1816,     9,\n",
      "          9460,     4,     2,     2,   133,   647,  6754,   794,     5,  1816,\n",
      "           342, 12952,    11,    69, 15811,     4,     2,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1392,  6754,  1238,     5,  1816,     9,\n",
      "          9460,     4,     2,     2,   133,   647,  6754,  1147,     5,  1816,\n",
      "           465,     5, 15811,    79,  6640,     4,     2,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   247,  2998,   997,    15,     5, 10935,\n",
      "          4284,     4,     2,     2, 44399,  4733,    58,  1051,    66,     7,\n",
      "          1032,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   247,  2998,   997,    15,     5, 10935,\n",
      "          4284,     4,     2,     2, 44399,  4733,    58, 15427,    19,    49,\n",
      "          1232,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   461, 14817,     5,  4456,  2255,     4,\n",
      "             2,     2,   250, 13069,  2263,  7082,    11,   760,     9,     5,\n",
      "         15695,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   461, 14817,     5,  4456,  2255,     4,\n",
      "             2,     2,   250,   891, 11024, 23297,    11,   760,     9,     5,\n",
      "         15695,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816, 32651,   402,  6574,     4,     2,\n",
      "             2,  2515,   362,     5, 15269,    66,     9,     5, 25413,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816, 32651,   402,  6574,     4,     2,\n",
      "             2,  2515,   314,     5, 15269,    11,     5, 12941,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1895,    21, 16407,   159,     4,     2,\n",
      "             2,   133,  2130, 23307,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1895,    21, 16407,   159,     4,     2,\n",
      "             2,   100, 30683,     7,   120,  1025,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   745,    21,  9593,     4,     2,     2,\n",
      "           133, 20276,  2294, 13838,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   745,    21,  9593,     4,     2,     2,\n",
      "           133,   668,  8054,   439,   160,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1150,  5032,  9663,    39,   979,    18,\n",
      "         37934,     4,     2,     2,   133,  1150,  2162,    39,   979,    10,\n",
      "          4437,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1150,  5032,  9663,    39,   979,    18,\n",
      "         37934,     4,     2,     2,   133,  1150,  5836,    39,   979,    66,\n",
      "             9,     5,   790,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2470,   362,     5, 16745,    62,     7,\n",
      "            69,   558,     4,     2,     2,   133,  2971,   439,   184,    13,\n",
      "             5,   183,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2470,   362,     5, 16745,    62,     7,\n",
      "            69,   558,     4,     2,     2,   133, 20276,    21,    66,     9,\n",
      "           645,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  1059, 26678,    19,    39,  1441,\n",
      "             4,     2,     2,  9962,  1441, 18525,   123,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  1059, 26678,    19,    39,  1441,\n",
      "             4,     2,     2,  9962,  1441,  2162,   123,  4592,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,  4507,    69,   418,     7,     5,\n",
      "          1055,   906,     4,     2,     2,   133,  1055,   906,   851,     5,\n",
      "          1816,    69,   464,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,  4507,    69,   418,     7,     5,\n",
      "          1055,   906,     4,     2,     2,   133,  1055,   906, 18774,     7,\n",
      "           492,     5,  1816,    10, 18245,     4,     2,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,    21,   342,    11,    10, 14298,\n",
      "             4,     2,     2,  2515,    21, 28582,    11,    41,  3213,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,    21,   342,    11,    10, 14298,\n",
      "             4,     2,     2,  2515,  2867,     5,  1098,    11,    10, 28723,\n",
      "          5260,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4, 14047, 10601,     5,   632,  3794,    62,   751,\n",
      "            49,  1611,     4,     2,     2,   133,   247,    21, 16293,  1295,\n",
      "            63,  5201,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4, 14047, 10601,     5,   632,  3794,    62,   751,\n",
      "            49,  1611,     4,     2,     2,   133,   247,    21,  2114,   776,\n",
      "         20802,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   165,   685,     5,  1967,     4,     2,\n",
      "             2,  1213,  5779,    49,   841,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   165,   685,     5,  1967,     4,     2,\n",
      "             2,  1213,  4083,    49,   841,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  1308,  1441,  3273,    66,    14,    38,    56,\n",
      "           689,  4889,    11,   127,  9927,     4,     2,     2,   100,  1299,\n",
      "         17319,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  1308,  1441,  3273,    66,    14,    38,    56,\n",
      "           689,  4889,    11,   127,  9927,     4,     2,     2,   100,  1299,\n",
      "          2602,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,  1447,    39,   750, 10743,     4,\n",
      "             2,     2,   894,  1199,  1503,    11,  1380,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,  1447,    39,   750, 10743,     4,\n",
      "             2,     2,   894, 18774,     7,   892,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3301,   745,  7793,     4,     2,     2,\n",
      "          4688,  8969,   478,     5,   343,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3301,   745,  7793,     4,     2,     2,\n",
      "         41514,  1162,    11,     5,   343,  1130,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,    18,  6096,  2263,    62,    19,\n",
      "           123,     4,     2,     2,   894, 29149,    69,     7,   185,   123,\n",
      "           124,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,    18,  6096,  2263,    62,    19,\n",
      "           123,     4,     2,     2,  2515,  2942,   123,     7,    69,  1041,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,    80,   408, 11586,  1348,   159,     7,\n",
      "         22661,     5,  1011,     4,     2,     2,   133,  1011,  6387,   409,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,    80,   408, 11586,  1348,   159,     7,\n",
      "         22661,     5,  1011,     4,     2,     2, 16837,  3885, 15268,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 13816, 21705,   910,  1253, 10074,     5,\n",
      "         11671,    64,     4,     2,     2,   970,    21, 25081,    11,     5,\n",
      "         11671,    64,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 13816, 21705,   910,  1253, 10074,     5,\n",
      "         11671,    64,     4,     2,     2,   133, 13431,    21,   160,     5,\n",
      "         11671,    64,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,  4406,  4490,     5, 21451,     4,\n",
      "             2,     2,   243,    21,  6162,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,  4406,  4490,     5, 21451,     4,\n",
      "             2,     2,   243,    21, 22018,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1055,   906,  2296,     5,   693,    10,\n",
      "         12173,    13,     5,  3588,     4,     2,     2,  2515,   685,    69,\n",
      "         18245,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1055,   906,  2296,     5,   693,    10,\n",
      "         12173,    13,     5,  3588,     4,     2,     2,   133,  3588,   399,\n",
      "            75,  2564,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 12272,    11,   127,  3024,    21,  1844,\n",
      "             4,     2,     2,   243, 32491,  1335,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 12272,    11,   127,  3024,    21,  1844,\n",
      "             4,     2,     2,   243,   314,    10, 14061,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   829,  7782,  1326,    31,  3670,\n",
      "            15,     5,  2341,     4,     2,     2,   894,    21, 19311,    23,\n",
      "             5,  1255,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   829,  7782,  1326,    31,  3670,\n",
      "            15,     5,  2341,     4,     2,     2,   894,    21,  1686,     7,\n",
      "          1003,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   920,   314,  3977, 29123,    15,     5,\n",
      "          1929,     4,     2,     2, 18348,    29, 38475,     7,     5,  3977,\n",
      "         29123,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   920,   314,  3977, 29123,    15,     5,\n",
      "          1929,     4,     2,     2,   133,   920,   342,     5,  8084,   409,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  4507,    69,  2761,    10, 11576,\n",
      "             4,     2,     2,   133,   693,    18,  2761, 26319,    69,  1420,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  4507,    69,  2761,    10, 11576,\n",
      "             4,     2,     2,   133,   693,    18,  2761,   880,     7,  8930,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   362,    10, 19109,     4,     2,\n",
      "             2,  9962, 14638,    58,  1855, 11251,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   362,    10, 19109,     4,     2,\n",
      "             2,   894,  3915,    59,  1099,  8016,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   891,   314,   419,    13,     5,   311,\n",
      "             4,     2,     2,  1213,  5291,  1703,   198,     5,  8870,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   891,   314,   419,    13,     5,   311,\n",
      "             4,     2,     2,  1213,   300,  9969,     7,     5,  8870,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,  4711,   184,    31,   173,     4,\n",
      "             2,     2, 13584,  3504,  6425,    69,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,  4711,   184,    31,   173,     4,\n",
      "             2,     2, 13584, 37966,   254,  2913,    13,    69,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  1419,     5,  4826,   108,  5265,\n",
      "             4,     2,     2,   894,  2800,    49,  1303,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  1419,     5,  4826,   108,  5265,\n",
      "             4,     2,     2,   894, 16978,   106,    25,  5373,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2701,    18,  1144,    21,  2342, 29414,\n",
      "           137,    39,   819,     4,     2,     2,   894,    56,  1289, 32580,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2701,    18,  1144,    21,  2342, 29414,\n",
      "           137,    39,   819,     4,     2,     2,   894, 16617,  1538,    39,\n",
      "          2301,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,    21,   685,     4,     2,     2,   100,\n",
      "         11590,   127,  1055,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,    21,   685,     4,     2,     2,   100,\n",
      "         21365,    10,  5456,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 23318,  6231, 24433,  3215,    11,     5,\n",
      "          3778,     4,     2,     2,   243,    21, 18804,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 23318,  6231, 24433,  3215,    11,     5,\n",
      "          3778,     4,     2,     2,   243, 39573,  5536,   196,    62,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   512,  2263,   159,     4,     2,     2,\n",
      "           100,  1224,     5, 32026,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   512,  2263,   159,     4,     2,     2,\n",
      "           133,  3819, 27169,  1070,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,  2581,    39,   124,     4,     2,\n",
      "             2,   894,   439,     7,   192,    10, 27321,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,  2581,    39,   124,     4,     2,\n",
      "             2,   894,  4711,    11,  3267,    13,   484,   360,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   554,    10,   668,    11,     5, 24672,\n",
      "             4,     2,     2,   100,    21,    66,     9,   668,  1845,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   554,    10,   668,    11,     5, 24672,\n",
      "             4,     2,     2,   243,    21,  2569,    11,     5,   790,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  2294,  1236, 24096,     4,     2,\n",
      "             2,  2515,   300,    10,  3977,  3914,    11,    69,   526,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  2294,  1236, 24096,     4,     2,\n",
      "             2,  2515,   300,    10,   200,  2508,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  6536,    15,   127,  8523,    18,  1883,\n",
      "             4,     2,     2,  2387,  8523,  4036,   162,    11,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  6536,    15,   127,  8523,    18,  1883,\n",
      "             4,     2,     2,  2387,  8523,   314,    69,   790,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693, 44931,    19,  8413,     4,     2,\n",
      "             2, 13584,  1623, 32085,    69,  1379,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693, 44931,    19,  8413,     4,     2,\n",
      "             2, 13584,  1623, 27046,    69, 15364,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3254,  7034,  6228,     5,  1294,     4,\n",
      "             2,     2,   133,  1294,  7173,     5,   864, 12461,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3254,  7034,  6228,     5,  1294,     4,\n",
      "             2,     2,   133,  1294, 40591,     7,  1948,     5,   864,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,  2075,    66,     9,  7689,     4,\n",
      "             2,     2,  2515,   439,     7,     5,  3380,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,  2075,    66,     9,  7689,     4,\n",
      "             2,     2,  2515,   439,     7,     5, 12647,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 13590,    41,   793,  1441,     4,     2,\n",
      "             2,   100,  1487,    10,  3556,     7,   123,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 13590,    41,   793,  1441,     4,     2,\n",
      "             2,   100,   851,   123,    10, 16531,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  9710,   164,    11,     5,  8037,\n",
      "             4,     2,     2,  2515,  2037,    10,  3539,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  9710,   164,    11,     5,  8037,\n",
      "             4,     2,     2,   243,  1415, 16194,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1294,  2035,     7,  1380, 30441,  7727,\n",
      "             4,     2,     2,  9962, 16676,    21,  3187,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1294,  2035,     7,  1380, 30441,  7727,\n",
      "             4,     2,     2,  9962,  4806,    21,  3579,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 45483,    15,     5,  3034,  2441,  1410,\n",
      "             4,     2,     2,   133,  3018, 28551,     5, 18292,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 45483,    15,     5,  3034,  2441,  1410,\n",
      "             4,     2,     2,   133,  3018,  9679,     5, 18292,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1393,   362,    10,  6769,  2126,     4,\n",
      "             2,     2,  4688,  3213,  2756,    15,     5,  1049,   921,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1393,   362,    10,  6769,  2126,     4,\n",
      "             2,     2,  2515,  1432,     5,  2484,    11,   760,     9,    69,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 10601,     5,  7727, 37919,    15,     5,\n",
      "          6185,  5418,  1902,     4,     2,     2,   133, 37919, 16380,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 10601,     5,  7727, 37919,    15,     5,\n",
      "          6185,  5418,  1902,     4,     2,     2,   133, 37919, 31789,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,   342,    15,    69, 16578,     4,\n",
      "             2,     2,   133, 20843,    21,  4520,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,   342,    15,    69, 16578,     4,\n",
      "             2,     2,  2515, 12395,    10, 11148,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313, 44556,    23,     5,   363,  6360,\n",
      "             4,     2,     2,   894, 14594,    24,    58,  1035,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313, 44556,    23,     5,   363,  6360,\n",
      "             4,     2,     2,   894,   802,    24,    21,  2721,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  1299, 17067,     4,     2,     2,   100,\n",
      "           439,     7,  3267,   419,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  1299, 17067,     4,     2,     2,   100,\n",
      "          4711,    62,    70,   363,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   439,     7,     5,  2003,  1943,\n",
      "             4,     2,     2,   894,    21,  1197,    66,    39,  2549,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   439,     7,     5,  2003,  1943,\n",
      "             4,     2,     2,  9962,  2549,    21,   562,   251,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,   702,  1266, 15154,    15,    39,\n",
      "            92, 27862,     4,     2,     2,   133,  2143,  5340,     5,    92,\n",
      "         27862,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,   702,  1266, 15154,    15,    39,\n",
      "            92, 27862,     4,     2,     2,   133,  2143, 40891,     5,    92,\n",
      "         27862,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 19656,  5202,    10,  4049,     9,  5803,\n",
      "             4,     2,     2,   100,    21,  4441, 15269,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 19656,  5202,    10,  4049,     9,  5803,\n",
      "             4,     2,     2,   100,    21, 14814,  8084,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    85,   880,     7,  1895,     4,     2,     2,\n",
      "           133,  1393,  1224,    15,     5, 30427,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    85,   880,     7,  1895,     4,     2,     2,\n",
      "           133,  1393,  9679,     5,   512,    88,  7213,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2932,   319,     9,     5,   745,    21,\n",
      "          5802,     4,     2,     2,   100,  9181,   420,     5,  2014,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2932,   319,     9,     5,   745,    21,\n",
      "          5802,     4,     2,     2,   100,  9181,   583,     5,  7266,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3331,  2039,    69,  4267,    13,     5,\n",
      "          2479, 13127,     4,     2,     2,  2515,    56,  3331,    18,  1803,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3331,  2039,    69,  4267,    13,     5,\n",
      "          2479, 13127,     4,     2,     2,  2515, 13366,     5,  2479,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  6754, 10601,    62,    15,   162,     4,\n",
      "             2,     2,   100,   553,     7,  1994,     7,    10, 13759,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  6754, 10601,    62,    15,   162,     4,\n",
      "             2,     2,   100,  1286,   127, 10614,   346,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2508, 10879,   149,     5,   490,  2931,\n",
      "             4,     2,     2,   133,  1883, 11312, 18780,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2508, 10879,   149,     5,   490,  2931,\n",
      "             4,     2,     2,   133, 31947,  1481,  7027,  3215,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  4382,    11,   127,   790,  2572,   160,\n",
      "             4,     2,     2,   100,   542, 33142,  4462,     5, 24272,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  4382,    11,   127,   790,  2572,   160,\n",
      "             4,     2,     2,   100, 10879,    10, 38689,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2408,   462, 33211, 39204,  5357,     4,\n",
      "             2,     2,   894, 18634,   196,    39, 14357,    11,     5,  9807,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2408,   462, 33211, 39204,  5357,     4,\n",
      "             2,     2,   894,  4639,     5,  2003,    81,    39,   471,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1294,  1381,     7,   109,     5, 10638,\n",
      "            11,    39,   471,     4,     2,     2,   894,   300,    66,    10,\n",
      "         37024,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1294,  1381,     7,   109,     5, 10638,\n",
      "            11,    39,   471,     4,     2,     2,   894,   300, 10985,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1928,  1064, 15028,     4,     2,     2,\n",
      "           133,  1150,  1714,     5,  1928,    18, 36672,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1928,  1064, 15028,     4,     2,     2,\n",
      "           133,  1150, 18399, 14311,     5,  1928,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,  4021,     5,   514, 14930,    23,\n",
      "             5,  2143,     4,     2,     2,   133,  2143,   300,    10, 12752,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,  4021,     5,   514, 14930,    23,\n",
      "             5,  2143,     4,     2,     2,   133,  2143,   300, 29365,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  9463, 18774,     7,   304,     5,  7462,\n",
      "            15,     5,  2280,     4,     2,     2,   133,  2356,  1224,    66,\n",
      "         40427,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  9463, 18774,     7,   304,     5,  7462,\n",
      "            15,     5,  2280,     4,     2,     2, 11243,    11,     5,  2356,\n",
      "          3179,     7,  6675,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  1981,     5, 10021,     7,     5,  4115,\n",
      "           537,     4,     2,     2,   100,    21, 20100,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  1981,     5, 10021,     7,     5,  4115,\n",
      "           537,     4,     2,     2,   100,    21,    66,     9,  1139,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 25316,     4,     2,     2,   100,  1299,\n",
      "         20425,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 25316,     4,     2,     2,   100,    21,\n",
      "          8265,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 21654,     5, 14324, 36499,     4,     2,\n",
      "             2,   243, 29365,    62,   514,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 21654,     5, 14324, 36499,     4,     2,\n",
      "             2, 25589,   842,  2462,   196,    66,     9,    24,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  7196,   268,   362,    10, 15169,     7,\n",
      "             5,  5753,     4,     2,     2,   133,  5753,    21,  7512,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  7196,   268,   362,    10, 15169,     7,\n",
      "             5,  5753,     4,     2,     2,   133,  5753,    21,    15,    41,\n",
      "          2946,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  7044,   300,    10, 12904,     4,     2,\n",
      "             2,  2515,    21,  6023,     9, 25775,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  7044,   300,    10, 12904,     4,     2,\n",
      "             2,  2515,   770,     7,  8829,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,   660, 21942,   512,  9181,   751,   127,   790,\n",
      "             4,     2,     2,   100,  1059,  7775,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,   660, 21942,   512,  9181,   751,   127,   790,\n",
      "             4,     2,     2,   100,   373,     5,   249,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1837,  1224,  1003,    11,     4,     2,\n",
      "             2,   133,  1283, 23316,   123,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1837,  1224,  1003,    11,     4,     2,\n",
      "             2,   970,    21,   117,  1283,   136,   123,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 42287,  2459,   594,   313,  1276,     7,\n",
      "          2217,  2408,     4,     2,     2,   894,   847,    66, 29842,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 42287,  2459,   594,   313,  1276,     7,\n",
      "          2217,  2408,     4,     2,     2,   894,  9710, 26604,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,  4425,    15,     5,  2480,     4,\n",
      "             2,     2,  2515, 13763,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,  4425,    15,     5,  2480,     4,\n",
      "             2,     2,  2515,  1481, 35158,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,    56, 11987,   223,    69,  2473,\n",
      "             4,     2,     2,  2515,  4711,    62,    70,   363,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,    56, 11987,   223,    69,  2473,\n",
      "             4,     2,     2,  2515,   342,    69,   979,     7,  3267,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,   226,  8604, 28601,    31,     5, 17321,     4,\n",
      "             2,     2,   133, 17321, 11376,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,   226,  8604, 28601,    31,     5, 17321,     4,\n",
      "             2,     2,   133, 17321,    21, 32434,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,   342,    69,  5582,    15,     4,\n",
      "             2,     2,  2515,  1467,   961,    23,     5,   537,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,   342,    69,  5582,    15,     4,\n",
      "             2,     2,  2515,   770,     7,   989,     5,   537,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  1199,     5,  5831,  3983,  6157, 22012,\n",
      "             4,     2,     2,  2515,   905,   162,  1323,   149,     5,  5831,\n",
      "          3983,  6157,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  1199,     5,  5831,  3983,  6157, 22012,\n",
      "             4,     2,     2,  2515,  5624,   162,    23,     5,  5831,  3983,\n",
      "          6157,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1031,   439, 19117,     4,     2,     2,\n",
      "           894,  1088,    39,   138,   388,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1031,   439, 19117,     4,     2,     2,\n",
      "           894,  9316,   463,  3215,    39, 13016,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   439,     7,     5,  3299,     4,\n",
      "             2,     2,   133,  3299,    21,    15,   989,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   439,     7,     5,  3299,     4,\n",
      "             2,     2,   133,   313,  1299,  4812,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 17469,   127,  8140,   149,     5,  2931,\n",
      "             4,     2,     2,   133,   790,    21,    15,   668,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 17469,   127,  8140,   149,     5,  2931,\n",
      "             4,     2,     2,   133,   790,    21,  5802,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,    18, 10802,  1059,  3349,   879,\n",
      "           219,     4,     2,     2,   894,   362,    10,   251,  9310,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,    18, 10802,  1059,  3349,   879,\n",
      "           219,     4,     2,     2,   894, 16619, 16375,    39,  1420,    19,\n",
      "         13938,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 28757,    66,     5,  5803,     4,     2,\n",
      "             2,   133,  5803, 29143, 16933,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 28757,    66,     5,  5803,     4,     2,\n",
      "             2,  2387,  6085,    21,  3841,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  2039,     5,  2353,     4,     2,     2,\n",
      "           100,    21,   419,     7,   173,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  2039,     5,  2353,     4,     2,     2,\n",
      "           100,    21,   628,     7,   173,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2484, 15268,    19,     5,   512,     4,\n",
      "             2,     2,   133,  2484, 24101,    62,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2484, 15268,    19,     5,   512,     4,\n",
      "             2,     2,   133,   512,   300, 13263,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   165, 27344,     5,  3096,    11,    49,\n",
      "          4402,     4,     2,     2,  1213,   351,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   165, 27344,     5,  3096,    11,    49,\n",
      "          4402,     4,     2,     2,  1213,  1882,    66,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 18833,  7304,    39, 28308,     4,     2,\n",
      "             2,   100,  1224,    81,     5,  7304,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 18833,  7304,    39, 28308,     4,     2,\n",
      "             2,   100, 22027,   160,     5,  2927,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,    21,  5930,    66,     9,    39,\n",
      "           790,     4,     2,     2,   894, 38475,    11,   149,    41,   490,\n",
      "          2931,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,    21,  5930,    66,     9,    39,\n",
      "           790,     4,     2,     2,   894,  7334,    62,     7,     5,  5645,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1883, 11312, 18780,     4,     2,     2,\n",
      "           133, 13338, 14681,     5,  7956,   254,    15,     5,  1883,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1883, 11312, 18780,     4,     2,     2,\n",
      "           133,   693,  3723,  3215,   149,     5,   762, 11616,    11,     5,\n",
      "          1883,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313, 31789,    39,  3235,     4,     2,\n",
      "             2,   894,   300,    24,  3841,    12, 16008, 22597,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313, 31789,    39,  3235,     4,     2,\n",
      "             2,   894, 10601,    24,    11,    39, 16198,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816, 21654,     5, 16875,     9, 13495,\n",
      "         34156,     4,     2,     2,   133, 13495, 34156,  9316, 31137,    66,\n",
      "             9,     5, 16875,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816, 21654,     5, 16875,     9, 13495,\n",
      "         34156,     4,     2,     2,   133,  1816, 28757,    66,     5, 13495,\n",
      "         34156,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  5280,   811,  3257,    31,     5,   997, 11157,\n",
      "             4,     2,     2, 35625,  1594,  1952, 10899,    10,  2790,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  5280,   811,  3257,    31,     5,   997, 11157,\n",
      "             4,     2,     2, 35625,  1594,  1952,   547,    10,  6767,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,  1423, 22697,     5, 21041,    66,\n",
      "             9,    69,  2549,     4,     2,     2,  2515,  3016,     5, 21041,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,  1423, 22697,     5, 21041,    66,\n",
      "             9,    69,  2549,     4,     2,     2,   133, 21041,  1415,  1928,\n",
      "          1173,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   300,  4136,  3012,     4,     2,\n",
      "             2,   894,  5180,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   300,  4136,  3012,     4,     2,\n",
      "             2,   894,  1415,  3240,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    83,  1928,  5884,  4373,    31,     5,  8380,\n",
      "             4,     2,     2,   133,  8380, 35391,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    83,  1928,  5884,  4373,    31,     5,  8380,\n",
      "             4,     2,     2,   100, 16212,     5,  8380,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 16796, 35365,     4,     2,     2,   894,\n",
      "           962,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 16796, 35365,     4,     2,     2,   894,\n",
      "          5303,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   685,    39,  2394,    15,     5,\n",
      "         16348,     4,     2,     2,   894,  7334,    62,     5, 16348,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   685,    39,  2394,    15,     5,\n",
      "         16348,     4,     2,     2,   894,  1064,   160,     5, 16348,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   920, 12601,  9700,     4,     2,     2,\n",
      "           894,   362,    10,  3514,  1023,     9, 18833,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   920, 12601,  9700,     4,     2,     2,\n",
      "           894,  1357,     5, 18833,    64,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    83,  2569,  2479,   376,    11,   149,     5,\n",
      "          2931,     4,     2,     2,   100, 11956,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    83,  2569,  2479,   376,    11,   149,     5,\n",
      "          2931,     4,     2,     2,   100,  1481, 35158,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1294,   829,    10, 10560,     7,   213,\n",
      "             7,  1564,     4,     2,     2, 13584, 18295,  9132,    69,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1294,   829,    10, 10560,     7,   213,\n",
      "             7,  1564,     4,     2,     2,  2515,   156,   205, 11165,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816, 32529,  1531,    23,     5,  2143,\n",
      "             4,     2,     2,  2515,  3033,   220,  1883,     7,   123,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816, 32529,  1531,    23,     5,  2143,\n",
      "             4,     2,     2,  2515,    56,    10, 18229,    15,   123,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 11130, 32447,  6618,  8268,   689,     4,\n",
      "             2,     2,   894,  5853,  4560, 31373,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 11130, 32447,  6618,  8268,   689,     4,\n",
      "             2,     2,   894,    56,   117,   418,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   373,   127,  1441,     7,  7359,     4,\n",
      "             2,     2,   100,   770,  4144,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   373,   127,  1441,     7,  7359,     4,\n",
      "             2,     2,   100,  1299, 20100,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,  3112,    39,   865,     7,   162,\n",
      "             4,     2,     2,   100, 14774,    39,   865,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,  3112,    39,   865,     7,   162,\n",
      "             4,     2,     2,   100, 18361,   123,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   385, 23289,     4,     2,     2,   133,\n",
      "         10756,  1660,    62,    11,     5,   935,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   385, 23289,     4,     2,     2,   133,\n",
      "          6664,   354, 14650, 14622,  1567,   127,   471,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,   828,    69, 20941,     4,     2,\n",
      "             2,  2515,    21,  3915,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,   828,    69, 20941,     4,     2,\n",
      "             2,  2515,    21,  3911,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  1224,     5,  1842,    15,     5,  7127,\n",
      "             4,     2,     2,   100,  4760,    41,  4916,    15,     5,  7127,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  1224,     5,  1842,    15,     5,  7127,\n",
      "             4,     2,     2,   243,    21,     5,  1786,     9,    10,    92,\n",
      "           353,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1623,  2967,    14,    39,  1141,    21,\n",
      "           519,    41,  7226,     4,     2,     2,   894,  2277,    39,  2470,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1623,  2967,    14,    39,  1141,    21,\n",
      "           519,    41,  7226,     4,     2,     2,   894,  1658,    13,  7402,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,  1882,     5, 11283,  1011,     4,\n",
      "             2,     2,   133,  1011, 12407,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,  1882,     5, 11283,  1011,     4,\n",
      "             2,     2,   133,  1011,  5921,  9725,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,   156,    10,  5021,    15,    69,\n",
      "         10743,     4,     2,     2,  2515, 28286,    23,     5,  1948,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,   156,    10,  5021,    15,    69,\n",
      "         10743,     4,     2,     2,  2515, 23717,    69,  1948,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   869, 19737,    39,  5254,     4,     2,\n",
      "             2,  9962,  5254,  2037,     5,  1323,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   869, 19737,    39,  5254,     4,     2,\n",
      "             2,  9962,  5254,   478,     5,  1255,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  2738,     5, 18553,    31,     5, 20151,\n",
      "             4,     2,     2,  1213,    58, 23318,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  2738,     5, 18553,    31,     5, 20151,\n",
      "             4,     2,     2,   100, 36408,   106,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   770,     7,  1760,  8728,     4,\n",
      "             2,     2,   894,  1145,    39,  1931,    12, 22943,    13,  4592,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   770,     7,  1760,  8728,     4,\n",
      "             2,     2,   894,  2162,    39,  6096,  1855, 23558,  1626,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 25755,    11,     5, 26898, 12687,  1458,\n",
      "             4,     2,     2,   100,  1882,     5, 26898, 12687,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 25755,    11,     5, 26898, 12687,  1458,\n",
      "             4,     2,     2,   133,  1650,   300, 13933,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    83, 17271,   376,   149,     5,  1139,     4,\n",
      "             2,     2,   133,  5645,     9,     5, 15695, 10879,   160,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    83, 17271,   376,   149,     5,  1139,     4,\n",
      "             2,     2,   133,  6418,  1059, 24631, 20023,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1294,   829, 15511,  5137,     4,     2,\n",
      "             2,  9962, 11165,  2782,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1294,   829, 15511,  5137,     4,     2,\n",
      "             2,   894, 25177,    15,     5, 10743,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  1299,  3473,     4,     2,     2,   100,\n",
      "         25619, 13587,   159,    15,     5,  1255,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  1299,  3473,     4,     2,     2,   100,\n",
      "          8144,  2185,    11,    10, 14165,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 23520,     5,  7326,     4,     2,     2,\n",
      "           243,  1059, 25645,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 23520,     5,  7326,     4,     2,     2,\n",
      "           243,  1059, 21199,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   355,  4696,     7,     5,  3895,     4,\n",
      "             2,     2,   133,  3895, 32651,   670,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   355,  4696,     7,     5,  3895,     4,\n",
      "             2,     2,   133,  3895, 29143,  4045,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313, 30573,  1329,   149,     5,  6665,\n",
      "             4,     2,     2,   894,   300,    10,  2225,   847,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313, 30573,  1329,   149,     5,  6665,\n",
      "             4,     2,     2,   894, 30274,     5,  6665,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 31101,     5, 13517,    19,     5, 13547,\n",
      "             4,     2,     2,   133, 13517, 21168,    88,     5,  5627,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 31101,     5, 13517,    19,     5, 13547,\n",
      "             4,     2,     2,   133, 13517,  1059, 36069,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  3539,   828,     5,   516,     4,     2,\n",
      "             2,   133, 28783,   769, 13587,    11,     5,  3539,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  3539,   828,     5,   516,     4,     2,\n",
      "             2,   133, 28783,  3872,  1988,     5,   516,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  7044,    21, 17319,     7,   213,     7,\n",
      "           334,     4,     2,     2,  2515,   300,    10, 39148,  8293,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  7044,    21, 17319,     7,   213,     7,\n",
      "           334,     4,     2,     2,  2515,   300,    69, 37706,   160,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,  1308, 11560,  8151,  6474,    62,     4,     2,\n",
      "             2,   100,   829,   205,   340,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,  1308, 11560,  8151,  6474,    62,     4,     2,\n",
      "             2,   100,   685,   127, 11383,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 16492,   127,  1420,    19,    10, 21342,\n",
      "             4,     2,     2,   133, 21342,    21,  7727,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 16492,   127,  1420,    19,    10, 21342,\n",
      "             4,     2,     2,  2387,  1420,    58,  7727,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   685,    39,  2394,    15,     5,\n",
      "         35264,     4,     2,     2,   133, 35264, 33346, 10288, 12213,   123,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   685,    39,  2394,    15,     5,\n",
      "         35264,     4,     2,     2,   894, 19932,  6345,    15,     5, 35264,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  5633,  3660,  4887,    23,   349,    97,\n",
      "             4,     2,     2,  1213,   685,    49,   177,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  5633,  3660,  4887,    23,   349,    97,\n",
      "             4,     2,     2, 16837,   704,  8102,  1524,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   553,    13, 21473,     4,     2,     2,\n",
      "           100, 27611,   127,  5021,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   553,    13, 21473,     4,     2,     2,\n",
      "           100,  4824,   127,   724,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  1059, 23809,    19,    69,  1248,\n",
      "             4,     2,     2,   894,   553,    69,  1142,    59,  2864,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  1059, 23809,    19,    69,  1248,\n",
      "             4,     2,     2,   894,  3244, 32772, 12106,    59,  1003,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816, 23116,    10,  6675,     4,     2,\n",
      "             2, 13584, 32040, 39275,  4490,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816, 23116,    10,  6675,     4,     2,\n",
      "             2, 13584, 14548, 12349,   969,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  8636,  3627, 10879,    62,     4,     2,\n",
      "             2,   243,  1595,    81,     5,  4318,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  8636,  3627, 10879,    62,     4,     2,\n",
      "             2,   243, 24318,    88,     5, 19655,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313, 15760,  4075,    39,  2767,     4,\n",
      "             2,     2,   894,  3203,    88,    10,   181, 20885,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313, 15760,  4075,    39,  2767,     4,\n",
      "             2,     2,   894,  4425,    15,  3187,  4049,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 10412,   385, 15876,     5,  1846,  1310,\n",
      "            13, 28113,     4,     2,     2,  1213,  2967,     5,  3599,     9,\n",
      "             5, 28051,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 10412,   385, 15876,     5,  1846,  1310,\n",
      "            13, 28113,     4,     2,     2,  1213,   303,     5,  4876,    23,\n",
      "             5,  1846,  1310,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,   345,    21,    10,   319,     9,  1703,    15,\n",
      "             5,  6418,     4,     2,     2,   100,   362,    10,  6769,  2126,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,   345,    21,    10,   319,     9,  1703,    15,\n",
      "             5,  6418,     4,     2,     2,   100,   553,    13,    10,  3068,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1226,    18,   866,  1981,     4,     2,\n",
      "             2, 10787,    82,   300,  4736,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1226,    18,   866,  1981,     4,     2,\n",
      "             2, 10787,    82,  2713,  5755,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  6724,  2510, 10879,    69, 16867,    23,\n",
      "             5,   408,     4,     2,     2,  1213,    58,    59,     7,  1656,\n",
      "            88,    15,  7936,  1703,     4,     2,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  6724,  2510, 10879,    69, 16867,    23,\n",
      "             5,   408,     4,     2,     2,  2515,  4984,   106,    31,    69,\n",
      "          3757,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  6387,   127,  2473,    23,   127,  1441,\n",
      "             4,     2,     2,   894,   174,   162,     5,  3157,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  6387,   127,  2473,    23,   127,  1441,\n",
      "             4,     2,     2,   894,   156,    10, 39580, 17680,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   512,  2075,    66,     9,  1123,     4,\n",
      "             2,     2,   133,  1393,    21, 13202,    15,     5,   921,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   512,  2075,    66,     9,  1123,     4,\n",
      "             2,     2,   133,  1393,  2738,    62,    10, 30601,   298, 17625,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,   439,    88,  4178,     4,     2,\n",
      "             2,   133,  1928,    21,  2781,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,   439,    88,  4178,     4,     2,\n",
      "             2,   133,   693,    56,   662, 25231,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    18,  3988, 10879,   409,     4,\n",
      "             2,     2,   894,   362,   160,     5,  3988,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    18,  3988, 10879,   409,     4,\n",
      "             2,     2,   243,    21,  2508,   219,   751,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,  2922,    69, 27862,    18,  4115,\n",
      "           537,     4,     2,     2,  2515,   829,    41, 10021,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,  2922,    69, 27862,    18,  4115,\n",
      "           537,     4,     2,     2,  2515,  2162,    10,  4085,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,    18, 28702,  1299,  2131,     4,\n",
      "             2,     2,  9962,   985,   362,    39,  5181,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,    18, 28702,  1299,  2131,     4,\n",
      "             2,     2,  9962,   985,   362,   123,     7,     5,  2221,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313, 26998,  1003,    19,   740, 45825,\n",
      "             4,     2,     2,   894,   770,     7, 13113,    39,  1248,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313, 26998,  1003,    19,   740, 45825,\n",
      "             4,     2,     2,   894,   342, 17916,    11,    39,  2549,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4382,    11,     5,   790,  2572,   160,\n",
      "             4,     2,     2,   100,  1415,    13,    10, 37575,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4382,    11,     5,   790,  2572,   160,\n",
      "             4,     2,     2,   100,  2738,    62,    10, 23439,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   284,  1410,    88,    10,  2671,   790,\n",
      "             4,     2,     2,   133,   979,  8505,    31,   239,   334,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   284,  1410,    88,    10,  2671,   790,\n",
      "             4,     2,     2,   133,   985,   851,  3113,     7, 13137,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 12973,   254,  1682,    23,    10,  2635,\n",
      "          2877,     4,     2,     2,  2515,   770,     7, 30646,    69,  1007,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 12973,   254,  1682,    23,    10,  2635,\n",
      "          2877,     4,     2,     2,  2515,   794,     5,  2073,   516,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,  5836,     5, 32948,  3563,     4,\n",
      "             2,     2,   133,  3563, 28757,    66,     5,   464,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,  5836,     5, 32948,  3563,     4,\n",
      "             2,     2,   133,  3298,     9,  8053,    21,  4889,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  1308,  1441,    18,  2335,   962,     4,     2,\n",
      "             2,   100,  6387,   127,  2473,    23,   123,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  1308,  1441,    18,  2335,   962,     4,     2,\n",
      "             2,   100,   851,   123,    10, 16531,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  8950,    18,  1361,  1886,   300,  1981,\n",
      "             4,     2,     2,   894,   875,    41,    38,  5061,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  8950,    18,  1361,  1886,   300,  1981,\n",
      "             4,     2,     2,   894,  1199,    19,  1055,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313, 37893,     4,     2,     2,   894,\n",
      "         33914,    39, 20941,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313, 37893,     4,     2,     2,   894,\n",
      "         35672,  5134,    39, 14934,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  1299,  2602,     9,    39,  2138,\n",
      "             4,     2,     2,  9962,  2138,   300,    11,    41,  4795,    19,\n",
      "            49,  1041,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  1299,  2602,     9,    39,  2138,\n",
      "             4,     2,     2,  9962,  2138,   300,  3903,    88,   488,   334,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,   770,     7,  1532,    59,     5,\n",
      "          4118,   467,     4,     2,     2,  2515,   439,     7,     5,  5560,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,   770,     7,  1532,    59,     5,\n",
      "          4118,   467,     4,     2,     2,  2515,  1415,    23,     5,  2690,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 11566,  4889,     7,     5,  2204,     4,\n",
      "             2,     2,   100, 11375,     5, 11566,  1065,     5,  1883,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 11566,  4889,     7,     5,  2204,     4,\n",
      "             2,     2,   100,   342,  7898,    15,     5,   124,     9,     5,\n",
      "         11566,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  3653,  2033,     5, 12970,    18,   708,\n",
      "            13,     5,   745,     4,     2,     2,   133, 12970, 11236,     5,\n",
      "           745,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  3653,  2033,     5, 12970,    18,   708,\n",
      "            13,     5,   745,     4,     2,     2,   133, 12970,  5493,     5,\n",
      "           708,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  1882,    39, 25409,     4,     2,\n",
      "             2,  9962,   865,    21, 14375,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  1882,    39, 25409,     4,     2,\n",
      "             2,   894,   784, 14851,     5, 25409,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1324,     9,     5,   138,  6490,     4,\n",
      "             2,     2,   133,   792,     9,  5392, 25385,     5,   138,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1324,     9,     5,   138,  6490,     4,\n",
      "             2,     2,   133,   792,     9,  5392,   303,    39,  5010,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  2035,   628,     7,     5, 17299,     4,\n",
      "             2,     2,   100,   362,    10,  2418,    11,     5,   124,  3236,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  2035,   628,     7,     5, 17299,     4,\n",
      "             2,     2,   100,  5508,     5, 11158,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    21,   703,    31,  2878,     4,\n",
      "             2,     2,  9962,   284,  1199,    39,  4852,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    21,   703,    31,  2878,     4,\n",
      "             2,     2,   894,  4487,    10,  2598, 12981,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   284,   685,    70,    49, 18750,     4,\n",
      "             2,     2,  1213,  1088,    49,   790,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   284,   685,    70,    49, 18750,     4,\n",
      "             2,     2, 16837,   790,  2037,   668,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 30309,   196,    15,     5,  9757,    64,\n",
      "             4,     2,     2,   133,    64,    21, 18505,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 30309,   196,    15,     5,  9757,    64,\n",
      "             4,     2,     2,   133,    64,   300, 14045,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,  1770,     5,  2625,   165,     4,\n",
      "             2,     2,  2515,  2435,     7,   304,    10,  3034,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,  1770,     5,  2625,   165,     4,\n",
      "             2,     2,  2515,  2435,  4358,  2417,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,  1308,  6711,  2782,     4,     2,     2,   100,\n",
      "         13165,     7,   930,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,  1308,  6711,  2782,     4,     2,     2,   100,\n",
      "           222,     5, 10230,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4440,   156,    10,   724,     7,  1693,\n",
      "           418,     4,     2,     2,  1213,  9789,     5,  5506,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4440,   156,    10,   724,     7,  1693,\n",
      "           418,     4,     2,     2,  1213,   547,    41,  4912,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 15950, 28910, 12662,   159,     5,  8431,\n",
      "          1874,     4,     2,     2,   133,  3670, 33786,  1329,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 15950, 28910, 12662,   159,     5,  8431,\n",
      "          1874,     4,     2,     2,   133,  3670, 24509,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,    21, 15940,     4,     2,     2,   100,\n",
      "          7869,     5, 36661,  2115,  1618,     5,   790,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,    21, 15940,     4,     2,     2,   100,\n",
      "          9597,     5,  1883,  2115,  1618,     5,   790,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   770,     7,  1183,     5, 29518,\n",
      "             4,     2,     2,   894, 11252,  1926,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   770,     7,  1183,     5, 29518,\n",
      "             4,     2,     2,   894,   300,    62,   419,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 26319,     5,  2225,     4,     2,     2,\n",
      "           100, 18505,     5,  2225,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 26319,     5,  2225,     4,     2,     2,\n",
      "           133,  2225,  8633, 11835,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1226, 12990,    10,  1632,  4463,     4,\n",
      "             2,     2, 32258,   268,     9,    97,   749,  4829,    41,  6529,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1226, 12990,    10,  1632,  4463,     4,\n",
      "             2,     2, 32258,   268,     9,    97,   749,  1051,  1923,  3500,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,    18,  5418,   300, 29365,     4,\n",
      "             2,     2,   894,  7334,    66,     9,     5,  3716,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,    18,  5418,   300, 29365,     4,\n",
      "             2,     2,   894,  1064,    88,     5,  3716,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1294,  6022,     7,  2073,     5,  1040,\n",
      "             4,     2,     2,   243,    21,   528,     7,    28,  1835,     7,\n",
      "             5,  5560,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1294,  6022,     7,  2073,     5,  1040,\n",
      "             4,     2,     2,   894, 18913,    24,    31,    10,  1441,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1837,    21,  9390,     4,     2,     2,\n",
      "           894,    21,  5629,    11,  2878,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1837,    21,  9390,     4,     2,     2,\n",
      "           894,    21,  3828,     9,  1900,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,  2083,  6991,  2867,     5,   929,     4,     2,\n",
      "             2,   100,  1357,     5, 31947,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,  2083,  6991,  2867,     5,   929,     4,     2,\n",
      "             2,   100, 22804,     5,  1883,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  1423, 22697,     5,  4023, 13991,    18,\n",
      "          2549,     4,     2,     2, 13584, 29478,   376,   160,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  1423, 22697,     5,  4023, 13991,    18,\n",
      "          2549,     4,     2,     2,  2515,   439, 24876,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  4474,   769, 14742,   196,    10,  3645,\n",
      "            11,     5, 37048,     4,     2,     2,   894,   303,     5, 37048,\n",
      "          9669,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  4474,   769, 14742,   196,    10,  3645,\n",
      "            11,     5, 37048,     4,     2,     2,   894,  7661,     5,  3645,\n",
      "          4381,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  8102,    69,  1361,  1886,  1316,\n",
      "             4,     2,     2,  2515,  5426,     5,  1886,    21,  1716,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  8102,    69,  1361,  1886,  1316,\n",
      "             4,     2,     2,  2515,  5426,     5,  1886,    21, 13729,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,     8,   693,  1064,    11,   657,\n",
      "             4,     2,     2,  1213,  2922,  1564,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,     8,   693,  1064,    11,   657,\n",
      "             4,     2,     2,  1213,   300,  2997,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   930,    21,   350, 27922,     7,  1798,\n",
      "             4,     2,     2,   100,  1224,    62,     5,  3149,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   930,    21,   350, 27922,     7,  1798,\n",
      "             4,     2,     2,   100, 14092,   127,   308,  2214,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,    18,  2549,    21, 11752,    62,\n",
      "             4,     2,     2,   133,  1816,   910,  5865,  1329,    24,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,    18,  2549,    21, 11752,    62,\n",
      "             4,     2,     2,   133,  1816,  2468,    24,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 13673,   300,  9316,  9512,     4,     2,\n",
      "             2,   100, 26998,  2185,    19, 13673, 25633,   890,  1342,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 13673,   300,  9316,  9512,     4,     2,\n",
      "             2,   100,  4425,    15,     5, 13673,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  1357,   127,  2473,     4,     2,     2,\n",
      "           100, 13356,    62,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  1357,   127,  2473,     4,     2,     2,\n",
      "           100, 11956,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  1308,  8523,    18,   930,    21,  3089,  5867,\n",
      "             4,     2,     2,   100,   553,   123,     7,  1004,    24,   159,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  1308,  8523,    18,   930,    21,  3089,  5867,\n",
      "             4,     2,     2,   100,   553,     7, 12152,     5,  7522,    31,\n",
      "           123,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    18,   284,  3033,    11,  5263,\n",
      "             4,     2,     2,   894,    21,   856, 12476,   337,    19,    39,\n",
      "          1107,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    18,   284,  3033,    11,  5263,\n",
      "             4,     2,     2,   894,  2208,   874,  3527,  5007,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1294,  8505,    31,     5,  2737,     4,\n",
      "             2,     2,   894,  1415,    13,    10,   633,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1294,  8505,    31,     5,  2737,     4,\n",
      "             2,     2,   894,   362,    62,    10, 21039,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  3025,  4281,  5718,  6345,    88,  2440,\n",
      "          6345,     4,     2,     2,   133,  6345, 11743, 26252,  6128,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  3025,  4281,  5718,  6345,    88,  2440,\n",
      "          6345,     4,     2,     2,   133,  6345,  1224,  2272,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  1714,     5,  5674,     9,  1607,     4,\n",
      "             2,     2,   100,  2075,    66,     9,   383,     7,  1067,    59,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  1714,     5,  5674,     9,  1607,     4,\n",
      "             2,     2,   133,  1607,  1059, 13554,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  1308,  2138,    21,   703,    31,     5,  1098,\n",
      "             4,     2,     2,   100,  5340,   123,   124,   184,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  1308,  2138,    21,   703,    31,     5,  1098,\n",
      "             4,     2,     2,   100,   851,   123,     5,  2569,  4793,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 23416,    15,     5,  1289,   439,    62,\n",
      "             4,     2,     2,   133,  1273,  1310,     9,     5,   310,   880,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 23416,    15,     5,  1289,   439,    62,\n",
      "             4,     2,     2,   133,  5552,    11,     5,   310, 17469,     5,\n",
      "          1289,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 16301,  4813,     7,     5, 24781, 11688,\n",
      "            18, 22386,     4,     2,     2,   133, 24781, 11688,  3711,     7,\n",
      "          2581,     5, 16301,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 16301,  4813,     7,     5, 24781, 11688,\n",
      "            18, 22386,     4,     2,     2,   133, 24781, 11688,   314,     5,\n",
      "         16301,    30,  1003,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    83,  8600, 34254,  1070,   420,     5,  1289,\n",
      "             4,     2,     2,   133,  9613, 14681,    39,  2767,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    83,  8600, 34254,  1070,   420,     5,  1289,\n",
      "             4,     2,     2,   133,  9613, 31101,     5, 12638,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1041,  6022,     7,    49,   920,    18,\n",
      "          8140,     4,     2,     2,   133,   920, 38295, 11347,    31,    10,\n",
      "         12808,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1041,  6022,     7,    49,   920,    18,\n",
      "          8140,     4,     2,     2,   133,   920,    21,  8265,     7,   356,\n",
      "           223,    69,  3267,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693, 21498,    19,  1203,  2777,     4,\n",
      "             2,     2,  2515,    21,  2421, 16374,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693, 21498,    19,  1203,  2777,     4,\n",
      "             2,     2,  2515,    21,  2421, 17138,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    83,  7635,  2756,    11,     5,   976,     4,\n",
      "             2,     2,   133,   514,  1059, 16194,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    83,  7635,  2756,    11,     5,   976,     4,\n",
      "             2,     2,   133,  9774, 34316,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4758, 15378,     5,  5103,     4,     2,\n",
      "             2,   133,  5103,  8294,   409,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4758, 15378,     5,  5103,     4,     2,\n",
      "             2,   133,  5103,  2037,    10, 33021,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816, 12012,  1304,     4,     2,     2,\n",
      "         26751,   905,    66,    13,     5,  1035,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816, 12012,  1304,     4,     2,     2,\n",
      "          2515,  1410,     7,    10,    92,  1139,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  5566,  1945,  3179,     7,  1693,  1321,\n",
      "           108,  6729,     4,     2,     2,   133,  1945,  3873,    10,    92,\n",
      "          1044,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  5566,  1945,  3179,     7,  1693,  1321,\n",
      "           108,  6729,     4,     2,     2,   133,  1321,   439,    15,  2506,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   884, 32726,  1538,     5, 16281,   566,\n",
      "            39,   247,     4,     2,     2,   133, 16281, 11359,   123,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   884, 32726,  1538,     5, 16281,   566,\n",
      "            39,   247,     4,     2,     2,   133, 16281, 31762,   123,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  3203, 10905,  2917,    15,     5,  4105,\n",
      "             4,     2,     2, 40213,  4889,     7,   127,  1730,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  3203, 10905,  2917,    15,     5,  4105,\n",
      "             4,     2,     2,   771,  9419,  6050,   552,     5,  8373,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 13356,    62,    11,     5,  1692,     9,\n",
      "             5,   363,  2157,  2569,     4,     2,     2,   100,   342, 14711,\n",
      "         33609,    15,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 13356,    62,    11,     5,  1692,     9,\n",
      "             5,   363,  2157,  2569,     4,     2,     2,   100, 24313,    10,\n",
      "          4049,     9,   514,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   985, 33476,  4183,    69,   979,     4,\n",
      "             2,     2, 13584,   979, 44414, 10916,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   985, 33476,  4183,    69,   979,     4,\n",
      "             2,     2, 13584,   979,  8401,  6158,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    83,  4683, 12256,    11,   127, 10844,     4,\n",
      "             2,     2,   100,   992,  8246,    62,     5, 10844,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    83,  4683, 12256,    11,   127, 10844,     4,\n",
      "             2,     2,   100,  7182,  5686,    15,     5, 20518,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,  5328, 37706,     4,     2,     2,\n",
      "           894,   300,    10, 39276,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,  5328, 37706,     4,     2,     2,\n",
      "          9962,  9927,  1059,  1359,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  1006,    66,    23,     5,  6545,  2350,\n",
      "             4,     2,     2,   100, 13356,    62,   452,    19, 12867, 14357,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  1006,    66,    23,     5,  6545,  2350,\n",
      "             4,     2,     2,   100, 13356,    62,   452,    19,    10, 12867,\n",
      "         14599,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816, 39217,   124,     8,  7264,     7,\n",
      "           349,    97,    23,     5,  4592,  2103,     4,     2,     2, 24989,\n",
      "           521,  4005,   159,    23,     5,  4592,  2103,     4,     2,     1],\n",
      "        [    0, 26715,     4,    20,  1816, 39217,   124,     8,  7264,     7,\n",
      "           349,    97,    23,     5,  4592,  2103,     4,     2,     2, 24989,\n",
      "           521,    23,     5,  4592,  2103,  1299,   314,    66,     4,     2]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   920,  5932,    15,     5,  2664,  3914,\n",
      "         18675,     4,     2,     2,  2515, 31979,   124,    62,    88,     5,\n",
      "           935,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   920,  5932,    15,     5,  2664,  3914,\n",
      "         18675,     4,     2,     2,  2515,  1276,     7,   860,     7,   109,\n",
      "            10, 11113,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 24232,     5,  1601,    11,     5, 36661,\n",
      "             4,     2,     2,   133,   618,   558,  2781,     5,  1601,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 24232,     5,  1601,    11,     5, 36661,\n",
      "             4,     2,     2,   133,   618,   558, 14418,  4560,     5,  1601,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 34796,  1371,    21,  3230,     4,     2,\n",
      "             2,   894,  5673,    70,     9,    39,   418,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 34796,  1371,    21,  3230,     4,     2,\n",
      "             2,   894,   439,   184,  2263,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  6693,   668,  2504,     4,     2,     2,\n",
      "           133,  2372,  1059,  3651,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  6693,   668,  2504,     4,     2,     2,\n",
      "           133, 18949,  1952,    58, 21539,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   920,  3024,  7456,    39,  4117,     4,\n",
      "             2,     2,  9962,   985,  1051,   123,     7,    39,   929,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   920,  3024,  7456,    39,  4117,     4,\n",
      "             2,     2,  9962,   985,   342,    10,  1971,  1580,    15,     5,\n",
      "          7725,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  5601,     5,  4847,  5467,     4,\n",
      "             2,     2,   894,  1419,    39,    40,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  5601,     5,  4847,  5467,     4,\n",
      "             2,     2,   894,   829,    41,  6757, 14067,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   362,    10, 19998,     9,     5,  2850,\n",
      "          5618,   154,  3895,     4,     2,     2,   100,   828,   127, 15686,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   362,    10, 19998,     9,     5,  2850,\n",
      "          5618,   154,  3895,     4,     2,     2,   100, 18698,   127, 15686,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  4474,  2277,     5,  3331,     4,     2,\n",
      "             2,   133,  3331,  9710,  9415,    11,    69,  1652,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  4474,  2277,     5,  3331,     4,     2,\n",
      "             2,   133,  3331,  2039,    41,   505,  4267,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  1299, 17067,     4,     2,     2,   100,\n",
      "         17931,    70,   183,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  1299, 17067,     4,     2,     2,   100,\n",
      "          8069,    70,   183,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 11593,  6443,     5,  3186,     4,     2,\n",
      "             2,  2515,  2006,     5,  3186,    18,  5298,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 11593,  6443,     5,  3186,     4,     2,\n",
      "             2,  2515, 14255, 13866,     7,     5,  3186,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 25807,   127,  3024,     4,     2,     2,\n",
      "           243,    21, 37487,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 25807,   127,  3024,     4,     2,     2,\n",
      "           243,  1299,    24, 17414,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313, 12796,  1923,  3012,     4,     2,\n",
      "             2,   894,   685,    39, 18586,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313, 12796,  1923,  3012,     4,     2,\n",
      "             2,   894,  2152,    10,  1144,   908,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    18,  3124, 14357, 22382,  4462,\n",
      "             4,     2,     2,   894, 18634,   196,    39,  3701,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    18,  3124, 14357, 22382,  4462,\n",
      "             4,     2,     2,   894, 34737,    39,  3701,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  1179,    39, 22229,     4,     2,\n",
      "             2,   894,    21,  3911,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  1179,    39, 22229,     4,     2,\n",
      "             2,   894,  1299, 25788,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 12562,  6199,   127,  9896,    18,  3089,\n",
      "          5087,     4,     2,     2,   100,  2047,    39, 11304,    58,   205,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 12562,  6199,   127,  9896,    18,  3089,\n",
      "          5087,     4,     2,     2,   100,  2047,    14,    37,  1467,   357,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,  6602,  7893,     4,     2,     2,\n",
      "           894,   880, 20203,    55,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,  6602,  7893,     4,     2,     2,\n",
      "           894,   554, 19841,    62,   656,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693, 15533,    69, 12082,    11,     5,\n",
      "          8658,     4,     2,     2,   133, 12082,    18,   809,   439, 37019,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693, 15533,    69, 12082,    11,     5,\n",
      "          8658,     4,     2,     2,   133, 12082,   554,     7, 33096,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 36513,  2039,     5,  8347,    18,  2295,\n",
      "             4,     2,     2,   133,   313,    18,  4374,    21,   160,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 36513,  2039,     5,  8347,    18,  2295,\n",
      "             4,     2,     2,   133,   313,    21,  2086,     5,   177,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 19502,  5372,    14,    41, 43191,  2630,\n",
      "           283,     7,    39,   790,     4,     2,     2,   894,  2967, 24162,\n",
      "            11,     5, 12288,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 19502,  5372,    14,    41, 43191,  2630,\n",
      "           283,     7,    39,   790,     4,     2,     2,   894,  1682,    41,\n",
      "          9876,  3380,    11,    39,   929,     4,     2,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  2528,     7,   127,   790,  5521,   990,\n",
      "            14,    52,   213,    66,     7,  3630,     4,     2,     2,   100,\n",
      "            21,   350,  7428,     7,  3886,   932,     4,     2,     1,     1],\n",
      "        [    0, 27037,     4,    38,  2528,     7,   127,   790,  5521,   990,\n",
      "            14,    52,   213,    66,     7,  3630,     4,     2,     2,  2387,\n",
      "           790,  5521,   990,    81,   620, 12198,    69,  2814,     4,     2]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,  2037,    69,  2138,  2600,    69,\n",
      "         25694,     4,     2,     2,  2515,   554,  9646,     5, 25694,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,  2037,    69,  2138,  2600,    69,\n",
      "         25694,     4,     2,     2,  2515,   300,    10,    92, 25694,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,    21,   765,    15,   418,    13,\n",
      "          5956,     4,     2,     2,  2515,  1006,  6120,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,    21,   765,    15,   418,    13,\n",
      "          5956,     4,     2,     2,  2515,  6602,    69,   633,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   920,    18,   865,  1335,  3872,   139,\n",
      "          6691,     4,     2,     2,   894,  6699,     5,  2131, 25901,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   920,    18,   865,  1335,  3872,   139,\n",
      "          6691,     4,     2,     2,   894,   181, 19747,     5, 20830,    18,\n",
      "           471,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   138,   770,     7, 12567,  2111, 11658,\n",
      "             4,     2,     2,  1213,  1661,    10,  6720,     7,    92,   916,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   138,   770,     7, 12567,  2111, 11658,\n",
      "             4,     2,     2,  1213,  7664,    10,  2658,     7,   916,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  5627,  1929,  1059, 25807,     4,     2,\n",
      "             2,   133,  2143,  4021,     5, 31601,  2485,   160,     5, 16433,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  5627,  1929,  1059, 25807,     4,     2,\n",
      "             2,   133,  2143, 10840,    10,  3428,   420,     5,  1929,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 33855,   127,   652,     4,     2,     2,\n",
      "          2387,  8636,   326, 19264,   162,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 33855,   127,   652,     4,     2,     2,\n",
      "          2387,  8636,   740,  9596,    10, 19033,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3395,  9577,  7685,   159,     4,     2,\n",
      "             2,   243,    21,  2322,    30, 14489,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3395,  9577,  7685,   159,     4,     2,\n",
      "             2,  4763,   376,     7, 43276,   877,    24,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   314,     5,  6231,    66,    15,     5,\n",
      "          2103,     4,     2,     2,   133,  6231,  7722,  9775,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   314,     5,  6231,    66,    15,     5,\n",
      "          2103,     4,     2,     2, 16197,   918,  3514, 17651,     5,  6231,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1011,   254,  1243, 17200,    10, 14038,\n",
      "          5511,     4,     2,     2,  2515,  3273,    69, 21565,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1011,   254,  1243, 17200,    10, 14038,\n",
      "          5511,     4,     2,     2,  2515, 22027,    69,  7451,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   920,    18, 14172,   523, 11667,   376,\n",
      "          7587,  2550,     4,     2,     2,   894,  2435,   141,     7,  3318,\n",
      "           106,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   920,    18, 14172,   523, 11667,   376,\n",
      "          7587,  2550,     4,     2,     2,   894,  2075,   198,    15,     5,\n",
      "         14988,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  1059,  3838,  5039,  9315,    11,     5,\n",
      "          1040,     4,     2,     2,   100,  1835,     5,  1040,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  1059,  3838,  5039,  9315,    11,     5,\n",
      "          1040,     4,     2,     2,   100,   685,  1349,     9,    86,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   547,  1122,  9734,     7,   167,\n",
      "             9,    39,  1041,     4,     2,     2,  9962,  1041, 11359,   123,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   547,  1122,  9734,     7,   167,\n",
      "             9,    39,  1041,     4,     2,     2,  9962,  1041,  2982,  4447,\n",
      "           123,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   512,  9097,  9546,     7,    10,   912,\n",
      "             4,     2,     2,   243,  2075,    66,     9,  1123,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   512,  9097,  9546,     7,    10,   912,\n",
      "             4,     2,     2,   133,  1393,  1064, 15028,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313, 14964,     5,  2480,  6353,    11,\n",
      "             5,  3778,     4,     2,     2,   133,  2480,  6353,   685,    63,\n",
      "         12117,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313, 14964,     5,  2480,  6353,    11,\n",
      "             5,  3778,     4,     2,     2,   133,  2480,  6353, 13911,  5686,\n",
      "            31,     5, 33216,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 10601, 14129,    11,     5,   929,     4,\n",
      "             2,     2,   133,  7986,  1415, 11216,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 10601, 14129,    11,     5,   929,     4,\n",
      "             2,     2,   133,  6347,  1415, 10905,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   314,   173,   419,     4,     2,     2,\n",
      "           100,    56,    10, 19344,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   314,   173,   419,     4,     2,     2,\n",
      "          2387,  3504,   547,    10,   529,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 20830,    98,  6691,     5,  7986,     4,\n",
      "             2,     2,   133,  1945,  2850, 40256,     5, 20830,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 20830,    98,  6691,     5,  7986,     4,\n",
      "             2,     2,   133,  1945,   851,     5, 20830,    10,  3951,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 11184,     7,   127,  1441,     4,     2,\n",
      "             2,  2387,  1441, 31928,  4097,   162,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 11184,     7,   127,  1441,     4,     2,\n",
      "             2,  2387,  1441,  1059, 26974,  1070,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,  3359,    66,    11,     5,  2180,\n",
      "             4,     2,     2,   894,  2584,    10, 16907,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,  3359,    66,    11,     5,  2180,\n",
      "             4,     2,     2,   894,  5328,    10, 22239, 15203,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4562, 15005,   223, 14270,     4,     2,\n",
      "             2,   894,  2121,    39,  5889,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4562, 15005,   223, 14270,     4,     2,\n",
      "             2,   894,    21,  1340,    19, 35059,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693, 39744,    69,  2549,     4,     2,\n",
      "             2,  2515,   770,    10,    92,   356,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693, 39744,    69,  2549,     4,     2,\n",
      "             2,  2515,   770,     7, 11739,    11,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4175,    58,  2037,  5176, 28111,    11,\n",
      "             5,   247,     4,     2,     2,  1213,   303,  4042,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4175,    58,  2037,  5176, 28111,    11,\n",
      "             5,   247,     4,     2,     2,  1213,    58, 14894,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   285,  5385, 16212,    10,  8018,     4,\n",
      "             2,     2,   133,  2437, 13503,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   285,  5385, 16212,    10,  8018,     4,\n",
      "             2,     2,   133,  2437,  3359,    62,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  1415,    88,     5,  3778,     4,     2,\n",
      "             2,   133,  3778, 40094,   162,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  1415,    88,     5,  3778,     4,     2,\n",
      "             2,   133,  3778,   326, 12788,   127,  3024,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  1299, 23809,     4,     2,     2,   100,\n",
      "          4543, 25654,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  1299, 23809,     4,     2,     2,   100,\n",
      "         39654,   196,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 19464,    21,  1202,     7,   847,     4,\n",
      "             2,     2,   133,  7023,    21, 22018,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 19464,    21,  1202,     7,   847,     4,\n",
      "             2,     2,   133, 19464,    21,  6087,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  2998,  7388,     4,     2,     2,\n",
      "          2515,   829,  1076, 36828,  3207,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  2998,  7388,     4,     2,     2,\n",
      "          2515,  3566,  2232,  1126,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4666,    11,   127,  1441,    18,  3537,\n",
      "            58,    15,     4,     2,     2,   100, 12267,   114,    37,    21,\n",
      "            66,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4666,    11,   127,  1441,    18,  3537,\n",
      "            58,    15,     4,     2,     2,   100,  1276,     7,   582,   123,\n",
      "            10,   825,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   342,     5, 14214,   223,   127,  8658,\n",
      "             4,     2,     2,   133,  4716,  1536,   376,   160,     5, 14214,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   342,     5, 14214,   223,   127,  8658,\n",
      "             4,     2,     2,   100,  2738,    62,     5, 14214,    18, 26431,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  1299, 28055,     4,     2,     2,\n",
      "          2515,  2075,    88,    10,  6585,  1441,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  1299, 28055,     4,     2,     2,\n",
      "          2515, 19475,    23,    69,   408,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1294, 17987, 16136,  9339,    15,     5,\n",
      "          2225,     4,     2,     2,   894,  4813,     5,  2225,   419,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1294, 17987, 16136,  9339,    15,     5,\n",
      "          2225,     4,     2,     2,   894,  4813,     5,  2225, 20044,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  1308,   512,  2263,   159,     4,     2,     2,\n",
      "           100,   439,     7,     5,  9367,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  1308,   512,  2263,   159,     4,     2,     2,\n",
      "           100,   373,    10, 25682,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 24706,     5,  1591,     4,     2,     2,\n",
      "           243,    21,  8466,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 24706,     5,  1591,     4,     2,     2,\n",
      "           243,    21, 32563,  4748,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  5103,  2342, 11251,    63, 11954,     4,\n",
      "             2,     2,   243,  4976,  7689,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  5103,  2342, 11251,    63, 11954,     4,\n",
      "             2,     2,   243, 41750, 19603,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  9181,    11,     5, 17139,     4,     2,\n",
      "             2,   133,  8247,    21,   490,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  9181,    11,     5, 17139,     4,     2,\n",
      "             2,   133,  8247,    21,   455,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1837,  3448,     5,  1751,    23,    39,\n",
      "          1802,     4,     2,     2,   133,  1837,   342,   159,     5,  1751,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1837,  3448,     5,  1751,    23,    39,\n",
      "          1802,     4,     2,     2,   133,  1802,   342,    39,  1420,    62,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  1415,   556,     7,     5,   983,     4,\n",
      "             2,     2,   100,  1904,     7,  2725,   127, 11992,    18,  6172,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  1415,   556,     7,     5,   983,     4,\n",
      "             2,     2,   100,  1904,     7,  2725,   127,  1441,    18,  3312,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   685,  1349,     9,    86,     4,     2,\n",
      "             2,   100,    21,   183, 24009,   154,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   685,  1349,     9,    86,     4,     2,\n",
      "             2,   100,    21, 39117,  1827,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3780, 11118,    66, 32563, 19031,     4,\n",
      "             2,     2,   133, 24079,    21,   614,    15, 16019,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3780, 11118,    66, 32563, 19031,     4,\n",
      "             2,     2,   133,  5780,    21,    66,     9,  2225,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4773,   702,     5,   632,  8392,     4,\n",
      "             2,     2,   133,   841,  1224,     7,     5,  3794,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4773,   702,     5,   632,  8392,     4,\n",
      "             2,     2,   133,   841,  6022,     5,   882,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 10645, 29143, 35063,     4,     2,     2,\n",
      "           100,  1665,    24,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 10645, 29143, 35063,     4,     2,     2,\n",
      "           100,   342,  6740,    11,    24,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   278,     5,  2225, 21342,    15,     5,\n",
      "         10923,     4,     2,     2,   133, 21342, 22416,     5,  6936,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   278,     5,  2225, 21342,    15,     5,\n",
      "         10923,     4,     2,     2,   133, 10923,   314,    10, 25247, 33753,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,    21, 18525,    11,     5, 11201,\n",
      "             9,  2600,    69,  1040,     4,     2,     2,  2515,  1040, 18584,\n",
      "            69,  1842,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,    21, 18525,    11,     5, 11201,\n",
      "             9,  2600,    69,  1040,     4,     2,     2,  2515,   769, 12745,\n",
      "             5,  1040,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  3286,   478,   103, 28742,     4,     2,\n",
      "             2,   133,   313, 21287,    39,  2418, 24187,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  3286,   478,   103, 28742,     4,     2,\n",
      "             2,   133,   313,  1415,    66,     5,  2931,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,  2342,   179,  3804,     4,     2,\n",
      "             2,   133,  1816,  8266,   123,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,  2342,   179,  3804,     4,     2,\n",
      "             2,   133,  1816, 32529,   123,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3333,   851,     5,  3186,    41,  7350,\n",
      "         29654,     4,     2,     2,  1213, 29327,  1070,    69,  2985,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3333,   851,     5,  3186,    41,  7350,\n",
      "         29654,     4,     2,     2,  1213, 14316,    69,   748, 19196,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,  7756,  3804,     5,  1816,    18,\n",
      "         13789,     4,     2,     2,  2515, 27531,    69, 10762,    23,   123,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,  7756,  3804,     5,  1816,    18,\n",
      "         13789,     4,     2,     2,  2515, 27338, 10916,    69,  3124,   409,\n",
      "            31,   123,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   553,   127,  1441,    13,  2949,     4,\n",
      "             2,     2,   100,  2328,    39,  2979,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   553,   127,  1441,    13,  2949,     4,\n",
      "             2,     2,   100,  1467,    38,    21,   235,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,  4425,    11, 10511,     4,     2,\n",
      "             2,   133, 10511,  4889,     7,    39,  5582,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,  4425,    11, 10511,     4,     2,\n",
      "             2,   133, 10511,   478,   123,    11,     5,   652,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1139,   829,   484,  4877,     9,  1958,\n",
      "             4,     2,     2, 26751,    29,  2572,   159,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1139,   829,   484,  4877,     9,  1958,\n",
      "             4,     2,     2,  4763, 20119,  9111,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  3200,    18,  3294,  1249,     4,     2,\n",
      "             2,   894,   439,   184,    13,     5,   183,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  3200,    18,  3294,  1249,     4,     2,\n",
      "             2,   894,  3711,     7,  6602,     5,   633,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3907,  5009,     5,   790,     4,     2,\n",
      "             2,   133,  3907,  1064,  2500,     5,  5645,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3907,  5009,     5,   790,     4,     2,\n",
      "             2,   133,  3907,  1481,  7560,     5, 12284,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  5627,  3462,    11,   457,     4,     2,\n",
      "             2,   100, 19030,     5,  5627,    11,     5, 24672,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  5627,  3462,    11,   457,     4,     2,\n",
      "             2,   100, 21372,     5, 27729,   159,     7,     5,  5627,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   284, 19412,     5,   891,     4,     2,\n",
      "             2,   133,   891,   585,    14,    51,    58, 18246,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   284, 19412,     5,   891,     4,     2,\n",
      "             2,   133,   891,   585,    14,    51,    58,   519,    10,  1928,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,  1051,     5,  2143,    10,  7398,\n",
      "          1342,   833,     4,     2,     2,  2515,  6640,   123,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,  1051,     5,  2143,    10,  7398,\n",
      "          1342,   833,     4,     2,     2,  2515, 27046,   123,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 33767,   127,   471,    23,   127,  1441,\n",
      "            18,   445,     4,     2,     2,   100,    21, 10985,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 33767,   127,   471,    23,   127,  1441,\n",
      "            18,   445,     4,     2,     2,   100,  1507,    19,   123,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   964, 18626,    10, 12911,     4,     2,\n",
      "             2,  1213,   770,     7,   465,    10,  7932,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   964, 18626,    10, 12911,     4,     2,\n",
      "             2,  1213,   770,     7,   146,    10,  2105,   568,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 35809,    11,     5,  4647,   439,   160,\n",
      "             4,     2,     2,   133,   313, 36450,     5, 20279,    88,     5,\n",
      "         25572,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 35809,    11,     5,  4647,   439,   160,\n",
      "             4,     2,     2,   133,   313,   362,     5,  9366,    66,     9,\n",
      "             5, 12941,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,   278,    41,  8263,   724,     4,\n",
      "             2,     2,  2515,  3369, 10074,   160,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,   278,    41,  8263,   724,     4,\n",
      "             2,     2,  2515,  1006,   543,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  8581,   313,   962,     9,   793,  1046,\n",
      "             4,     2,     2,  9962,   979,   300,    88,  1030,  3605,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  8581,   313,   962,     9,   793,  1046,\n",
      "             4,     2,     2,  9962,   979, 17136,    39, 13016,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693, 30309,   196,    15,     5,  8493,\n",
      "             4,     2,     2,   133,  8493,   439,    66,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693, 30309,   196,    15,     5,  8493,\n",
      "             4,     2,     2, 23996,  5361, 22465,    31,     5,  8493,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,    18,   512,    21,    11,     5,\n",
      "          2792,     4,     2,     2, 13584,  1393,    18,  4385,    21, 19358,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,    18,   512,    21,    11,     5,\n",
      "          2792,     4,     2,     2,  2515,   300,    11,    10,   512,  3213,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 17931,   149,   127,  8054,     4,     2,\n",
      "             2,   100,   156,  7080,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 17931,   149,   127,  8054,     4,     2,\n",
      "             2,   100,  2039,  7080,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   285,  1955,   300,    66,     9,     5,\n",
      "         11369,  1827,   833,     4,     2,     2,   347,  8015,   281, 23116,\n",
      "            11,    39,  2698,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   285,  1955,   300,    66,     9,     5,\n",
      "         11369,  1827,   833,     4,     2,     2,  9962,   284,  2922,     5,\n",
      "          1228,  1019,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693, 24433,  3215,    11,     5, 11824,\n",
      "         30326,     4,     2,     2,   133, 11824,  5412,  1059,   784,  7480,\n",
      "         29530,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693, 24433,  3215,    11,     5, 11824,\n",
      "         30326,     4,     2,     2,   133, 11824,  5412, 23544,    66,     9,\n",
      "             5, 17465,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1564,  1294,   770,     7,   972,    97,\n",
      "           521,    15,  2894,     4,     2,     2,   894,  1770,    10, 19589,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1564,  1294,   770,     7,   972,    97,\n",
      "           521,    15,  2894,     4,     2,     2,   894, 22878,  3995,    11,\n",
      "          4675,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  4639,    62,     5, 16433, 31601,  2485,\n",
      "             4,     2,     2,   100,    21,   546,    13,  7082,   464,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  4639,    62,     5, 16433, 31601,  2485,\n",
      "             4,     2,     2,   100,    21, 37060, 23786,     5,  1207,   929,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,    21,   642,  8294,  1567,     5,  2143,\n",
      "             4,     2,     2,   133,  2143,  2075,   409,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,    21,   642,  8294,  1567,     5,  2143,\n",
      "             4,     2,     2,   133,  2143,  2738,    10, 14214,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,    21,   303,  2181,     9,    10,\n",
      "         13811,     4,     2,     2,  2515,    21,  4018,     7,  3008,   435,\n",
      "           544,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,    21,   303,  2181,     9,    10,\n",
      "         13811,     4,     2,     2,  2515,    21,   342,    15,   744,  3236,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 26158,     5,  4696,    88,     5,  2131,\n",
      "          6845,     4,     2,     2,   133,  6845, 11235,  7486,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 26158,     5,  4696,    88,     5,  2131,\n",
      "          6845,     4,     2,     2,   133,  4696, 25385,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  3142,  3203,    19,    10, 34478,     4,\n",
      "             2,     2,   894,    21,  9559,    13,     5,   997,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  3142,  3203,    19,    10, 34478,     4,\n",
      "             2,     2,   894,    21,  1710,    11,  2168,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1837,  2075,   409,    31,     5,   249,\n",
      "             4,     2,     2,   133,   249,  2922,     7,     5,  1802,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1837,  2075,   409,    31,     5,   249,\n",
      "             4,     2,     2,   133,   249, 15378,     5,  1837,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  9972,  1979,    75,  1004,    15,     4,\n",
      "             2,     2,   100,  1882,    24,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  9972,  1979,    75,  1004,    15,     4,\n",
      "             2,     2,   100,  1340,    24,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  2075,    66,     9,   929,    11,\n",
      "            69, 16198,     4,     2,     2,  2515,  3566,    41,  4935, 18704,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  2075,    66,     9,   929,    11,\n",
      "            69, 16198,     4,     2,     2,  2515, 26319,    69, 16937,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    21,  1144, 15894,     4,     2,\n",
      "             2,  9962,  1141,   851,  3113,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    21,  1144, 15894,     4,     2,\n",
      "             2,  9962,  1141,   314,   123,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,  4756,    10,  3093,     4,     2,\n",
      "             2,   894,  1059,  6048,    13,     5,   633,    37,   770,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,  4756,    10,  3093,     4,     2,\n",
      "             2,  9962,   633,   904,    21, 21961,   196,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    18,  2236,  5635,  2563,  1328,\n",
      "             5, 15279,  4031,     4,     2,     2,   894, 13029,     5,  2437,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    18,  2236,  5635,  2563,  1328,\n",
      "             5, 15279,  4031,     4,     2,     2,   894,  1834,    88,     5,\n",
      "         18896,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 14937,    10, 12911,    88,     5, 29333,\n",
      "             9,   514,     4,     2,     2,   133, 12911, 21168,     7,     5,\n",
      "          2576,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 14937,    10, 12911,    88,     5, 29333,\n",
      "             9,   514,     4,     2,     2,   133, 12911,  2263,    11,   457,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   869,   478,     5,  1011,  1706,     5,\n",
      "          4683,     4,     2,     2,   133,  1011,   439,    11,     5,  4683,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   869,   478,     5,  1011,  1706,     5,\n",
      "          4683,     4,     2,     2,   133,  1011, 24304,   124,     7,     5,\n",
      "           869,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 37253,    11,     5,  8402,    11,     5,\n",
      "         33093,     4,     2,     2,   100,  1368,   636, 16312,  5686,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 37253,    11,     5,  8402,    11,     5,\n",
      "         33093,     4,     2,     2,   100, 18013,  5841,   196,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1400,  1055,   906,   373,   573,     4,\n",
      "             2,     2,   133,  2111,   341, 26160,   418,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1400,  1055,   906,   373,   573,     4,\n",
      "             2,     2,   133,  2111,   314,    39, 30427,    15,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,   362,     5, 11671,    66,     4,     2,\n",
      "             2,   133, 11671,   156,     5,  4647, 11362,  1099,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,   362,     5, 11671,    66,     4,     2,\n",
      "             2,   100, 13636,  4021,   409,   127,  3482,   889,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   284,   439,     7,     5, 14188,     4,\n",
      "             2,     2,   133,   408, 22610,     5,  3122,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   284,   439,     7,     5, 14188,     4,\n",
      "             2,     2,   133,   408, 15378,     5,  3122,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    18,  9589,    21,  7337,     4,\n",
      "             2,     2,  9962, 33473,    58,  4551,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    18,  9589,    21,  7337,     4,\n",
      "             2,     2,  9962, 19147,    58, 29367,   196,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,    56,    41,  1823,  3682,    13,     5,\n",
      "          4192,     4,     2,     2,   100,   553,   127,  1441,    13,  9969,\n",
      "             7,     5,  5584,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,    56,    41,  1823,  3682,    13,     5,\n",
      "          4192,     4,     2,     2,   100,   553,   127,  1441,   114,    37,\n",
      "            21,  2509,    11,   164,     4,     2,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   935,  1881,   254,    11,     5,   790,\n",
      "          2263,     4,     2,     2,   100,  1146,    66, 20850,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   935,  1881,   254,    11,     5,   790,\n",
      "          2263,     4,     2,     2,   100,  1357,     5,  6410,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,    18,   124,  4285,  4183,     4,\n",
      "             2,     2,  9962, 16907,    21,   490,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,    18,   124,  4285,  4183,     4,\n",
      "             2,     2,  9962, 16907,    21,  2016,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  2162,   127,   985,    10,  1455,     4,\n",
      "             2,     2,   100, 17241,    69,    10,  8492,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  2162,   127,   985,    10,  1455,     4,\n",
      "             2,     2,   243,    21,    69,  4115,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   385,  3707,  1630,  5290,    11,     5,\n",
      "          5671,    58,  4957,     4,     2,     2,   250, 19417,  1690,  1545,\n",
      "             5, 23118,  5777,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   385,  3707,  1630,  5290,    11,     5,\n",
      "          5671,    58,  4957,     4,     2,     2, 38378, 48226,    29, 11532,\n",
      "            62,     5, 27353,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,  2322,     5,   914,     4,     2,     2,\n",
      "           133, 21382, 21155,    66,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,  2322,     5,   914,     4,     2,     2,\n",
      "           133,   914,  2622,    10, 21382,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2982, 34618,  1799,  1348,    10,  4221,\n",
      "             4,     2,     2,  1213,   399,    75,   236,     7,  2625,    11,\n",
      "           461,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2982, 34618,  1799,  1348,    10,  4221,\n",
      "             4,     2,     2,  1213,   770,     7,  5989,    49,  1081,  1291,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   408,    58,  1051,     7,    41, 21297,\n",
      "          1580,     4,     2,     2, 16837,  1041,   962,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   408,    58,  1051,     7,    41, 21297,\n",
      "          1580,     4,     2,     2, 16837,  1041, 29136,   106,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    83, 12505,  1459,  5932,    11,     5,  6444,\n",
      "             4,     2,     2,   250, 16309,  2756,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    83, 12505,  1459,  5932,    11,     5,  6444,\n",
      "             4,     2,     2,   243,   880,     7, 18742,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1368, 17625, 13590,    10, 34382, 16173,\n",
      "             4,     2,     2,  2515,  1059, 36410,  8358,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1368, 17625, 13590,    10, 34382, 16173,\n",
      "             4,     2,     2,  2515, 28604,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20, 12941,  1059,  2131,     4,     2,     2,\n",
      "           100,  1224,     5, 12941,    15,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20, 12941,  1059,  2131,     4,     2,     2,\n",
      "           100,   342,     5,  8847,    11,     5, 12941,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38, 21654,     5, 14099, 27288,     4,     2,\n",
      "             2,   133, 14099,   300, 16140,   219,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38, 21654,     5, 14099, 27288,     4,     2,\n",
      "             2,   133, 14099,  9316, 31137,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   247,  2967,    92,  1212,     4,     2,\n",
      "             2,   133,   247,  6978,     5,  1212,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   247,  2967,    92,  1212,     4,     2,\n",
      "             2,   133,   247, 17735,  1538,     5,  1212,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  4049, 21753,   160,     5,  2103,     4,\n",
      "             2,     2,   243, 17306,    70,    81,     5,  1929,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  4049, 21753,   160,     5,  2103,     4,\n",
      "             2,     2,   243,  5932,    11,    10, 12177,     9, 16937,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2103, 33346, 10288,     4,     2,     2,\n",
      "           133,  1929,    21, 25169,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2103, 33346, 10288,     4,     2,     2,\n",
      "           133,  1929,    21, 25645,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1150,  2037,    39,   979,  6480,     4,\n",
      "             2,     2,  9962,   979, 13901,     5,  3157,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1150,  2037,    39,   979,  6480,     4,\n",
      "             2,     2,   133,  1150, 10128,    39,   979,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,    18,   471, 45219,  5134,    19,\n",
      "          2400,     4,     2,     2,   894,   362, 21768, 21580,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,    18,   471, 45219,  5134,    19,\n",
      "          2400,     4,     2,     2,   894,   362, 39447,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2341,  9546,   159,     4,     2,     2,\n",
      "           243,    21,  8955,     5,  1992,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2341,  9546,   159,     4,     2,     2,\n",
      "           243,    21,   878,   639,  3078,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   439,   149,  5804,     4,     2,\n",
      "             2,   448, 13589,  5467,  2075,    11,    39,   284,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   439,   149,  5804,     4,     2,\n",
      "             2,   894,    21,  6443,    19,  6943,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693, 29409,  3804,    69, 14599,     4,\n",
      "             2,     2,  2515, 32305,    69,   689,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693, 29409,  3804,    69, 14599,     4,\n",
      "             2,     2,  2515, 27021,    15,    69,   689,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,    56,    10, 12867, 14599,     4,\n",
      "             2,     2, 13584,  2236, 12020,   910,  9331,   219,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,    56,    10, 12867, 14599,     4,\n",
      "             2,     2,  2515,  1834,    19,    41, 15056,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2335, 36235,     5, 28068, 19464,    15,\n",
      "             5,  2103,     4,     2,     2,   243, 13868, 30304,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2335, 36235,     5, 28068, 19464,    15,\n",
      "             5,  2103,     4,     2,     2,   243,  4976,   159,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,    18,   265, 13227,     4,     2,\n",
      "             2,  2515,  2277,    69,  1321,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,    18,   265, 13227,     4,     2,\n",
      "             2,  2515,  1059,  8581,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   521, 17469,     5,  8171,     4,     2,\n",
      "             2,   133, 10342, 18780,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   521, 17469,     5,  8171,     4,     2,\n",
      "             2,   133,  3254,  5530, 19122,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,  1695,    79,   794,    10, 15934,\n",
      "             4,     2,     2, 13584, 37069,  2327, 22222,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,  1695,    79,   794,    10, 15934,\n",
      "             4,     2,     2, 13584, 37069,  1330,     7,    69,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   685,    39,  1576,     4,     2,\n",
      "             2,   894,   823, 20923,    11,     5,  6444,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   685,    39,  1576,     4,     2,\n",
      "             2,   894,    21,   823,   848,    11,    41,  6986,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   920,   905,   213,     9,     5, 14930,\n",
      "          6755,     4,     2,     2,   133, 14930,  3816, 32914,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   920,   905,   213,     9,     5, 14930,\n",
      "          6755,     4,     2,     2,   133, 14930,  1458,    88,     5,   935,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   685,    39,  1460,     7,  1994,\n",
      "             4,     2,     2,   894,    56,    10,  8579,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   685,    39,  1460,     7,  1994,\n",
      "             4,     2,     2,   894,   362,    10,  1844,  8016,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,  7182,  5686,    15,     5, 15032,\n",
      "             4,     2,     2,   970,    21,    10,  7009,    11,     5, 10546,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,  7182,  5686,    15,     5, 15032,\n",
      "             4,     2,     2,  2515,  1317,    69,   766,   145,   373,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   222,    10, 32839,  1011,    88,\n",
      "             5,  3716,     4,     2,     2,   133,   301, 12984,  4262,    11,\n",
      "            71,   123,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   222,    10, 32839,  1011,    88,\n",
      "             5,  3716,     4,     2,     2,   133,   313, 29365,     5,   301,\n",
      "         12984,     4,     2,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   362, 16674,     4,     2,     2,  2387,\n",
      "          7910,  6049,    62,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   362, 16674,     4,     2,     2,  2387,\n",
      "          7910,  2504,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1703,  1109,  1224,  5718,     4,     2,\n",
      "             2,   133,  1393,  3148,     5, 18507,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1703,  1109,  1224,  5718,     4,     2,\n",
      "             2,   133,  1393, 11006, 10916,    39, 21305,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  4136, 11255, 24136,     4,     2,     2,\n",
      "           100, 29365,     5, 11255,    11,  3279,   514,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  4136, 11255, 24136,     4,     2,     2,\n",
      "           100,  2325,     5, 11255,    15,     5,  2131, 25901,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   512,   300,   385,  9663,     4,     2,\n",
      "             2,   133,  1393,   478,    10,  7377,  9438,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   512,   300,   385,  9663,     4,     2,\n",
      "             2,   133,  1393,  2075,    10,  1275,  1109,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,  8069,    70,   363,     4,     2,\n",
      "             2,   894, 22904,     5, 10743,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,  8069,    70,   363,     4,     2,\n",
      "             2,   894,  1595,     5, 10743,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   664,  2143,  3741,  1545,     7,     5,\n",
      "         41378,     9,     5,  3716,     4,     2,     2,   894,  9741,  2239,\n",
      "             7,  6966,     4,     2,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   664,  2143,  3741,  1545,     7,     5,\n",
      "         41378,     9,     5,  3716,     4,     2,     2,   133,   301, 12984,\n",
      "            21,    15,  4053,     4,     2,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   342,   127,   865,     7,   127,  7050,\n",
      "             4,     2,     2,   100,  1299,   127, 28288,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   342,   127,   865,     7,   127,  7050,\n",
      "             4,     2,     2,  2387,  1144,   731, 24101,    62,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   745, 12142,     7,   127,   558,    21,\n",
      "           223,  1663,     4,     2,     2,  2387,   558,    21, 11138,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   745, 12142,     7,   127,   558,    21,\n",
      "           223,  1663,     4,     2,     2,  2387,   558,    21, 28269,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   284,   770,     7,   120,     7,   216,\n",
      "            49,    92,  6611,     4,     2,     2,   133,   284,  4036,     5,\n",
      "          6611,    81,    13,  3630,     4,     2,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   284,   770,     7,   120,     7,   216,\n",
      "            49,    92,  6611,     4,     2,     2,   133,   284, 21017,     7,\n",
      "             5,  6611,    31,    49,  6993,     4,     2,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,  3201, 11743,  9512,    62,    31,     5,  3716,\n",
      "             4,     2,     2,   133,  6966,  2089, 27764,    88,     5,  3716,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,  3201, 11743,  9512,    62,    31,     5,  3716,\n",
      "             4,     2,     2,   133,  6966,  2089, 19387,    11,     5,  3716,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   828,    88,    10, 15711,     9,   514,\n",
      "         34092,     4,     2,     2,   100, 13636, 32305,    10,  5018,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   828,    88,    10, 15711,     9,   514,\n",
      "         34092,     4,     2,     2,   100, 13636,  1855,  8246,   127, 13495,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2143,  7182,  5686,     4,     2,     2,\n",
      "          9962,  8443,    21,   542,   329,  8246,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2143,  7182,  5686,     4,     2,     2,\n",
      "          9962, 14172,   523, 11667,    58,  7587,  2550,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   693,   342,  5567,  2911, 16148,    11,\n",
      "             4,     2,     2,  2515,    21, 16573,    30,  6496,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   693,   342,  5567,  2911, 16148,    11,\n",
      "             4,     2,     2,  2515,   300,    69, 12137, 40227,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38,  4885, 12146,   127,   514,  7304,     4,\n",
      "             2,     2,   100, 24313,    70,     5,   514,    11,    24,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38,  4885, 12146,   127,   514,  7304,     4,\n",
      "             2,     2,   100,  1682,    24,    11,     5, 22087,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  2384,   311,    21, 39692,     4,     2,\n",
      "             2,   243,  5558, 28792,  2777,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  2384,   311,    21, 39692,     4,     2,\n",
      "             2,   243,    56,    10,  6336,  6197,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  3627, 30090,     4,     2,     2,   133,\n",
      "          3419, 20923,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  3627, 30090,     4,     2,     2,   133,\n",
      "          3419, 13590, 34941,     4,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,  1299,  1690, 25844,    30,     5,\n",
      "           910, 17993,     4,     2,     2,   894, 15960,     5,   910, 17993,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,  1299,  1690, 25844,    30,     5,\n",
      "           910, 17993,     4,     2,     2,   894,  5372,    10, 11602,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1028, 18780,     4,     2,     2,   133,\n",
      "           313, 10601,    62,     5,  1028,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1028, 18780,     4,     2,     2,   133,\n",
      "           313,  2738,    62,     5,  1028,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   693,    21, 19311,    23,   162,     4,\n",
      "             2,     2,   100, 27425,    69,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   693,    21, 19311,    23,   162,     4,\n",
      "             2,     2,   100,  1299,  9800,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   333,   314,     5,  5707,     4,     2,\n",
      "             2,  1213,   362,  3493,     9,     5, 18293,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   333,   314,     5,  5707,     4,     2,\n",
      "             2,  1213,  5915,    70,     5, 18293,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   554,    41,  4795,    19,   162,\n",
      "             4,     2,     2,  2387,  1441,  2942,   162,     7,     5,   313,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   554,    41,  4795,    19,   162,\n",
      "             4,     2,     2,  2387,  1441,  3359,    62,    13,   162,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 12431,    15,   127,  4806,    21,  3269,\n",
      "             4,     2,     2,   100, 19153,   935,    88,     5, 12431,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 12431,    15,   127,  4806,    21,  3269,\n",
      "             4,     2,     2,   100, 12012, 24767,    15,     5,  4806,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,  1415, 18100,     4,     2,     2,\n",
      "         13584,  1150,  1166,    69,    10,   527,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,  1415, 18100,     4,     2,     2,\n",
      "         13584,  1150,  1299,    69, 28702,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  7670,  2075,    66,     9, 16019,     4,\n",
      "             2,     2,   100,   341,    10, 21451,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  7670,  2075,    66,     9, 16019,     4,\n",
      "             2,     2,   100,  1419,   127,   766,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,    21,  2296,    13,    10,  2541,\n",
      "             4,     2,     2,   894,    21,    11,  1126,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,    21,  2296,    13,    10,  2541,\n",
      "             4,     2,     2,   894,   554,    10,   265,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,  1816,  4711,   184,    31,   334,     4,\n",
      "             2,     2,  2515,    56,  5884,  4202,  1178,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,  1816,  4711,   184,    31,   334,     4,\n",
      "             2,     2,  2515,  3776,  2239, 10638,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  8875,  3298,    21,   455,     4,     2,\n",
      "             2,   100,   362,    24,     7,     5, 12371,  3121,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  8875,  3298,    21,   455,     4,     2,\n",
      "             2,   100, 12961,    24,   159,     5, 12045,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    38, 15702,   196,     5,  7986,     4,     2,\n",
      "             2,  2387, 25537, 19932, 10064,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    38, 15702,   196,     5,  7986,     4,     2,\n",
      "             2,  2387,  2335,  7722,  2549,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,   685,    39, 18586,     4,     2,\n",
      "             2,   894,  1224,   160,    39,  3034,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,   685,    39, 18586,     4,     2,\n",
      "             2,   894,  4021,    10,  3428,   420,     5,   929,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1816,  4021,    10, 11901,  1023,    88,\n",
      "             5,  2205,  7051,     4,     2,     2,   133, 11901,  1023,  7685,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1816,  4021,    10, 11901,  1023,    88,\n",
      "             5,  2205,  7051,     4,     2,     2,   133,   668,   439,    66,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   300,    66,     9,     5,  9310,\n",
      "             4,     2,     2,   133,  2131,   514,    21,  1613,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   300,    66,     9,     5,  9310,\n",
      "             4,     2,     2,   894,  1705,    75,   465,    10, 21342,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  1041,   770,    49,   408,     7,   213,\n",
      "             7,  1564,     4,     2,     2,  1213,   278,  4364,    10,  4522,\n",
      "          1391,    13, 12263,     4,     2,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  1041,   770,    49,   408,     7,   213,\n",
      "             7,  1564,     4,     2,     2,  1213,  4446,    49,   408,     7,\n",
      "           310,   751,     4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313, 35237,  8988,    39,  5582,     4,\n",
      "             2,     2,   133,  5582, 27715,  4490,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313, 35237,  8988,    39,  5582,     4,\n",
      "             2,     2,   133,  5582,  1059, 10610,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313, 14964,   457,     9,     5,  3838,\n",
      "          5314,     4,     2,     2,   894, 20659,  1070,     5,   314, 13507,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313, 14964,   457,     9,     5,  3838,\n",
      "          5314,     4,     2,     2,   894,  5305,     5, 10324,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  1308,  7451,    21, 27722,     4,     2,     2,\n",
      "           100,   342,  2480,    15,    24,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  1308,  7451,    21, 27722,     4,     2,     2,\n",
      "           100, 34737,   319,  1499,    15,    24,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,  1308,   558,  1883,    21,   490,     4,     2,\n",
      "             2,   100,  3244,     7,   127,  9896,    23,   127,  8429,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,  1308,   558,  1883,    21,   490,     4,     2,\n",
      "             2,   100, 36726,     5,  1607,    11,     5,  5179,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,    56,     7,  2067,    11,   516,     4,\n",
      "             2,     2,   100,   362,    10,  2418,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,    56,     7,  2067,    11,   516,     4,\n",
      "             2,     2,   100, 28772,  4567,    10,  4320,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,  3514, 19747,    23,     5,  3598,\n",
      "             4,     2,     2,   133,  3598,  8775,   196,   409,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,  3514, 19747,    23,     5,  3598,\n",
      "             4,     2,     2,   133,  3598,  4711,   202,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 27037,     4,    20,   313,   875,    10,    40,     4,     2,\n",
      "             2,   894,    21,  8180,     4,     2,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 27037,     4,    20,   313,   875,    10,    40,     4,     2,\n",
      "             2,   894,    21,    10, 23772,  8285,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  7449, 37667,    39, 11439,  8079,    15,\n",
      "           123,     4,     2,     2,   894,  1882,    66,     9,     5,  1015,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  7449, 37667,    39, 11439,  8079,    15,\n",
      "           123,     4,     2,     2,   894, 24101,    62,    39,  2877,     4,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    38,   802,  7015,    59,     5,   936,     4,\n",
      "             2,     2,   100,   553,    13,  2949,     4,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    38,   802,  7015,    59,     5,   936,     4,\n",
      "             2,     2,   100,   376,    62,    19,    10,  2472,     4,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20, 33489,  3203,    15,     5, 22032,  5436,\n",
      "          4081,     4,     2,     2,   894,  1299, 19419,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20, 33489,  3203,    15,     5, 22032,  5436,\n",
      "          4081,     4,     2,     2,   894,  1299, 30754,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,   313,  5291,     5,   165,    18,  1124,\n",
      "             4,     2,     2,   894,  1145,    39,   964,     7,  1183,     5,\n",
      "           177,     4,     2,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,   313,  5291,     5,   165,    18,  1124,\n",
      "             4,     2,     2,   894,   156,    10,  5673,    19,    39,   964,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0'), tensor([[    0, 26715,     4,    20,  2143,  1705,    75,  1136, 15028,     4,\n",
      "             2,     2,   894,   278,    39,  8054,  6700,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0, 26715,     4,    20,  2143,  1705,    75,  1136, 15028,     4,\n",
      "             2,     2,   894, 11590, 14336,     4,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('roberta-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training loop\n",
      "### Epoch: 1 ###\n",
      "y:  tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[3.2036, 3.0278],\n",
      "        [2.5597, 2.4564],\n",
      "        [2.2944, 2.4106],\n",
      "        [2.5914, 2.7487],\n",
      "        [2.4181, 2.5587],\n",
      "        [2.7133, 2.7988],\n",
      "        [2.3569, 2.6809],\n",
      "        [2.0399, 2.7059],\n",
      "        [2.5950, 2.7416],\n",
      "        [2.8363, 2.5785],\n",
      "        [2.7422, 2.4715],\n",
      "        [2.8912, 3.0162],\n",
      "        [3.1677, 2.2946],\n",
      "        [2.5664, 3.1847],\n",
      "        [2.5508, 2.8875],\n",
      "        [2.7700, 2.5883],\n",
      "        [2.5913, 2.4422],\n",
      "        [2.3646, 2.9348],\n",
      "        [2.3453, 2.7471],\n",
      "        [3.0238, 2.7619],\n",
      "        [3.0419, 2.7865],\n",
      "        [2.8838, 2.5871],\n",
      "        [2.9521, 2.7794],\n",
      "        [2.7139, 3.1100],\n",
      "        [1.9232, 2.4189],\n",
      "        [2.1656, 2.7444],\n",
      "        [2.6486, 2.7163],\n",
      "        [3.0277, 2.5907],\n",
      "        [2.6719, 2.7131],\n",
      "        [2.4274, 2.5877],\n",
      "        [2.2378, 2.5903],\n",
      "        [2.7655, 2.2364],\n",
      "        [2.8045, 2.4577],\n",
      "        [2.6178, 2.6085],\n",
      "        [2.5768, 2.9406],\n",
      "        [2.7696, 2.8830],\n",
      "        [2.7393, 2.7506],\n",
      "        [2.4508, 2.3098],\n",
      "        [2.3624, 2.5391],\n",
      "        [2.3346, 2.5278],\n",
      "        [2.9297, 2.9562],\n",
      "        [2.6955, 2.4647],\n",
      "        [2.4455, 2.8732],\n",
      "        [2.4510, 1.7563],\n",
      "        [2.7158, 2.4677],\n",
      "        [2.3714, 2.9279],\n",
      "        [2.2595, 2.7468],\n",
      "        [2.4937, 2.7351],\n",
      "        [2.8477, 2.8907],\n",
      "        [2.7822, 2.5577],\n",
      "        [2.5345, 2.3181],\n",
      "        [2.4693, 2.9593],\n",
      "        [2.5677, 3.0709],\n",
      "        [2.3312, 2.3350],\n",
      "        [2.9788, 2.3906],\n",
      "        [3.2687, 2.7579],\n",
      "        [2.2047, 2.7701],\n",
      "        [2.4825, 2.3192],\n",
      "        [2.7047, 2.3291],\n",
      "        [2.3872, 2.6249],\n",
      "        [3.1307, 2.5104],\n",
      "        [2.6151, 2.6982],\n",
      "        [2.4036, 2.9628],\n",
      "        [2.3750, 2.5697],\n",
      "        [2.6363, 2.7708],\n",
      "        [2.6808, 2.6402],\n",
      "        [3.1254, 2.9903],\n",
      "        [2.9847, 2.5575],\n",
      "        [2.6685, 2.0135],\n",
      "        [2.6234, 2.9607],\n",
      "        [2.7326, 2.2915],\n",
      "        [2.7291, 2.7580],\n",
      "        [2.5750, 2.6963],\n",
      "        [2.8183, 2.2142],\n",
      "        [2.4211, 2.5539],\n",
      "        [2.7388, 2.7735],\n",
      "        [2.7238, 2.5354],\n",
      "        [2.3096, 2.7573],\n",
      "        [2.7528, 2.6491],\n",
      "        [2.4393, 2.3340],\n",
      "        [2.5081, 2.9471],\n",
      "        [2.8487, 2.8318],\n",
      "        [2.2204, 2.5826],\n",
      "        [2.5692, 2.3884],\n",
      "        [3.1853, 2.9004],\n",
      "        [2.0771, 2.5259],\n",
      "        [3.1484, 2.5373],\n",
      "        [2.6807, 1.8069],\n",
      "        [2.7919, 2.3335],\n",
      "        [2.5122, 2.4352],\n",
      "        [2.5900, 2.4664],\n",
      "        [2.7448, 2.6776],\n",
      "        [2.5445, 2.9138],\n",
      "        [2.4743, 2.7432],\n",
      "        [2.5419, 3.0078],\n",
      "        [2.9008, 2.5891],\n",
      "        [2.8095, 2.7471],\n",
      "        [2.9052, 2.9631],\n",
      "        [2.7467, 2.5604],\n",
      "        [2.5226, 2.9774]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6589, 2.8620],\n",
      "        [2.3218, 2.2546],\n",
      "        [2.6042, 2.4517],\n",
      "        [2.9821, 2.7141],\n",
      "        [2.4137, 2.8200],\n",
      "        [2.9817, 2.8326],\n",
      "        [2.7652, 2.4491],\n",
      "        [2.5201, 2.8424],\n",
      "        [2.6693, 2.2143],\n",
      "        [2.7155, 1.8415],\n",
      "        [2.4868, 2.3689],\n",
      "        [2.4724, 2.3806],\n",
      "        [2.6390, 2.7684],\n",
      "        [2.3636, 2.6490],\n",
      "        [2.2256, 2.3685],\n",
      "        [2.5125, 2.6519],\n",
      "        [2.6600, 2.9487],\n",
      "        [2.5943, 2.7178],\n",
      "        [2.5595, 2.0904],\n",
      "        [3.1690, 2.8273],\n",
      "        [2.8433, 2.8364],\n",
      "        [2.2860, 2.6391],\n",
      "        [2.3200, 2.3449],\n",
      "        [2.4026, 2.7718],\n",
      "        [2.8509, 2.4820],\n",
      "        [2.7748, 2.5842],\n",
      "        [2.4435, 2.6812],\n",
      "        [2.9678, 2.4236],\n",
      "        [2.4378, 2.7966],\n",
      "        [2.5181, 2.3446],\n",
      "        [2.4925, 2.8729],\n",
      "        [2.7459, 2.6062],\n",
      "        [2.8165, 2.6326],\n",
      "        [2.3007, 2.2079],\n",
      "        [2.4679, 3.1525],\n",
      "        [2.7542, 2.7449],\n",
      "        [2.7636, 2.7843],\n",
      "        [2.4781, 2.7558],\n",
      "        [2.6828, 1.9877],\n",
      "        [2.8723, 1.9482],\n",
      "        [2.4431, 2.8438],\n",
      "        [2.7909, 3.0743],\n",
      "        [2.1684, 2.4740],\n",
      "        [2.9997, 3.1296],\n",
      "        [2.4807, 3.1876],\n",
      "        [2.0299, 2.6730],\n",
      "        [2.2484, 2.6529],\n",
      "        [2.6956, 2.9478],\n",
      "        [2.7234, 3.0697],\n",
      "        [2.7992, 2.7128],\n",
      "        [2.8404, 2.7783],\n",
      "        [2.6664, 2.6779],\n",
      "        [2.4677, 2.5912],\n",
      "        [2.8406, 2.6623],\n",
      "        [2.9786, 2.5338],\n",
      "        [3.2708, 2.5420],\n",
      "        [2.2550, 2.3051],\n",
      "        [2.9538, 2.1341],\n",
      "        [2.5462, 2.7547],\n",
      "        [2.7204, 2.6386],\n",
      "        [2.7367, 2.4523],\n",
      "        [2.8754, 2.3315],\n",
      "        [2.8007, 2.5629],\n",
      "        [2.5362, 2.7631],\n",
      "        [2.4497, 2.5965],\n",
      "        [2.3380, 2.7266],\n",
      "        [2.4606, 2.5540],\n",
      "        [2.7801, 2.6978],\n",
      "        [3.0947, 2.3177],\n",
      "        [2.8829, 2.8773],\n",
      "        [2.3084, 2.3067],\n",
      "        [2.4694, 2.7616],\n",
      "        [2.5760, 2.6699],\n",
      "        [2.3070, 2.3221],\n",
      "        [2.6155, 2.3574],\n",
      "        [2.7762, 2.6998],\n",
      "        [2.7029, 2.2053],\n",
      "        [3.1723, 2.7489],\n",
      "        [2.2600, 2.6486],\n",
      "        [2.6701, 2.9926],\n",
      "        [2.3259, 2.6227],\n",
      "        [2.8376, 2.5250],\n",
      "        [2.7613, 2.6795],\n",
      "        [2.6694, 2.2741],\n",
      "        [2.8481, 2.4182],\n",
      "        [3.0223, 2.2830],\n",
      "        [2.3329, 2.8952],\n",
      "        [2.9388, 2.5369],\n",
      "        [2.5467, 2.8704],\n",
      "        [2.7191, 2.7860],\n",
      "        [2.2787, 2.7271],\n",
      "        [2.4441, 2.7301],\n",
      "        [2.7350, 2.8992],\n",
      "        [2.3465, 2.6957],\n",
      "        [2.2546, 2.6744],\n",
      "        [2.8543, 3.0847],\n",
      "        [2.9463, 2.2866],\n",
      "        [2.9680, 2.9126],\n",
      "        [2.4958, 2.4539],\n",
      "        [2.3697, 2.2796]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5525, 3.2180],\n",
      "        [2.4259, 2.7946],\n",
      "        [2.7720, 2.7561],\n",
      "        [2.7109, 2.5401],\n",
      "        [2.7936, 2.1295],\n",
      "        [2.7533, 2.5074],\n",
      "        [2.7214, 2.4722],\n",
      "        [2.8864, 2.6262],\n",
      "        [2.6257, 2.5021],\n",
      "        [3.0211, 2.5427],\n",
      "        [3.3214, 2.6811],\n",
      "        [2.5999, 2.5112],\n",
      "        [2.5202, 2.8059],\n",
      "        [2.7802, 2.9835],\n",
      "        [2.3544, 2.5471],\n",
      "        [2.6963, 2.4403],\n",
      "        [3.0428, 2.8680],\n",
      "        [2.4299, 2.6617],\n",
      "        [3.1002, 2.5688],\n",
      "        [2.2782, 2.5298],\n",
      "        [2.8106, 2.7182],\n",
      "        [2.6811, 2.6878],\n",
      "        [2.9995, 2.6125],\n",
      "        [2.3879, 2.8058],\n",
      "        [2.5463, 2.6045],\n",
      "        [2.6878, 2.6246],\n",
      "        [1.8901, 2.5750],\n",
      "        [2.5472, 2.5657],\n",
      "        [2.5329, 2.5404],\n",
      "        [2.1329, 2.8523],\n",
      "        [3.0723, 2.6398],\n",
      "        [2.2453, 2.2667],\n",
      "        [2.5273, 2.7523],\n",
      "        [1.6511, 3.1050],\n",
      "        [2.3514, 2.8639],\n",
      "        [2.3191, 2.2912],\n",
      "        [2.3966, 2.5988],\n",
      "        [2.7027, 2.5533],\n",
      "        [2.3578, 2.5400],\n",
      "        [2.3761, 2.5743],\n",
      "        [3.0548, 2.2354],\n",
      "        [2.7360, 2.4883],\n",
      "        [2.5025, 2.2562],\n",
      "        [2.2829, 2.5189],\n",
      "        [2.3826, 2.8420],\n",
      "        [2.9291, 2.6100],\n",
      "        [3.0340, 3.0465],\n",
      "        [2.4343, 2.7808],\n",
      "        [2.6559, 2.5649],\n",
      "        [2.6405, 2.5049],\n",
      "        [2.5218, 2.7173],\n",
      "        [2.2402, 2.9047],\n",
      "        [2.6735, 2.7042],\n",
      "        [2.5560, 2.5232],\n",
      "        [2.7318, 2.4316],\n",
      "        [2.3979, 2.6112],\n",
      "        [3.0288, 2.6778],\n",
      "        [2.3572, 2.8375],\n",
      "        [3.1174, 2.4370],\n",
      "        [2.6566, 2.6229],\n",
      "        [2.4507, 3.0671],\n",
      "        [2.5745, 2.6242],\n",
      "        [2.7230, 3.1961],\n",
      "        [2.8260, 2.5925],\n",
      "        [2.5992, 2.6204],\n",
      "        [2.7181, 2.6921],\n",
      "        [2.6822, 2.8461],\n",
      "        [2.8914, 2.6329],\n",
      "        [2.7066, 2.8028],\n",
      "        [2.7300, 3.0504],\n",
      "        [2.6415, 3.0656],\n",
      "        [2.7607, 2.8073],\n",
      "        [2.9623, 2.4967],\n",
      "        [2.9024, 2.9081],\n",
      "        [3.0716, 2.4603],\n",
      "        [3.0302, 2.9176],\n",
      "        [2.5615, 2.6619],\n",
      "        [2.4131, 2.8770],\n",
      "        [2.7383, 2.8117],\n",
      "        [2.9089, 2.8168],\n",
      "        [2.2895, 2.3722],\n",
      "        [2.4585, 2.7217],\n",
      "        [2.4909, 2.7818],\n",
      "        [2.6603, 2.8591],\n",
      "        [2.5630, 3.0050],\n",
      "        [2.5645, 2.5922],\n",
      "        [2.6677, 2.7029],\n",
      "        [2.1865, 2.6092],\n",
      "        [3.0339, 2.7002],\n",
      "        [2.2297, 3.3970],\n",
      "        [2.6231, 2.8538],\n",
      "        [2.1982, 2.4450],\n",
      "        [2.5318, 2.2543],\n",
      "        [2.8191, 2.4440],\n",
      "        [2.2656, 2.6340],\n",
      "        [2.8175, 2.8659],\n",
      "        [2.3632, 2.6041],\n",
      "        [2.7209, 2.4529],\n",
      "        [2.7950, 2.5926],\n",
      "        [2.6427, 2.5107]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8369, 2.4609],\n",
      "        [2.5614, 2.2591],\n",
      "        [2.4011, 2.4535],\n",
      "        [2.7517, 2.4583],\n",
      "        [2.5743, 2.0615],\n",
      "        [2.4115, 2.8769],\n",
      "        [2.7298, 3.0595],\n",
      "        [2.1276, 2.6988],\n",
      "        [2.8586, 2.4651],\n",
      "        [2.4663, 2.8847],\n",
      "        [2.5017, 2.6210],\n",
      "        [2.8047, 2.5978],\n",
      "        [2.1636, 2.6425],\n",
      "        [2.6107, 2.4777],\n",
      "        [2.9002, 2.6835],\n",
      "        [2.9496, 2.7449],\n",
      "        [2.7224, 2.7048],\n",
      "        [3.0742, 3.1575],\n",
      "        [3.1512, 2.4017],\n",
      "        [2.9255, 2.9677],\n",
      "        [2.4435, 2.6253],\n",
      "        [2.9170, 2.8124],\n",
      "        [2.6600, 2.4117],\n",
      "        [2.9242, 2.5826],\n",
      "        [2.7696, 2.5401],\n",
      "        [2.3231, 2.5290],\n",
      "        [2.1705, 2.7877],\n",
      "        [2.5488, 2.6803],\n",
      "        [2.4502, 2.7583],\n",
      "        [2.7622, 2.1792],\n",
      "        [2.4141, 2.5594],\n",
      "        [2.1881, 2.7024],\n",
      "        [2.2589, 2.4326],\n",
      "        [2.1280, 2.7528],\n",
      "        [2.9684, 2.8167],\n",
      "        [2.5771, 2.3651],\n",
      "        [2.1220, 2.6737],\n",
      "        [2.6651, 2.8715],\n",
      "        [2.9196, 2.9592],\n",
      "        [2.9517, 2.6592],\n",
      "        [2.8766, 2.8687],\n",
      "        [2.6570, 2.9392],\n",
      "        [2.6188, 2.5087],\n",
      "        [2.6461, 2.7816],\n",
      "        [2.5732, 2.9290],\n",
      "        [2.3582, 2.2462],\n",
      "        [2.4667, 2.7422],\n",
      "        [2.4776, 2.5340],\n",
      "        [2.9053, 3.0059],\n",
      "        [2.6408, 3.1515],\n",
      "        [1.8729, 2.5026],\n",
      "        [2.5247, 2.3072],\n",
      "        [2.5950, 2.7121],\n",
      "        [2.7072, 2.3735],\n",
      "        [2.7935, 2.2799],\n",
      "        [2.5579, 2.8129],\n",
      "        [2.9236, 2.9405],\n",
      "        [2.8872, 2.4043],\n",
      "        [2.5938, 3.0236],\n",
      "        [2.8039, 2.1752],\n",
      "        [2.1638, 2.6638],\n",
      "        [2.8105, 2.6253],\n",
      "        [2.4187, 2.7211],\n",
      "        [2.7522, 2.7831],\n",
      "        [2.9106, 2.5815],\n",
      "        [2.4625, 2.2730],\n",
      "        [2.1772, 2.7569],\n",
      "        [2.7143, 2.4305],\n",
      "        [2.2250, 2.3785],\n",
      "        [2.4582, 2.3180],\n",
      "        [2.5335, 3.0318],\n",
      "        [2.8886, 2.7013],\n",
      "        [2.0128, 2.4808],\n",
      "        [2.6907, 2.6509],\n",
      "        [2.8889, 2.6160],\n",
      "        [2.6404, 2.9077],\n",
      "        [2.5150, 2.3985],\n",
      "        [2.4237, 2.3923],\n",
      "        [2.6750, 2.5790],\n",
      "        [2.4296, 2.6802],\n",
      "        [2.5661, 2.4184],\n",
      "        [2.9889, 2.9836],\n",
      "        [2.8921, 2.9488],\n",
      "        [2.5847, 2.5832],\n",
      "        [2.6046, 2.6035],\n",
      "        [2.7764, 2.4153],\n",
      "        [2.6889, 2.9814],\n",
      "        [2.4382, 2.7600],\n",
      "        [2.1184, 2.7019],\n",
      "        [2.3365, 2.7670],\n",
      "        [2.3662, 2.8429],\n",
      "        [2.3867, 2.5360],\n",
      "        [2.4606, 2.7137],\n",
      "        [2.3698, 3.1114],\n",
      "        [2.8468, 1.9103],\n",
      "        [3.1401, 2.4686],\n",
      "        [2.6232, 2.5853],\n",
      "        [2.2837, 2.6777],\n",
      "        [2.7231, 2.9097],\n",
      "        [3.1112, 2.7063]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3303, 2.5637],\n",
      "        [2.4575, 2.8465],\n",
      "        [2.2676, 2.5286],\n",
      "        [2.6176, 2.9987],\n",
      "        [2.8474, 2.6271],\n",
      "        [2.3828, 2.7236],\n",
      "        [2.4746, 2.8357],\n",
      "        [2.5897, 2.7914],\n",
      "        [2.7061, 2.4912],\n",
      "        [2.5240, 2.4397],\n",
      "        [2.6443, 2.2820],\n",
      "        [2.9957, 2.6061],\n",
      "        [2.7885, 2.0852],\n",
      "        [2.7217, 2.4088],\n",
      "        [2.8211, 2.9126],\n",
      "        [2.2868, 2.2859],\n",
      "        [2.9030, 2.9490],\n",
      "        [2.6425, 3.0625],\n",
      "        [2.4902, 2.5265],\n",
      "        [2.8201, 2.4389],\n",
      "        [2.7525, 2.6602],\n",
      "        [2.3847, 2.2443],\n",
      "        [2.3469, 2.2778],\n",
      "        [2.4278, 2.3041],\n",
      "        [2.3660, 2.6139],\n",
      "        [2.9852, 2.7617],\n",
      "        [2.9679, 3.0877],\n",
      "        [2.7803, 2.9899],\n",
      "        [2.7616, 3.0020],\n",
      "        [2.6538, 2.5353],\n",
      "        [2.3014, 2.5682],\n",
      "        [3.0427, 2.7843],\n",
      "        [2.6739, 2.8055],\n",
      "        [2.3584, 2.4090],\n",
      "        [2.4576, 2.3486],\n",
      "        [2.6874, 2.6636],\n",
      "        [2.4596, 2.5921],\n",
      "        [2.4866, 2.6207],\n",
      "        [2.5117, 2.1912],\n",
      "        [2.3566, 2.9203],\n",
      "        [2.6536, 2.8417],\n",
      "        [2.9192, 2.4022],\n",
      "        [2.7199, 2.5665],\n",
      "        [2.4814, 2.4640],\n",
      "        [2.9268, 2.7028],\n",
      "        [2.7993, 2.1588],\n",
      "        [2.9705, 2.7244],\n",
      "        [2.8164, 2.7155],\n",
      "        [2.6478, 2.9488],\n",
      "        [2.7908, 2.5590],\n",
      "        [2.7121, 2.6223],\n",
      "        [2.7793, 3.1030],\n",
      "        [2.5429, 2.4141],\n",
      "        [2.6746, 2.3955],\n",
      "        [2.8290, 2.3673],\n",
      "        [2.5197, 3.1390],\n",
      "        [2.2395, 2.7451],\n",
      "        [2.3631, 2.7543],\n",
      "        [2.7325, 2.9027],\n",
      "        [2.6483, 2.5811],\n",
      "        [2.5787, 2.5489],\n",
      "        [2.4854, 2.5967],\n",
      "        [2.3992, 2.9696],\n",
      "        [2.5818, 2.7607],\n",
      "        [2.2422, 2.6468],\n",
      "        [2.8723, 2.6067],\n",
      "        [2.5510, 2.8401],\n",
      "        [2.5713, 2.6512],\n",
      "        [2.8058, 2.8348],\n",
      "        [2.8578, 2.3744],\n",
      "        [2.7420, 2.9386],\n",
      "        [2.9474, 2.3629],\n",
      "        [2.8418, 2.3913],\n",
      "        [2.2913, 3.0644],\n",
      "        [3.0879, 2.9608],\n",
      "        [2.5948, 2.3223],\n",
      "        [2.5475, 2.8114],\n",
      "        [3.1343, 2.5342],\n",
      "        [2.4308, 2.6206],\n",
      "        [2.6727, 2.5836],\n",
      "        [3.0492, 2.3503],\n",
      "        [2.8154, 2.6540],\n",
      "        [2.8677, 2.2654],\n",
      "        [2.6539, 2.2269],\n",
      "        [2.3850, 2.5449],\n",
      "        [2.6356, 2.7851],\n",
      "        [2.6899, 2.6777],\n",
      "        [2.9060, 2.4301],\n",
      "        [1.9398, 2.7231],\n",
      "        [2.8616, 2.9132],\n",
      "        [2.8483, 2.8902],\n",
      "        [2.9206, 2.9643],\n",
      "        [2.6758, 3.1255],\n",
      "        [2.8747, 2.5785],\n",
      "        [2.6558, 2.6051],\n",
      "        [2.7148, 2.2465],\n",
      "        [2.6773, 2.9024],\n",
      "        [2.4520, 2.6306],\n",
      "        [3.1463, 2.4056],\n",
      "        [2.5392, 2.7887]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 5 complete in 0:00:13.697641; est. finish at 2021-11-29 21:55:54.791463\n",
      "Validation: 0.456 train | 0.52 dev\n",
      "### Epoch: 6 ###\n",
      "y:  tensor([0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8417, 2.6401],\n",
      "        [2.5515, 2.6660],\n",
      "        [2.6307, 2.7701],\n",
      "        [2.5938, 2.6426],\n",
      "        [2.3401, 2.8938],\n",
      "        [2.3243, 2.9726],\n",
      "        [2.9764, 2.6376],\n",
      "        [2.3871, 2.3567],\n",
      "        [2.6119, 2.4556],\n",
      "        [2.3222, 2.7850],\n",
      "        [2.2465, 2.4460],\n",
      "        [2.4690, 2.7163],\n",
      "        [2.5289, 2.4439],\n",
      "        [2.6012, 2.4812],\n",
      "        [2.7012, 2.6514],\n",
      "        [1.8205, 2.4702],\n",
      "        [2.7081, 2.3370],\n",
      "        [2.4503, 2.4792],\n",
      "        [2.5190, 2.7936],\n",
      "        [2.5427, 2.6732],\n",
      "        [2.9679, 2.3184],\n",
      "        [2.5595, 3.0074],\n",
      "        [2.2844, 1.9827],\n",
      "        [2.5596, 2.7767],\n",
      "        [2.0765, 2.7980],\n",
      "        [2.2753, 3.0116],\n",
      "        [2.1099, 2.5672],\n",
      "        [2.4060, 2.3279],\n",
      "        [2.7292, 2.4879],\n",
      "        [2.5389, 2.8003],\n",
      "        [2.3355, 2.2522],\n",
      "        [2.5998, 2.3467],\n",
      "        [2.8570, 2.7192],\n",
      "        [2.3337, 2.7058],\n",
      "        [2.3054, 2.2753],\n",
      "        [2.5407, 2.0317],\n",
      "        [2.7318, 2.8175],\n",
      "        [3.0551, 2.0418],\n",
      "        [2.7305, 2.6479],\n",
      "        [2.6298, 2.6857],\n",
      "        [2.3951, 2.1740],\n",
      "        [2.5125, 2.3943],\n",
      "        [2.4868, 2.5673],\n",
      "        [2.7992, 2.4931],\n",
      "        [2.2154, 2.2684],\n",
      "        [2.7041, 2.9702],\n",
      "        [2.5626, 2.2184],\n",
      "        [2.3335, 2.4071],\n",
      "        [2.3687, 2.6033],\n",
      "        [2.6259, 3.0261],\n",
      "        [3.0144, 1.9946],\n",
      "        [2.6863, 2.6579],\n",
      "        [2.3591, 2.4626],\n",
      "        [2.3648, 3.0977],\n",
      "        [2.3153, 2.4865],\n",
      "        [2.6094, 2.4195],\n",
      "        [2.4122, 2.3167],\n",
      "        [2.2041, 2.6510],\n",
      "        [2.8115, 2.6099],\n",
      "        [2.3725, 2.2444],\n",
      "        [2.7245, 2.2712],\n",
      "        [2.1638, 2.4244],\n",
      "        [2.8338, 2.6955],\n",
      "        [2.1771, 2.7733],\n",
      "        [2.7652, 2.3752],\n",
      "        [2.4739, 2.1514],\n",
      "        [2.4095, 2.7254],\n",
      "        [2.4900, 3.0622],\n",
      "        [2.5517, 3.0401],\n",
      "        [2.7408, 3.0510],\n",
      "        [2.4248, 2.8957],\n",
      "        [2.6259, 2.8556],\n",
      "        [2.7001, 2.4777],\n",
      "        [2.2473, 2.8315],\n",
      "        [2.6552, 2.5810],\n",
      "        [2.5226, 3.0891],\n",
      "        [2.4724, 2.7820],\n",
      "        [2.2121, 2.6318],\n",
      "        [2.1071, 2.2703],\n",
      "        [2.4190, 2.9043],\n",
      "        [2.6094, 2.6494],\n",
      "        [2.6420, 2.4598],\n",
      "        [2.2642, 2.9448],\n",
      "        [2.6790, 2.4034],\n",
      "        [2.3335, 2.5541],\n",
      "        [2.0722, 2.5151],\n",
      "        [2.5617, 2.3814],\n",
      "        [2.4237, 2.5545],\n",
      "        [2.3682, 2.6731],\n",
      "        [2.9445, 2.2651],\n",
      "        [2.3191, 2.5698],\n",
      "        [2.6049, 2.4917],\n",
      "        [2.4393, 2.6030],\n",
      "        [2.5041, 2.3647],\n",
      "        [2.2021, 2.6880],\n",
      "        [2.2222, 2.3257],\n",
      "        [2.5592, 2.6455],\n",
      "        [2.2136, 2.8069],\n",
      "        [2.7093, 2.6114],\n",
      "        [2.3355, 3.0614]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7572, 2.9137],\n",
      "        [2.7318, 2.7245],\n",
      "        [2.7249, 2.7350],\n",
      "        [2.7085, 2.6832],\n",
      "        [2.6870, 2.4847],\n",
      "        [2.5988, 2.4953],\n",
      "        [2.6972, 2.5426],\n",
      "        [2.6108, 2.2550],\n",
      "        [2.4958, 2.2350],\n",
      "        [2.4739, 2.6727],\n",
      "        [2.6315, 2.1179],\n",
      "        [2.7724, 3.0279],\n",
      "        [2.6231, 2.5344],\n",
      "        [2.9801, 2.6804],\n",
      "        [2.5179, 2.9052],\n",
      "        [2.6106, 2.4807],\n",
      "        [2.6265, 2.6805],\n",
      "        [2.5640, 2.8502],\n",
      "        [2.4248, 2.5964],\n",
      "        [2.6284, 2.5328],\n",
      "        [2.2963, 2.9027],\n",
      "        [2.5315, 2.7087],\n",
      "        [2.5399, 2.2670],\n",
      "        [2.5516, 2.8278],\n",
      "        [2.1921, 2.7041],\n",
      "        [2.3418, 3.0270],\n",
      "        [2.6681, 2.3408],\n",
      "        [2.3267, 2.1166],\n",
      "        [3.0662, 2.5941],\n",
      "        [2.4090, 2.5149],\n",
      "        [2.2471, 2.6809],\n",
      "        [2.6227, 2.8499],\n",
      "        [2.5109, 2.6628],\n",
      "        [2.6792, 2.6716],\n",
      "        [3.0565, 2.4365],\n",
      "        [2.1283, 2.3333],\n",
      "        [2.3448, 3.0980],\n",
      "        [2.4562, 2.6134],\n",
      "        [2.7917, 2.8160],\n",
      "        [2.6093, 3.0304],\n",
      "        [2.2401, 3.0906],\n",
      "        [2.7965, 3.0444],\n",
      "        [2.2925, 2.8239],\n",
      "        [3.0816, 2.6987],\n",
      "        [2.8108, 2.4214],\n",
      "        [2.7809, 2.5969],\n",
      "        [2.5134, 1.9787],\n",
      "        [2.7772, 2.8021],\n",
      "        [2.3749, 2.5834],\n",
      "        [2.3092, 2.1322],\n",
      "        [2.3380, 2.4304],\n",
      "        [2.4924, 2.6099],\n",
      "        [2.8369, 2.7140],\n",
      "        [2.5739, 2.7318],\n",
      "        [2.5769, 2.5352],\n",
      "        [2.5327, 2.5177],\n",
      "        [2.9516, 2.3590],\n",
      "        [2.5756, 2.6094],\n",
      "        [2.7561, 2.1626],\n",
      "        [2.4449, 2.5755],\n",
      "        [2.4331, 2.5696],\n",
      "        [1.9989, 3.1923],\n",
      "        [2.5493, 2.4628],\n",
      "        [2.8169, 2.7876],\n",
      "        [2.6155, 2.7814],\n",
      "        [2.6412, 2.5022],\n",
      "        [2.3896, 2.4769],\n",
      "        [2.7014, 2.2674],\n",
      "        [2.6269, 2.4290],\n",
      "        [2.4650, 2.9302],\n",
      "        [2.6463, 2.5560],\n",
      "        [2.3954, 3.1539],\n",
      "        [2.4413, 2.3754],\n",
      "        [2.6281, 2.4242],\n",
      "        [2.2833, 2.4853],\n",
      "        [3.0522, 2.5997],\n",
      "        [2.6826, 2.8937],\n",
      "        [2.7353, 2.4695],\n",
      "        [2.3390, 2.6117],\n",
      "        [2.4586, 2.6310],\n",
      "        [2.5662, 2.4448],\n",
      "        [1.8878, 2.6671],\n",
      "        [2.5647, 2.3508],\n",
      "        [2.3205, 2.4667],\n",
      "        [2.4889, 2.7481],\n",
      "        [2.2807, 2.3417],\n",
      "        [2.6194, 2.2617],\n",
      "        [2.6607, 2.6160],\n",
      "        [2.3256, 2.4104],\n",
      "        [2.2136, 2.7375],\n",
      "        [2.6992, 2.5650],\n",
      "        [2.3326, 2.3617],\n",
      "        [2.3256, 2.6257],\n",
      "        [2.7853, 2.8531],\n",
      "        [2.4956, 2.8747],\n",
      "        [2.5252, 2.8872],\n",
      "        [2.3070, 2.5083],\n",
      "        [2.3354, 2.3125],\n",
      "        [2.4928, 2.6140],\n",
      "        [2.8623, 2.3526]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3080, 3.0878],\n",
      "        [2.1340, 2.7000],\n",
      "        [2.1927, 2.5467],\n",
      "        [2.5918, 2.6512],\n",
      "        [3.0081, 2.2935],\n",
      "        [2.7078, 2.3341],\n",
      "        [2.5755, 2.5160],\n",
      "        [2.8120, 2.5356],\n",
      "        [2.2059, 2.5299],\n",
      "        [2.3284, 2.4848],\n",
      "        [2.8002, 2.2333],\n",
      "        [2.0712, 2.9399],\n",
      "        [2.7146, 1.8987],\n",
      "        [2.8558, 2.5950],\n",
      "        [2.6336, 2.8732],\n",
      "        [2.5570, 2.2953],\n",
      "        [2.6638, 2.1980],\n",
      "        [2.7662, 2.7658],\n",
      "        [2.6777, 2.5412],\n",
      "        [3.1885, 3.4372],\n",
      "        [3.1791, 2.4930],\n",
      "        [2.6163, 2.4031],\n",
      "        [2.6991, 1.8900],\n",
      "        [2.2401, 2.5387],\n",
      "        [2.3216, 2.8168],\n",
      "        [2.3624, 2.7549],\n",
      "        [2.8604, 2.5655],\n",
      "        [2.2870, 2.4186],\n",
      "        [2.4774, 2.9583],\n",
      "        [2.8066, 2.3269],\n",
      "        [2.7459, 2.2443],\n",
      "        [2.4369, 2.7037],\n",
      "        [2.9270, 2.4066],\n",
      "        [2.8373, 2.4319],\n",
      "        [2.3060, 2.2603],\n",
      "        [2.6234, 2.6792],\n",
      "        [2.6379, 2.8675],\n",
      "        [2.3297, 2.6443],\n",
      "        [2.6147, 3.1284],\n",
      "        [2.3059, 2.7133],\n",
      "        [2.2851, 2.8041],\n",
      "        [2.5368, 2.5979],\n",
      "        [2.5026, 2.7226],\n",
      "        [2.4749, 2.7390],\n",
      "        [2.5662, 2.0928],\n",
      "        [2.7646, 3.1365],\n",
      "        [2.6169, 2.6393],\n",
      "        [2.4748, 2.2174],\n",
      "        [2.8093, 2.4771],\n",
      "        [2.9834, 2.6687],\n",
      "        [2.3248, 2.2328],\n",
      "        [2.4830, 2.9160],\n",
      "        [2.0049, 2.8460],\n",
      "        [2.5126, 2.2683],\n",
      "        [2.6287, 2.7622],\n",
      "        [2.3950, 2.9308],\n",
      "        [2.4082, 2.2096],\n",
      "        [2.7436, 2.6009],\n",
      "        [2.7393, 2.7851],\n",
      "        [2.6780, 2.5089],\n",
      "        [2.8062, 2.3503],\n",
      "        [2.5654, 2.3877],\n",
      "        [2.9471, 2.2064],\n",
      "        [2.4755, 2.5700],\n",
      "        [2.3447, 2.4587],\n",
      "        [2.5027, 2.5120],\n",
      "        [2.8270, 2.8769],\n",
      "        [2.2479, 2.4698],\n",
      "        [2.6439, 2.8441],\n",
      "        [2.5040, 2.6980],\n",
      "        [2.5048, 2.0869],\n",
      "        [2.4197, 2.6521],\n",
      "        [2.7150, 2.5680],\n",
      "        [2.4202, 2.4976],\n",
      "        [2.4290, 2.8058],\n",
      "        [2.6450, 2.2839],\n",
      "        [2.6311, 2.4326],\n",
      "        [2.2891, 2.3806],\n",
      "        [2.5164, 2.5138],\n",
      "        [2.4731, 2.5444],\n",
      "        [2.2285, 2.8093],\n",
      "        [2.2422, 2.2181],\n",
      "        [2.5905, 2.5017],\n",
      "        [2.1786, 2.4354],\n",
      "        [2.6559, 2.5991],\n",
      "        [2.6106, 2.2877],\n",
      "        [2.5906, 2.5229],\n",
      "        [3.1358, 2.9958],\n",
      "        [3.0720, 2.4258],\n",
      "        [2.2574, 2.5214],\n",
      "        [2.2656, 3.1839],\n",
      "        [2.6702, 2.5467],\n",
      "        [2.1393, 2.5896],\n",
      "        [2.3940, 2.5435],\n",
      "        [2.8961, 2.3066],\n",
      "        [2.2754, 2.2239],\n",
      "        [2.1465, 2.6329],\n",
      "        [2.3631, 2.5563],\n",
      "        [2.5523, 2.9389],\n",
      "        [2.5620, 2.3197]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3360, 2.3159],\n",
      "        [1.9217, 2.8117],\n",
      "        [2.9015, 2.7702],\n",
      "        [2.8520, 2.5721],\n",
      "        [2.7215, 2.4581],\n",
      "        [2.5254, 2.7632],\n",
      "        [2.3513, 2.8925],\n",
      "        [2.3915, 2.4260],\n",
      "        [2.1310, 2.5682],\n",
      "        [2.8097, 2.6099],\n",
      "        [2.9439, 2.4251],\n",
      "        [2.5689, 2.5581],\n",
      "        [2.2693, 2.3646],\n",
      "        [3.1161, 2.3344],\n",
      "        [2.5733, 2.8665],\n",
      "        [2.4438, 2.4959],\n",
      "        [2.1859, 2.6730],\n",
      "        [2.7607, 2.5794],\n",
      "        [2.6313, 2.5318],\n",
      "        [2.4773, 2.3417],\n",
      "        [2.8339, 2.3805],\n",
      "        [2.7601, 2.4364],\n",
      "        [2.7452, 2.6593],\n",
      "        [2.3892, 2.8003],\n",
      "        [2.5617, 2.4163],\n",
      "        [2.6179, 2.8060],\n",
      "        [2.8851, 3.0098],\n",
      "        [2.8151, 3.0591],\n",
      "        [2.2829, 2.7582],\n",
      "        [2.5945, 2.4901],\n",
      "        [2.3001, 2.2469],\n",
      "        [2.7281, 1.9192],\n",
      "        [2.7184, 2.4892],\n",
      "        [2.3153, 2.6246],\n",
      "        [2.6751, 2.3649],\n",
      "        [1.9157, 2.2143],\n",
      "        [2.2576, 2.2395],\n",
      "        [2.3304, 2.6488],\n",
      "        [2.6669, 2.2465],\n",
      "        [2.7100, 2.7359],\n",
      "        [2.1556, 2.0954],\n",
      "        [3.0171, 2.6732],\n",
      "        [2.4597, 2.1953],\n",
      "        [2.5116, 2.8775],\n",
      "        [2.4564, 2.6771],\n",
      "        [2.6743, 2.5517],\n",
      "        [2.2200, 2.2620],\n",
      "        [2.8854, 2.0514],\n",
      "        [2.4354, 2.1753],\n",
      "        [2.4987, 2.5725],\n",
      "        [2.7757, 2.8881],\n",
      "        [2.3942, 2.5477],\n",
      "        [2.6007, 2.7665],\n",
      "        [2.9625, 2.6661],\n",
      "        [3.2002, 2.7235],\n",
      "        [2.6110, 2.7100],\n",
      "        [2.4546, 2.3734],\n",
      "        [2.4089, 2.5562],\n",
      "        [2.7794, 2.7524],\n",
      "        [2.7933, 2.2835],\n",
      "        [2.6781, 2.3905],\n",
      "        [2.5528, 2.8798],\n",
      "        [2.5881, 2.4724],\n",
      "        [2.5069, 2.6633],\n",
      "        [2.7339, 2.7973],\n",
      "        [2.3843, 2.4236],\n",
      "        [2.4300, 3.0204],\n",
      "        [2.3897, 2.1511],\n",
      "        [2.8989, 2.4178],\n",
      "        [2.7968, 2.4838],\n",
      "        [2.9233, 2.5577],\n",
      "        [2.7929, 2.1695],\n",
      "        [2.6230, 2.5457],\n",
      "        [2.5621, 2.5093],\n",
      "        [2.2059, 2.1558],\n",
      "        [2.3028, 2.7590],\n",
      "        [2.4940, 2.3885],\n",
      "        [2.7593, 2.4702],\n",
      "        [3.0081, 2.9267],\n",
      "        [2.5438, 2.9301],\n",
      "        [2.7957, 2.4425],\n",
      "        [2.0052, 2.2619],\n",
      "        [2.7794, 2.5160],\n",
      "        [2.6283, 2.7732],\n",
      "        [2.8624, 2.3512],\n",
      "        [2.2501, 2.2456],\n",
      "        [2.9729, 2.4942],\n",
      "        [2.5322, 2.6246],\n",
      "        [2.9418, 2.5351],\n",
      "        [2.4929, 2.1656],\n",
      "        [2.6082, 2.6311],\n",
      "        [2.6006, 2.3764],\n",
      "        [2.5559, 2.6662],\n",
      "        [2.6669, 2.7655],\n",
      "        [2.5987, 2.7269],\n",
      "        [2.7611, 2.5627],\n",
      "        [2.3993, 2.5147],\n",
      "        [2.5683, 2.4891],\n",
      "        [2.4503, 2.8002],\n",
      "        [2.4609, 2.9977]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6202, 2.5139],\n",
      "        [2.7387, 2.6417],\n",
      "        [2.7416, 2.7551],\n",
      "        [2.5358, 2.6447],\n",
      "        [2.6339, 3.1478],\n",
      "        [2.1938, 2.4807],\n",
      "        [2.9826, 2.6444],\n",
      "        [2.2263, 2.8600],\n",
      "        [3.1683, 2.5150],\n",
      "        [2.8078, 2.6764],\n",
      "        [2.2646, 2.4420],\n",
      "        [2.8578, 3.0151],\n",
      "        [2.6532, 2.2473],\n",
      "        [2.6292, 2.6438],\n",
      "        [2.2485, 2.8801],\n",
      "        [2.7196, 2.4289],\n",
      "        [2.5112, 2.7141],\n",
      "        [2.6576, 1.9667],\n",
      "        [2.5360, 2.3118],\n",
      "        [2.9193, 2.5827],\n",
      "        [2.3404, 2.5840],\n",
      "        [2.4550, 2.6981],\n",
      "        [2.4847, 2.1325],\n",
      "        [2.5600, 2.7289],\n",
      "        [2.9072, 2.0188],\n",
      "        [2.9077, 2.1536],\n",
      "        [2.4798, 2.2896],\n",
      "        [2.7756, 2.7715],\n",
      "        [2.8193, 2.6939],\n",
      "        [2.6520, 2.8586],\n",
      "        [2.3949, 2.9098],\n",
      "        [2.3471, 2.2496],\n",
      "        [2.7327, 2.0246],\n",
      "        [2.6589, 2.2307],\n",
      "        [2.8503, 2.3890],\n",
      "        [2.6046, 2.4600],\n",
      "        [3.0129, 2.5870],\n",
      "        [2.4137, 2.6144],\n",
      "        [2.3552, 2.6125],\n",
      "        [2.9302, 2.6051],\n",
      "        [2.4993, 2.0518],\n",
      "        [2.6836, 2.5705],\n",
      "        [2.4881, 2.3838],\n",
      "        [2.8116, 2.5465],\n",
      "        [2.3151, 2.3987],\n",
      "        [2.3041, 2.7980],\n",
      "        [2.6887, 1.8857],\n",
      "        [2.4120, 2.4642],\n",
      "        [2.2507, 2.9559],\n",
      "        [2.4117, 2.5776],\n",
      "        [2.1957, 2.4402],\n",
      "        [2.1965, 2.3044],\n",
      "        [2.4826, 2.8426],\n",
      "        [2.3229, 2.8954],\n",
      "        [2.8589, 2.5156],\n",
      "        [2.7609, 2.7598],\n",
      "        [2.4572, 2.8319],\n",
      "        [2.6795, 2.5360],\n",
      "        [2.5974, 2.5035],\n",
      "        [2.5608, 2.5192],\n",
      "        [2.4383, 2.7244],\n",
      "        [2.6491, 2.1142],\n",
      "        [2.2750, 3.0104],\n",
      "        [2.4532, 2.4945],\n",
      "        [2.9250, 2.8775],\n",
      "        [2.9945, 2.5353],\n",
      "        [3.0100, 2.1417],\n",
      "        [2.2973, 2.0827],\n",
      "        [2.5282, 2.4001],\n",
      "        [3.0705, 2.6128],\n",
      "        [2.1243, 2.9088],\n",
      "        [2.3758, 2.2920],\n",
      "        [2.7224, 2.6813],\n",
      "        [2.8031, 2.9841],\n",
      "        [2.8978, 2.3570],\n",
      "        [2.4428, 2.6423],\n",
      "        [2.7817, 2.7745],\n",
      "        [2.3042, 2.4170],\n",
      "        [2.7088, 2.1959],\n",
      "        [2.5121, 2.8325],\n",
      "        [2.7933, 2.4433],\n",
      "        [2.4513, 2.2313],\n",
      "        [2.3055, 3.0875],\n",
      "        [2.4564, 2.2297],\n",
      "        [2.9324, 2.8396],\n",
      "        [2.2172, 2.6822],\n",
      "        [2.7637, 2.1856],\n",
      "        [2.3659, 2.9313],\n",
      "        [2.7262, 2.9117],\n",
      "        [1.7954, 2.8308],\n",
      "        [2.8071, 2.1402],\n",
      "        [2.2998, 2.4916],\n",
      "        [2.5108, 2.9030],\n",
      "        [2.3606, 2.4091],\n",
      "        [2.5411, 2.6812],\n",
      "        [1.8830, 2.7289],\n",
      "        [2.2024, 2.5743],\n",
      "        [2.7701, 2.1989],\n",
      "        [2.6135, 2.7504],\n",
      "        [2.8232, 3.1412]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 10 complete in 0:00:28.399157; est. finish at 2021-11-29 21:56:04.830263\n",
      "Validation: 0.502 train | 0.498 dev\n",
      "### Epoch: 11 ###\n",
      "y:  tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5569, 2.4184],\n",
      "        [2.4184, 2.3770],\n",
      "        [2.8607, 2.3186],\n",
      "        [2.6233, 2.5554],\n",
      "        [2.2937, 2.1421],\n",
      "        [2.3296, 2.1337],\n",
      "        [2.4384, 2.5202],\n",
      "        [2.7342, 2.4204],\n",
      "        [2.7615, 2.7997],\n",
      "        [3.1493, 2.1891],\n",
      "        [2.4947, 2.5482],\n",
      "        [2.5732, 2.6567],\n",
      "        [2.3646, 2.9258],\n",
      "        [2.8257, 2.2972],\n",
      "        [2.5276, 2.6323],\n",
      "        [2.5438, 2.3776],\n",
      "        [2.1365, 2.9538],\n",
      "        [2.7875, 2.4650],\n",
      "        [2.6446, 2.4522],\n",
      "        [2.4815, 3.1638],\n",
      "        [2.4338, 2.4482],\n",
      "        [2.5482, 2.6502],\n",
      "        [2.7048, 2.3951],\n",
      "        [2.2915, 2.6824],\n",
      "        [2.0414, 2.7487],\n",
      "        [2.8164, 2.4889],\n",
      "        [2.7231, 2.4653],\n",
      "        [2.4766, 2.2498],\n",
      "        [2.5064, 2.5116],\n",
      "        [2.6150, 2.6497],\n",
      "        [2.3733, 2.7414],\n",
      "        [2.5024, 2.5064],\n",
      "        [2.6523, 2.1920],\n",
      "        [2.3350, 2.3664],\n",
      "        [2.6143, 2.1547],\n",
      "        [2.8118, 2.4347],\n",
      "        [2.3494, 2.4604],\n",
      "        [2.3646, 2.6465],\n",
      "        [2.0976, 2.4711],\n",
      "        [2.4788, 2.2621],\n",
      "        [2.3508, 2.1518],\n",
      "        [2.6077, 2.4796],\n",
      "        [2.8795, 2.3714],\n",
      "        [2.5757, 2.4606],\n",
      "        [2.2459, 3.1824],\n",
      "        [2.3581, 2.7646],\n",
      "        [2.6239, 2.8046],\n",
      "        [2.7574, 2.2997],\n",
      "        [2.6713, 2.7097],\n",
      "        [2.4538, 2.6070],\n",
      "        [2.4953, 2.5824],\n",
      "        [2.9153, 2.4700],\n",
      "        [2.6611, 2.3744],\n",
      "        [3.0365, 2.6864],\n",
      "        [2.5022, 2.6518],\n",
      "        [2.4402, 2.7440],\n",
      "        [2.7986, 2.6817],\n",
      "        [2.6752, 2.8740],\n",
      "        [2.6687, 2.8006],\n",
      "        [3.0782, 2.8969],\n",
      "        [2.5928, 2.4682],\n",
      "        [2.4875, 1.8387],\n",
      "        [2.4121, 2.7871],\n",
      "        [2.4028, 2.1938],\n",
      "        [2.8601, 2.5569],\n",
      "        [2.1655, 2.6361],\n",
      "        [2.0274, 2.5342],\n",
      "        [2.6904, 2.1089],\n",
      "        [2.4326, 2.4993],\n",
      "        [2.3635, 2.6032],\n",
      "        [2.6672, 2.2139],\n",
      "        [2.1450, 2.8355],\n",
      "        [2.6680, 2.7189],\n",
      "        [2.4300, 2.2787],\n",
      "        [2.6661, 2.7594],\n",
      "        [2.6014, 2.5689],\n",
      "        [2.5383, 2.4581],\n",
      "        [2.7995, 2.3893],\n",
      "        [2.3486, 2.1721],\n",
      "        [2.4350, 2.4343],\n",
      "        [2.6574, 2.7923],\n",
      "        [2.4924, 2.7169],\n",
      "        [2.9294, 2.8136],\n",
      "        [2.5239, 2.3966],\n",
      "        [2.6681, 2.4985],\n",
      "        [2.6302, 2.6381],\n",
      "        [2.3356, 2.5221],\n",
      "        [2.4996, 2.1253],\n",
      "        [2.8421, 2.9323],\n",
      "        [2.3897, 2.7302],\n",
      "        [2.4715, 2.7156],\n",
      "        [2.6533, 2.5460],\n",
      "        [2.6631, 2.5453],\n",
      "        [2.3891, 2.5015],\n",
      "        [3.0572, 2.3475],\n",
      "        [2.7680, 3.1779],\n",
      "        [3.0044, 2.6743],\n",
      "        [2.9141, 2.3000],\n",
      "        [2.5976, 2.5179],\n",
      "        [3.0758, 2.7090]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7226, 2.2159],\n",
      "        [2.7038, 2.6352],\n",
      "        [2.3880, 2.3928],\n",
      "        [1.8587, 2.5556],\n",
      "        [2.2149, 2.7733],\n",
      "        [2.3991, 2.3942],\n",
      "        [2.3586, 2.6676],\n",
      "        [2.8136, 2.2875],\n",
      "        [2.5589, 2.3731],\n",
      "        [2.5400, 2.5379],\n",
      "        [2.4702, 2.3346],\n",
      "        [2.6827, 2.5599],\n",
      "        [2.5528, 2.4226],\n",
      "        [2.7712, 3.0223],\n",
      "        [2.2286, 2.4143],\n",
      "        [2.6343, 2.5735],\n",
      "        [2.8738, 2.6907],\n",
      "        [2.7317, 2.6366],\n",
      "        [2.5641, 2.5999],\n",
      "        [2.9679, 2.9571],\n",
      "        [2.4905, 2.6504],\n",
      "        [2.7053, 2.4403],\n",
      "        [2.1243, 2.5410],\n",
      "        [2.5662, 2.0143],\n",
      "        [2.8545, 2.5185],\n",
      "        [2.5672, 2.8815],\n",
      "        [2.1248, 2.6618],\n",
      "        [2.3105, 2.5447],\n",
      "        [2.4923, 2.1314],\n",
      "        [2.8156, 2.6032],\n",
      "        [2.7674, 2.2906],\n",
      "        [2.3304, 2.2335],\n",
      "        [1.9282, 2.4746],\n",
      "        [2.5063, 2.8052],\n",
      "        [2.1299, 2.6515],\n",
      "        [2.3377, 2.7224],\n",
      "        [2.1017, 2.4535],\n",
      "        [2.8868, 2.4090],\n",
      "        [2.8353, 2.5634],\n",
      "        [3.0191, 2.7670],\n",
      "        [2.4286, 2.6391],\n",
      "        [2.3754, 2.8738],\n",
      "        [2.5131, 1.9772],\n",
      "        [2.6421, 2.1860],\n",
      "        [2.4827, 2.5501],\n",
      "        [2.8211, 2.5649],\n",
      "        [2.6758, 2.8538],\n",
      "        [2.2383, 2.5886],\n",
      "        [2.4701, 2.4598],\n",
      "        [2.3348, 2.4064],\n",
      "        [2.8520, 2.4884],\n",
      "        [3.1201, 2.9430],\n",
      "        [3.0963, 2.6304],\n",
      "        [2.2322, 2.3284],\n",
      "        [2.1166, 2.5300],\n",
      "        [2.3890, 2.5765],\n",
      "        [2.6897, 2.3450],\n",
      "        [2.6642, 2.5941],\n",
      "        [2.4211, 3.0263],\n",
      "        [3.0573, 2.6977],\n",
      "        [2.4994, 2.3854],\n",
      "        [2.4889, 2.5647],\n",
      "        [2.4409, 2.7800],\n",
      "        [2.6856, 2.5897],\n",
      "        [2.6971, 2.2928],\n",
      "        [2.4516, 2.3551],\n",
      "        [2.2967, 2.4417],\n",
      "        [2.8221, 2.8070],\n",
      "        [2.5135, 2.4819],\n",
      "        [2.6707, 2.5420],\n",
      "        [2.2134, 2.6829],\n",
      "        [2.6306, 2.6320],\n",
      "        [2.6459, 2.1480],\n",
      "        [2.5738, 2.8068],\n",
      "        [2.6505, 2.8062],\n",
      "        [3.0107, 2.6871],\n",
      "        [2.7589, 2.4212],\n",
      "        [2.4388, 2.8112],\n",
      "        [2.5910, 2.2545],\n",
      "        [2.3589, 2.6379],\n",
      "        [2.4204, 2.0274],\n",
      "        [2.5090, 2.0733],\n",
      "        [2.5517, 2.6385],\n",
      "        [3.1253, 2.8327],\n",
      "        [2.3205, 2.1644],\n",
      "        [1.6105, 2.4862],\n",
      "        [2.7675, 2.8628],\n",
      "        [2.8461, 2.4057],\n",
      "        [3.2993, 2.6892],\n",
      "        [2.7650, 2.8230],\n",
      "        [2.4306, 2.4411],\n",
      "        [2.1465, 2.7027],\n",
      "        [2.6683, 2.5985],\n",
      "        [2.3961, 2.3435],\n",
      "        [2.4641, 2.3662],\n",
      "        [2.2126, 2.3761],\n",
      "        [1.9735, 2.0627],\n",
      "        [2.8382, 2.3125],\n",
      "        [2.5751, 2.5673],\n",
      "        [2.4950, 2.3446]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.4558, 2.0567],\n",
      "        [3.0950, 2.6549],\n",
      "        [2.1300, 2.5716],\n",
      "        [2.8486, 2.4475],\n",
      "        [2.6233, 2.5573],\n",
      "        [2.3975, 2.3175],\n",
      "        [2.7548, 2.7402],\n",
      "        [2.6957, 2.9271],\n",
      "        [2.3399, 2.4517],\n",
      "        [2.4526, 2.8071],\n",
      "        [2.4818, 2.7419],\n",
      "        [2.6899, 2.6397],\n",
      "        [2.5669, 2.6254],\n",
      "        [2.4975, 2.5913],\n",
      "        [2.7999, 2.6279],\n",
      "        [2.9819, 2.5196],\n",
      "        [2.5309, 2.2241],\n",
      "        [2.2345, 2.9217],\n",
      "        [3.1376, 2.7395],\n",
      "        [2.6382, 2.9372],\n",
      "        [2.5292, 2.5926],\n",
      "        [2.7558, 2.1881],\n",
      "        [2.6944, 2.6639],\n",
      "        [2.3295, 2.7556],\n",
      "        [2.9972, 2.2287],\n",
      "        [2.8987, 2.3490],\n",
      "        [2.3745, 2.4687],\n",
      "        [2.3965, 2.4421],\n",
      "        [2.6885, 2.4450],\n",
      "        [2.1199, 2.6771],\n",
      "        [2.6089, 2.7910],\n",
      "        [2.5454, 1.8874],\n",
      "        [2.6264, 2.9612],\n",
      "        [2.4700, 2.3940],\n",
      "        [2.3904, 2.3212],\n",
      "        [2.6310, 2.3994],\n",
      "        [3.1354, 2.4950],\n",
      "        [2.6057, 2.6673],\n",
      "        [2.6319, 2.4173],\n",
      "        [2.4182, 2.8028],\n",
      "        [2.9249, 2.4997],\n",
      "        [2.8931, 2.1230],\n",
      "        [2.4435, 2.5360],\n",
      "        [2.5508, 2.4271],\n",
      "        [2.5405, 2.4434],\n",
      "        [2.5602, 3.2031],\n",
      "        [2.4745, 2.5253],\n",
      "        [2.6383, 2.4399],\n",
      "        [2.6890, 2.7383],\n",
      "        [2.1704, 2.4894],\n",
      "        [2.5814, 2.4742],\n",
      "        [2.9188, 2.2439],\n",
      "        [2.6410, 2.4743],\n",
      "        [2.0532, 2.6923],\n",
      "        [2.9803, 2.6223],\n",
      "        [2.4132, 2.5778],\n",
      "        [2.6610, 2.5414],\n",
      "        [2.3677, 2.9036],\n",
      "        [2.2048, 3.1351],\n",
      "        [2.1326, 2.4724],\n",
      "        [2.4952, 2.2272],\n",
      "        [2.3374, 2.2626],\n",
      "        [2.7206, 2.7497],\n",
      "        [2.9790, 2.3840],\n",
      "        [2.7785, 2.1993],\n",
      "        [2.0620, 2.9027],\n",
      "        [2.5724, 2.4366],\n",
      "        [2.6984, 2.0446],\n",
      "        [2.5244, 2.4608],\n",
      "        [2.3008, 2.7282],\n",
      "        [2.5838, 2.8634],\n",
      "        [2.3861, 2.8006],\n",
      "        [2.7693, 2.6050],\n",
      "        [2.7470, 2.8284],\n",
      "        [2.5353, 2.7044],\n",
      "        [2.8688, 2.6363],\n",
      "        [2.7098, 2.1363],\n",
      "        [2.4724, 2.6472],\n",
      "        [2.4871, 2.3803],\n",
      "        [2.9332, 2.8212],\n",
      "        [2.1464, 2.3889],\n",
      "        [2.3380, 2.6470],\n",
      "        [2.6382, 2.6680],\n",
      "        [2.5175, 2.6056],\n",
      "        [2.7247, 2.9604],\n",
      "        [2.5505, 2.3556],\n",
      "        [2.5737, 2.5739],\n",
      "        [2.6539, 2.5558],\n",
      "        [2.5140, 2.7195],\n",
      "        [2.7112, 2.5377],\n",
      "        [2.2076, 2.9724],\n",
      "        [2.6391, 2.0491],\n",
      "        [2.8033, 2.6247],\n",
      "        [2.3111, 2.3281],\n",
      "        [1.8108, 2.7113],\n",
      "        [2.5039, 2.7261],\n",
      "        [2.6929, 2.9274],\n",
      "        [2.6963, 2.5676],\n",
      "        [2.5398, 2.1794],\n",
      "        [2.6263, 2.6760]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.9742, 2.0686],\n",
      "        [2.4303, 2.8434],\n",
      "        [2.2246, 2.4327],\n",
      "        [2.9860, 2.7137],\n",
      "        [2.9594, 2.7312],\n",
      "        [2.8484, 1.8670],\n",
      "        [2.6625, 2.2855],\n",
      "        [2.3679, 2.1094],\n",
      "        [3.1019, 2.5501],\n",
      "        [2.7464, 2.3909],\n",
      "        [2.9243, 2.5441],\n",
      "        [2.7481, 1.9468],\n",
      "        [2.3905, 2.5785],\n",
      "        [2.3996, 2.8632],\n",
      "        [2.7044, 2.8053],\n",
      "        [2.6699, 2.4914],\n",
      "        [2.7123, 2.4269],\n",
      "        [2.6545, 2.6520],\n",
      "        [2.5780, 2.1572],\n",
      "        [2.3578, 2.3966],\n",
      "        [2.2839, 2.8132],\n",
      "        [2.5452, 2.7779],\n",
      "        [2.3254, 2.9718],\n",
      "        [2.4739, 2.6712],\n",
      "        [2.6464, 2.5319],\n",
      "        [2.7401, 3.0068],\n",
      "        [2.2319, 2.5333],\n",
      "        [2.4643, 2.7863],\n",
      "        [2.4763, 2.4380],\n",
      "        [2.7865, 2.7216],\n",
      "        [2.5620, 2.9447],\n",
      "        [2.9399, 2.5190],\n",
      "        [2.1855, 2.4064],\n",
      "        [2.6450, 2.4088],\n",
      "        [2.3972, 2.2654],\n",
      "        [2.5899, 2.2886],\n",
      "        [2.4948, 2.5071],\n",
      "        [2.4601, 2.4712],\n",
      "        [2.7335, 2.4962],\n",
      "        [2.5417, 2.6330],\n",
      "        [2.6001, 2.3980],\n",
      "        [3.0545, 2.4897],\n",
      "        [2.6128, 2.2078],\n",
      "        [2.6217, 2.5125],\n",
      "        [2.5279, 2.3476],\n",
      "        [2.6937, 2.5875],\n",
      "        [2.2690, 2.6819],\n",
      "        [2.2621, 2.3122],\n",
      "        [2.7559, 2.4163],\n",
      "        [2.5914, 2.4106],\n",
      "        [2.8173, 2.3425],\n",
      "        [2.3477, 2.3543],\n",
      "        [2.5636, 2.7701],\n",
      "        [2.5509, 2.4493],\n",
      "        [2.3368, 2.4922],\n",
      "        [2.0846, 2.4309],\n",
      "        [2.8977, 2.6374],\n",
      "        [2.0303, 3.0043],\n",
      "        [2.8787, 2.7067],\n",
      "        [2.5600, 2.2253],\n",
      "        [1.9669, 2.6473],\n",
      "        [2.6397, 2.7230],\n",
      "        [3.1228, 2.8921],\n",
      "        [2.0573, 2.4277],\n",
      "        [2.4372, 2.4687],\n",
      "        [2.5158, 2.5733],\n",
      "        [2.7885, 2.5437],\n",
      "        [2.5775, 2.2328],\n",
      "        [2.7073, 2.4902],\n",
      "        [2.6729, 2.5124],\n",
      "        [2.8973, 2.1052],\n",
      "        [2.5210, 2.8619],\n",
      "        [2.6463, 1.9141],\n",
      "        [2.6321, 2.3279],\n",
      "        [3.2080, 2.6958],\n",
      "        [2.9834, 2.5606],\n",
      "        [2.2861, 2.4041],\n",
      "        [1.8971, 2.4353],\n",
      "        [2.4184, 2.9677],\n",
      "        [2.5504, 2.2386],\n",
      "        [2.6374, 2.7712],\n",
      "        [2.5912, 2.4185],\n",
      "        [2.5624, 2.1568],\n",
      "        [2.2341, 2.8974],\n",
      "        [2.2884, 2.7693],\n",
      "        [2.0166, 2.7700],\n",
      "        [2.5792, 2.7079],\n",
      "        [3.0079, 2.3439],\n",
      "        [2.5218, 2.8424],\n",
      "        [2.0851, 2.7315],\n",
      "        [2.7859, 2.5203],\n",
      "        [2.6835, 2.4925],\n",
      "        [2.4241, 2.8644],\n",
      "        [2.8229, 2.6583],\n",
      "        [2.1514, 2.5470],\n",
      "        [2.5483, 2.3557],\n",
      "        [2.5960, 2.4250],\n",
      "        [2.5968, 2.2946],\n",
      "        [2.7647, 2.5968],\n",
      "        [2.8168, 2.2193]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8781, 2.8156],\n",
      "        [2.7867, 2.3448],\n",
      "        [2.6914, 2.2010],\n",
      "        [2.7882, 2.9299],\n",
      "        [2.6681, 2.6331],\n",
      "        [2.5109, 2.6886],\n",
      "        [2.1752, 2.7460],\n",
      "        [2.9589, 2.0072],\n",
      "        [2.9702, 2.1417],\n",
      "        [2.6587, 2.2985],\n",
      "        [2.4875, 2.4106],\n",
      "        [2.3333, 2.8152],\n",
      "        [2.5472, 2.1408],\n",
      "        [2.4084, 2.4325],\n",
      "        [2.1533, 2.6514],\n",
      "        [2.5904, 2.4751],\n",
      "        [2.9926, 2.4807],\n",
      "        [2.7449, 2.2202],\n",
      "        [2.3746, 2.5798],\n",
      "        [2.5269, 3.0818],\n",
      "        [2.1397, 2.5539],\n",
      "        [3.0722, 2.4963],\n",
      "        [2.4647, 2.4279],\n",
      "        [1.9076, 2.3904],\n",
      "        [2.8959, 2.7902],\n",
      "        [2.5099, 2.5143],\n",
      "        [2.5474, 2.6199],\n",
      "        [2.4460, 2.5757],\n",
      "        [2.1991, 2.5540],\n",
      "        [2.6956, 2.6372],\n",
      "        [2.5507, 2.4987],\n",
      "        [2.3275, 2.5523],\n",
      "        [3.0222, 2.1385],\n",
      "        [2.5602, 2.5416],\n",
      "        [2.7614, 2.2126],\n",
      "        [2.4674, 2.4414],\n",
      "        [2.6954, 2.4125],\n",
      "        [2.8493, 2.4792],\n",
      "        [2.4683, 2.1514],\n",
      "        [2.8551, 2.6194],\n",
      "        [2.3537, 2.6299],\n",
      "        [2.5973, 2.4596],\n",
      "        [3.0919, 2.4282],\n",
      "        [2.2330, 2.6051],\n",
      "        [2.5095, 2.5957],\n",
      "        [2.6173, 2.7908],\n",
      "        [2.6896, 2.3838],\n",
      "        [2.3626, 2.6104],\n",
      "        [2.2912, 2.9215],\n",
      "        [2.7876, 2.7627],\n",
      "        [2.9317, 2.6085],\n",
      "        [2.3369, 2.4261],\n",
      "        [2.4833, 2.6253],\n",
      "        [2.7092, 2.8591],\n",
      "        [2.3897, 2.3763],\n",
      "        [2.8703, 2.4494],\n",
      "        [3.0498, 2.5723],\n",
      "        [2.6045, 2.2958],\n",
      "        [2.5453, 2.4196],\n",
      "        [2.8086, 2.8307],\n",
      "        [2.8431, 2.5151],\n",
      "        [2.4694, 2.4322],\n",
      "        [2.9576, 2.3476],\n",
      "        [3.0015, 2.7183],\n",
      "        [2.7217, 2.6218],\n",
      "        [2.8099, 2.6102],\n",
      "        [2.4718, 2.8623],\n",
      "        [2.7169, 2.3986],\n",
      "        [2.7541, 2.7075],\n",
      "        [2.4996, 2.4428],\n",
      "        [2.0950, 2.5897],\n",
      "        [2.3990, 2.3952],\n",
      "        [2.5481, 2.8206],\n",
      "        [2.3891, 2.4182],\n",
      "        [2.2106, 3.0125],\n",
      "        [2.7455, 2.7316],\n",
      "        [2.6346, 2.3722],\n",
      "        [2.5549, 2.8577],\n",
      "        [2.5242, 2.4451],\n",
      "        [2.4448, 2.6120],\n",
      "        [2.3957, 2.4767],\n",
      "        [2.7940, 2.1850],\n",
      "        [2.4152, 2.5379],\n",
      "        [1.9063, 2.7196],\n",
      "        [2.7908, 2.5637],\n",
      "        [2.4229, 2.9035],\n",
      "        [2.5038, 2.7364],\n",
      "        [2.9519, 2.5217],\n",
      "        [2.2477, 2.7209],\n",
      "        [2.4846, 2.2604],\n",
      "        [2.5894, 2.6251],\n",
      "        [2.6155, 2.7651],\n",
      "        [2.4031, 2.8362],\n",
      "        [2.5888, 2.2180],\n",
      "        [2.6411, 2.2071],\n",
      "        [2.8866, 2.4623],\n",
      "        [2.8278, 2.5003],\n",
      "        [2.4910, 2.6841],\n",
      "        [2.5671, 2.6549],\n",
      "        [2.5967, 3.1122]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 15 complete in 0:00:43.226855; est. finish at 2021-11-29 21:56:09.017663\n",
      "Validation: 0.498 train | 0.502 dev\n",
      "### Epoch: 16 ###\n",
      "y:  tensor([0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.9256, 2.3528],\n",
      "        [2.1868, 2.1434],\n",
      "        [2.7591, 1.7929],\n",
      "        [2.5543, 2.7805],\n",
      "        [2.4408, 2.7691],\n",
      "        [2.1535, 2.3568],\n",
      "        [2.4876, 2.5760],\n",
      "        [2.3692, 2.7128],\n",
      "        [2.9408, 2.4598],\n",
      "        [2.3335, 2.4715],\n",
      "        [3.0352, 2.4236],\n",
      "        [2.4684, 2.6764],\n",
      "        [2.3550, 2.4151],\n",
      "        [2.4445, 3.1052],\n",
      "        [2.1313, 3.0623],\n",
      "        [2.7528, 2.4674],\n",
      "        [2.6881, 2.6431],\n",
      "        [2.2536, 2.2942],\n",
      "        [1.9233, 2.5877],\n",
      "        [2.6933, 2.4887],\n",
      "        [2.4588, 2.7097],\n",
      "        [1.8707, 2.7907],\n",
      "        [2.4991, 2.7834],\n",
      "        [2.8534, 2.9488],\n",
      "        [2.4865, 2.4960],\n",
      "        [2.5291, 2.5610],\n",
      "        [2.5015, 3.0848],\n",
      "        [2.0036, 2.6869],\n",
      "        [3.1103, 2.9465],\n",
      "        [2.5499, 2.6568],\n",
      "        [2.5610, 2.7812],\n",
      "        [2.3567, 2.8521],\n",
      "        [2.6482, 2.8718],\n",
      "        [2.8918, 2.5045],\n",
      "        [2.4277, 2.3925],\n",
      "        [2.9252, 2.6616],\n",
      "        [2.7896, 2.9725],\n",
      "        [2.8163, 2.7007],\n",
      "        [2.8518, 2.8020],\n",
      "        [2.8138, 2.4330],\n",
      "        [2.4156, 2.5249],\n",
      "        [2.5409, 2.7229],\n",
      "        [2.9718, 2.7271],\n",
      "        [2.5293, 2.4658],\n",
      "        [2.7937, 2.1839],\n",
      "        [2.3847, 2.4978],\n",
      "        [2.2736, 2.5376],\n",
      "        [3.0374, 3.3134],\n",
      "        [2.4949, 2.5097],\n",
      "        [2.5868, 2.3837],\n",
      "        [2.5742, 2.7065],\n",
      "        [2.5513, 2.7007],\n",
      "        [2.6971, 2.8318],\n",
      "        [2.4267, 2.7196],\n",
      "        [2.5776, 3.1504],\n",
      "        [3.0893, 2.1033],\n",
      "        [2.3366, 2.6274],\n",
      "        [2.1670, 2.8121],\n",
      "        [2.5469, 2.6039],\n",
      "        [2.4614, 2.5512],\n",
      "        [2.2083, 2.0933],\n",
      "        [2.4061, 2.6042],\n",
      "        [2.4162, 2.2819],\n",
      "        [2.7797, 2.7767],\n",
      "        [2.5296, 2.3319],\n",
      "        [2.4141, 2.3821],\n",
      "        [2.5023, 2.3895],\n",
      "        [3.4526, 3.0018],\n",
      "        [2.7290, 2.4504],\n",
      "        [2.2207, 2.5087],\n",
      "        [1.9905, 2.6950],\n",
      "        [1.9468, 2.6638],\n",
      "        [2.4370, 2.5155],\n",
      "        [1.8681, 2.2637],\n",
      "        [2.3983, 2.5386],\n",
      "        [2.4761, 2.8440],\n",
      "        [2.1643, 2.8193],\n",
      "        [2.2109, 2.5689],\n",
      "        [2.6875, 2.4132],\n",
      "        [2.3444, 2.5087],\n",
      "        [2.6268, 2.6155],\n",
      "        [2.2576, 2.3483],\n",
      "        [2.8483, 2.6189],\n",
      "        [2.3400, 2.4309],\n",
      "        [2.8073, 2.1117],\n",
      "        [2.4020, 2.3065],\n",
      "        [2.4647, 2.6315],\n",
      "        [2.2740, 2.2889],\n",
      "        [2.4680, 3.0025],\n",
      "        [2.3677, 2.5914],\n",
      "        [2.6523, 2.6306],\n",
      "        [2.3230, 2.2405],\n",
      "        [2.7097, 2.5417],\n",
      "        [2.7014, 2.2688],\n",
      "        [2.6087, 2.5854],\n",
      "        [3.0118, 2.2564],\n",
      "        [2.5369, 2.6412],\n",
      "        [2.5816, 3.0055],\n",
      "        [2.4895, 2.7816],\n",
      "        [2.3303, 2.8669]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6176, 2.6440],\n",
      "        [2.8522, 2.4904],\n",
      "        [2.5417, 2.4296],\n",
      "        [2.3447, 2.6258],\n",
      "        [2.6682, 2.8044],\n",
      "        [2.6196, 2.0089],\n",
      "        [2.3294, 2.5771],\n",
      "        [2.4927, 2.4641],\n",
      "        [3.1690, 2.8309],\n",
      "        [2.5520, 2.7002],\n",
      "        [2.3541, 2.3469],\n",
      "        [2.8552, 2.1546],\n",
      "        [2.5061, 2.7472],\n",
      "        [2.3784, 2.6954],\n",
      "        [2.5348, 2.2472],\n",
      "        [2.4909, 2.5220],\n",
      "        [2.8126, 2.5577],\n",
      "        [2.6565, 2.2655],\n",
      "        [2.7723, 2.5572],\n",
      "        [2.3934, 2.6121],\n",
      "        [2.7239, 2.4675],\n",
      "        [2.7352, 2.7721],\n",
      "        [2.5682, 2.5697],\n",
      "        [2.2001, 2.4418],\n",
      "        [2.4320, 2.2780],\n",
      "        [2.5465, 2.4562],\n",
      "        [2.2619, 2.5999],\n",
      "        [2.7422, 2.2558],\n",
      "        [2.3538, 1.7432],\n",
      "        [2.6996, 2.5500],\n",
      "        [2.5791, 2.6723],\n",
      "        [2.7457, 2.1736],\n",
      "        [2.4331, 2.6029],\n",
      "        [2.7923, 3.0537],\n",
      "        [2.6924, 2.5137],\n",
      "        [2.7606, 2.5320],\n",
      "        [3.0095, 2.1915],\n",
      "        [2.2650, 2.3719],\n",
      "        [2.1732, 2.3867],\n",
      "        [2.5149, 3.0707],\n",
      "        [2.9777, 2.3428],\n",
      "        [2.9607, 2.5451],\n",
      "        [2.2465, 1.9859],\n",
      "        [2.7904, 2.5592],\n",
      "        [2.1843, 2.5548],\n",
      "        [2.4519, 2.9321],\n",
      "        [2.5575, 2.0937],\n",
      "        [2.4534, 2.4116],\n",
      "        [2.6651, 2.5729],\n",
      "        [2.5130, 3.5233],\n",
      "        [2.9684, 2.1224],\n",
      "        [2.3518, 2.3001],\n",
      "        [2.7719, 2.8614],\n",
      "        [2.5740, 2.5604],\n",
      "        [2.7603, 2.6294],\n",
      "        [2.6691, 2.5228],\n",
      "        [2.7583, 2.8649],\n",
      "        [2.4788, 2.6453],\n",
      "        [2.4882, 2.6843],\n",
      "        [2.3020, 2.4390],\n",
      "        [2.5139, 2.7441],\n",
      "        [2.7406, 2.5369],\n",
      "        [3.0967, 2.1768],\n",
      "        [2.3257, 2.6507],\n",
      "        [2.5850, 2.5216],\n",
      "        [2.4021, 2.3434],\n",
      "        [2.3431, 2.5772],\n",
      "        [2.4707, 2.5513],\n",
      "        [2.4165, 2.5530],\n",
      "        [2.8393, 2.8811],\n",
      "        [2.8798, 3.0648],\n",
      "        [3.0190, 2.1999],\n",
      "        [2.3063, 2.7723],\n",
      "        [2.7652, 2.4117],\n",
      "        [2.4778, 2.6946],\n",
      "        [2.7445, 2.2289],\n",
      "        [2.5943, 2.8329],\n",
      "        [2.6070, 2.7311],\n",
      "        [2.6550, 2.5041],\n",
      "        [2.7125, 2.4608],\n",
      "        [2.7286, 2.3029],\n",
      "        [2.3925, 3.0291],\n",
      "        [2.2506, 2.6665],\n",
      "        [2.4541, 2.5496],\n",
      "        [2.0696, 2.0645],\n",
      "        [2.7253, 2.7228],\n",
      "        [2.4921, 2.6732],\n",
      "        [2.4492, 2.7083],\n",
      "        [2.5299, 3.1409],\n",
      "        [2.5892, 2.6925],\n",
      "        [2.7697, 2.4663],\n",
      "        [2.2588, 2.8065],\n",
      "        [2.8373, 2.5965],\n",
      "        [2.4479, 2.8454],\n",
      "        [2.8500, 2.6024],\n",
      "        [2.8318, 2.8620],\n",
      "        [2.5433, 2.2725],\n",
      "        [2.3568, 2.0456],\n",
      "        [2.8618, 2.2382],\n",
      "        [2.1816, 3.1257]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7421, 2.3377],\n",
      "        [3.0808, 2.5790],\n",
      "        [2.4713, 2.4386],\n",
      "        [3.1493, 2.6355],\n",
      "        [2.4147, 2.2604],\n",
      "        [2.4326, 2.5953],\n",
      "        [2.2607, 2.3841],\n",
      "        [2.6060, 2.2704],\n",
      "        [2.8288, 2.6817],\n",
      "        [2.6161, 2.7709],\n",
      "        [2.3133, 2.7409],\n",
      "        [2.2814, 2.8129],\n",
      "        [2.3642, 2.6120],\n",
      "        [2.7315, 2.7460],\n",
      "        [2.9335, 2.8742],\n",
      "        [2.2347, 2.8140],\n",
      "        [2.4849, 2.5522],\n",
      "        [2.6904, 2.7574],\n",
      "        [2.4528, 2.3847],\n",
      "        [2.4284, 2.3664],\n",
      "        [2.3899, 2.4583],\n",
      "        [2.7834, 2.1712],\n",
      "        [2.2917, 2.6708],\n",
      "        [2.7017, 2.9927],\n",
      "        [2.4411, 2.4776],\n",
      "        [2.5756, 2.5624],\n",
      "        [2.3857, 2.2117],\n",
      "        [2.3892, 2.8519],\n",
      "        [1.9152, 2.4538],\n",
      "        [2.3828, 2.4432],\n",
      "        [2.6924, 2.4643],\n",
      "        [2.3480, 2.7201],\n",
      "        [2.5127, 2.5383],\n",
      "        [2.5967, 2.4189],\n",
      "        [2.3663, 2.3108],\n",
      "        [2.8754, 2.5430],\n",
      "        [2.6861, 2.5112],\n",
      "        [2.3014, 2.8071],\n",
      "        [2.4638, 2.7995],\n",
      "        [2.5702, 2.7835],\n",
      "        [1.9057, 2.9040],\n",
      "        [2.3231, 2.7140],\n",
      "        [2.6352, 2.2940],\n",
      "        [2.7931, 2.2693],\n",
      "        [2.2052, 2.4789],\n",
      "        [2.5154, 2.1645],\n",
      "        [2.4978, 2.3193],\n",
      "        [2.8885, 2.0768],\n",
      "        [2.7728, 2.7110],\n",
      "        [2.4562, 2.4281],\n",
      "        [2.3771, 2.6989],\n",
      "        [2.7568, 2.3464],\n",
      "        [2.4738, 2.6129],\n",
      "        [2.5122, 2.5996],\n",
      "        [2.4873, 2.6337],\n",
      "        [2.4246, 2.2030],\n",
      "        [2.3526, 2.4976],\n",
      "        [2.4821, 2.7407],\n",
      "        [2.2320, 2.7468],\n",
      "        [3.0241, 2.7516],\n",
      "        [2.3163, 2.9094],\n",
      "        [2.3085, 2.3044],\n",
      "        [2.3870, 2.3982],\n",
      "        [2.9968, 2.1688],\n",
      "        [2.6208, 2.7646],\n",
      "        [2.7163, 2.9018],\n",
      "        [2.4328, 2.4782],\n",
      "        [2.6460, 2.5852],\n",
      "        [2.4209, 2.4864],\n",
      "        [2.5901, 2.6998],\n",
      "        [2.2236, 2.8174],\n",
      "        [2.9191, 2.8385],\n",
      "        [2.3758, 2.5824],\n",
      "        [2.0100, 2.5675],\n",
      "        [2.3705, 2.5221],\n",
      "        [2.6620, 2.6251],\n",
      "        [2.1923, 2.7234],\n",
      "        [2.4511, 2.5173],\n",
      "        [2.3729, 2.3177],\n",
      "        [2.5224, 2.5083],\n",
      "        [2.3808, 2.8130],\n",
      "        [2.5910, 2.7404],\n",
      "        [2.5365, 2.5103],\n",
      "        [2.6572, 2.2026],\n",
      "        [2.6096, 2.4269],\n",
      "        [2.5417, 2.5611],\n",
      "        [2.6058, 2.3738],\n",
      "        [2.6280, 2.2412],\n",
      "        [2.8056, 2.2338],\n",
      "        [2.7234, 2.7837],\n",
      "        [2.6362, 2.7560],\n",
      "        [2.0493, 2.9485],\n",
      "        [2.3397, 2.8718],\n",
      "        [2.8705, 2.2480],\n",
      "        [2.6548, 2.6900],\n",
      "        [2.4832, 2.5980],\n",
      "        [2.3130, 1.9591],\n",
      "        [2.6516, 2.7325],\n",
      "        [2.3259, 2.2811],\n",
      "        [2.9870, 2.2691]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3663, 2.8264],\n",
      "        [2.9142, 2.2348],\n",
      "        [2.7163, 2.8269],\n",
      "        [2.4195, 2.4328],\n",
      "        [2.8368, 2.7164],\n",
      "        [2.4208, 2.4191],\n",
      "        [2.5591, 2.5431],\n",
      "        [2.5896, 2.3927],\n",
      "        [2.6851, 2.2804],\n",
      "        [2.7319, 2.1327],\n",
      "        [2.3559, 2.5940],\n",
      "        [2.4117, 2.6147],\n",
      "        [2.6907, 2.6259],\n",
      "        [2.4918, 1.9788],\n",
      "        [2.8507, 2.3532],\n",
      "        [2.8069, 2.8423],\n",
      "        [2.7004, 2.5790],\n",
      "        [2.4280, 2.5545],\n",
      "        [2.6323, 2.2873],\n",
      "        [2.0708, 2.8680],\n",
      "        [2.1452, 2.8383],\n",
      "        [2.6190, 2.3490],\n",
      "        [2.8271, 2.6181],\n",
      "        [2.7372, 2.5004],\n",
      "        [2.7594, 2.5733],\n",
      "        [2.1809, 2.3751],\n",
      "        [2.5188, 2.1972],\n",
      "        [2.7116, 2.2852],\n",
      "        [2.4347, 2.1772],\n",
      "        [2.6144, 2.5894],\n",
      "        [2.4778, 2.5654],\n",
      "        [2.4594, 2.5046],\n",
      "        [2.4114, 2.6903],\n",
      "        [2.5040, 2.3834],\n",
      "        [2.4651, 2.1302],\n",
      "        [2.2431, 2.8066],\n",
      "        [2.6343, 2.4639],\n",
      "        [2.5986, 2.4554],\n",
      "        [2.3808, 2.9685],\n",
      "        [2.6743, 2.7917],\n",
      "        [2.6533, 2.6762],\n",
      "        [2.8561, 2.4242],\n",
      "        [2.7465, 2.4401],\n",
      "        [2.7645, 2.6151],\n",
      "        [2.3706, 2.4464],\n",
      "        [2.3528, 2.6700],\n",
      "        [2.3804, 3.1264],\n",
      "        [2.6497, 2.5143],\n",
      "        [2.7871, 2.5208],\n",
      "        [2.7017, 2.4211],\n",
      "        [2.9174, 2.4756],\n",
      "        [2.2956, 3.0009],\n",
      "        [2.2615, 2.2922],\n",
      "        [2.6339, 2.6602],\n",
      "        [3.0049, 2.8028],\n",
      "        [2.4767, 2.2697],\n",
      "        [2.4078, 2.4206],\n",
      "        [2.9385, 1.8417],\n",
      "        [2.5024, 2.2411],\n",
      "        [2.4098, 2.7186],\n",
      "        [2.4131, 2.3800],\n",
      "        [2.4300, 2.1113],\n",
      "        [2.3180, 2.3062],\n",
      "        [2.6655, 2.3191],\n",
      "        [2.5990, 2.5004],\n",
      "        [2.2794, 2.7245],\n",
      "        [2.8895, 2.2475],\n",
      "        [2.2124, 2.2488],\n",
      "        [2.5218, 2.2410],\n",
      "        [2.5333, 2.8052],\n",
      "        [2.6455, 2.5860],\n",
      "        [2.7320, 2.8549],\n",
      "        [2.3046, 2.8719],\n",
      "        [2.6707, 2.7445],\n",
      "        [2.8936, 2.4594],\n",
      "        [2.4921, 2.7143],\n",
      "        [2.3723, 2.7069],\n",
      "        [2.4582, 2.6628],\n",
      "        [2.6514, 2.5860],\n",
      "        [2.2584, 2.4280],\n",
      "        [2.2411, 2.4605],\n",
      "        [2.3013, 2.7873],\n",
      "        [2.7290, 2.4967],\n",
      "        [2.4650, 2.3142],\n",
      "        [2.2594, 2.7384],\n",
      "        [2.3495, 2.6231],\n",
      "        [2.3845, 2.5909],\n",
      "        [2.1202, 2.1632],\n",
      "        [2.4845, 2.4835],\n",
      "        [2.6758, 2.6722],\n",
      "        [2.5158, 2.8522],\n",
      "        [2.6682, 2.7654],\n",
      "        [2.7744, 2.6053],\n",
      "        [2.6038, 2.1822],\n",
      "        [2.6987, 2.6465],\n",
      "        [2.3311, 2.6088],\n",
      "        [2.9769, 2.4642],\n",
      "        [2.6408, 2.7151],\n",
      "        [2.4297, 3.0185],\n",
      "        [2.3930, 2.6390]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5015, 2.2317],\n",
      "        [2.7295, 2.7000],\n",
      "        [2.6692, 2.6757],\n",
      "        [2.5791, 2.4952],\n",
      "        [2.4009, 2.8043],\n",
      "        [2.1786, 2.5669],\n",
      "        [2.2888, 2.5722],\n",
      "        [2.6681, 2.4191],\n",
      "        [2.1572, 2.8577],\n",
      "        [2.6755, 2.0327],\n",
      "        [2.7897, 2.5126],\n",
      "        [2.7379, 2.3252],\n",
      "        [2.6802, 2.5300],\n",
      "        [2.2744, 2.7627],\n",
      "        [2.7781, 2.8404],\n",
      "        [2.2474, 2.3841],\n",
      "        [2.3360, 2.4394],\n",
      "        [2.6570, 2.3465],\n",
      "        [2.0450, 2.4032],\n",
      "        [2.0005, 2.4005],\n",
      "        [2.7105, 2.4862],\n",
      "        [2.5470, 2.4978],\n",
      "        [2.3895, 2.6763],\n",
      "        [2.2361, 2.3484],\n",
      "        [2.4048, 2.4830],\n",
      "        [2.4677, 2.0575],\n",
      "        [2.4377, 2.6616],\n",
      "        [2.6117, 2.7291],\n",
      "        [2.2959, 3.0105],\n",
      "        [2.3873, 2.4145],\n",
      "        [2.7124, 2.5833],\n",
      "        [2.8902, 2.7930],\n",
      "        [2.2573, 2.6792],\n",
      "        [2.7836, 2.4593],\n",
      "        [2.4959, 2.4356],\n",
      "        [2.7227, 1.9439],\n",
      "        [2.6695, 2.8412],\n",
      "        [3.1097, 2.0198],\n",
      "        [2.4247, 2.3810],\n",
      "        [2.9474, 2.0495],\n",
      "        [2.4834, 3.0598],\n",
      "        [3.3021, 2.5423],\n",
      "        [2.1734, 2.4789],\n",
      "        [2.2241, 2.1843],\n",
      "        [2.7396, 2.5660],\n",
      "        [3.0933, 1.9273],\n",
      "        [2.8510, 2.0617],\n",
      "        [2.5329, 2.2125],\n",
      "        [2.4718, 2.6422],\n",
      "        [2.2401, 2.3376],\n",
      "        [2.4796, 2.1713],\n",
      "        [2.1214, 2.7088],\n",
      "        [2.3827, 2.2199],\n",
      "        [2.7953, 2.3999],\n",
      "        [2.5674, 2.8373],\n",
      "        [2.2300, 2.7970],\n",
      "        [2.5484, 2.9512],\n",
      "        [2.7198, 2.5880],\n",
      "        [2.4509, 2.7616],\n",
      "        [2.5344, 2.6383],\n",
      "        [2.3896, 2.6046],\n",
      "        [2.7492, 2.5566],\n",
      "        [2.8508, 2.3919],\n",
      "        [1.7556, 2.9654],\n",
      "        [2.6866, 2.5979],\n",
      "        [2.4808, 2.2745],\n",
      "        [2.2229, 2.2479],\n",
      "        [2.6922, 2.1945],\n",
      "        [2.2256, 2.2072],\n",
      "        [2.5370, 2.8151],\n",
      "        [2.5514, 2.2648],\n",
      "        [2.9554, 2.1613],\n",
      "        [2.5685, 2.5088],\n",
      "        [3.0331, 2.4066],\n",
      "        [2.6462, 2.5792],\n",
      "        [2.6984, 2.4753],\n",
      "        [2.6487, 2.6336],\n",
      "        [2.6086, 3.1877],\n",
      "        [2.4636, 2.4113],\n",
      "        [2.3837, 2.4026],\n",
      "        [2.8205, 2.2907],\n",
      "        [2.3435, 2.5662],\n",
      "        [2.6426, 2.9154],\n",
      "        [2.0545, 2.5044],\n",
      "        [2.4010, 2.8298],\n",
      "        [2.5704, 2.4345],\n",
      "        [2.1232, 2.3590],\n",
      "        [2.3944, 2.4652],\n",
      "        [2.3182, 2.4714],\n",
      "        [2.4031, 2.3337],\n",
      "        [2.6285, 2.6782],\n",
      "        [2.4112, 2.7881],\n",
      "        [2.6589, 2.8805],\n",
      "        [2.3235, 2.5167],\n",
      "        [2.5204, 2.8039],\n",
      "        [2.5430, 2.6062],\n",
      "        [2.4443, 3.3647],\n",
      "        [2.4910, 2.1003],\n",
      "        [2.6361, 2.3582],\n",
      "        [2.4744, 2.4464]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 20 complete in 0:00:58.651479; est. finish at 2021-11-29 21:56:14.096063\n",
      "Validation: 0.504 train | 0.46 dev\n",
      "### Epoch: 21 ###\n",
      "y:  tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7319, 2.2566],\n",
      "        [2.7376, 2.4270],\n",
      "        [2.3375, 2.5371],\n",
      "        [2.4154, 2.8605],\n",
      "        [2.7436, 2.6559],\n",
      "        [2.7021, 2.3044],\n",
      "        [2.3470, 2.9741],\n",
      "        [2.2455, 2.7856],\n",
      "        [2.7458, 2.6711],\n",
      "        [2.7195, 2.5037],\n",
      "        [2.2620, 2.4968],\n",
      "        [2.0505, 2.5904],\n",
      "        [2.6446, 2.5984],\n",
      "        [2.6797, 2.2725],\n",
      "        [2.5224, 2.1832],\n",
      "        [2.3192, 2.4939],\n",
      "        [2.8669, 2.8599],\n",
      "        [2.7392, 2.6685],\n",
      "        [2.5786, 2.5286],\n",
      "        [2.3805, 2.8329],\n",
      "        [2.7135, 2.5187],\n",
      "        [2.4114, 2.6126],\n",
      "        [2.8583, 2.4883],\n",
      "        [2.5552, 2.3345],\n",
      "        [2.7970, 2.8063],\n",
      "        [2.3956, 2.4032],\n",
      "        [2.0682, 2.3536],\n",
      "        [2.8551, 2.5457],\n",
      "        [2.9125, 2.7612],\n",
      "        [2.3556, 3.1295],\n",
      "        [2.3201, 2.3184],\n",
      "        [2.3302, 2.7974],\n",
      "        [2.6443, 2.2907],\n",
      "        [2.5290, 2.7496],\n",
      "        [2.2086, 1.8539],\n",
      "        [3.0381, 2.1045],\n",
      "        [2.7506, 2.3162],\n",
      "        [2.4947, 2.1283],\n",
      "        [2.2194, 2.6422],\n",
      "        [2.0416, 3.0342],\n",
      "        [2.0428, 3.0322],\n",
      "        [2.5913, 2.7409],\n",
      "        [2.6448, 2.5243],\n",
      "        [2.2896, 2.4938],\n",
      "        [2.4310, 2.1215],\n",
      "        [3.0376, 2.5833],\n",
      "        [2.5577, 2.5407],\n",
      "        [2.5305, 2.6334],\n",
      "        [2.6731, 2.4932],\n",
      "        [2.4949, 2.5109],\n",
      "        [2.6735, 2.3510],\n",
      "        [2.4804, 2.2793],\n",
      "        [1.9808, 2.9928],\n",
      "        [2.6896, 2.4839],\n",
      "        [2.3957, 2.5284],\n",
      "        [2.5466, 2.6247],\n",
      "        [2.5308, 2.1016],\n",
      "        [2.9788, 2.7859],\n",
      "        [2.7374, 2.2850],\n",
      "        [2.3969, 2.3442],\n",
      "        [2.4533, 2.4927],\n",
      "        [2.8932, 2.4511],\n",
      "        [3.1585, 2.4439],\n",
      "        [2.6445, 1.9094],\n",
      "        [2.6960, 2.5411],\n",
      "        [2.4824, 2.9276],\n",
      "        [2.5943, 2.9412],\n",
      "        [2.8080, 2.5935],\n",
      "        [2.2654, 2.2056],\n",
      "        [2.4504, 2.9372],\n",
      "        [2.3303, 3.0294],\n",
      "        [2.7705, 3.1098],\n",
      "        [2.4475, 2.6590],\n",
      "        [2.3548, 2.4789],\n",
      "        [2.3386, 2.3985],\n",
      "        [3.0345, 2.6369],\n",
      "        [2.0891, 2.6262],\n",
      "        [2.2722, 2.5586],\n",
      "        [2.7345, 2.9199],\n",
      "        [2.6717, 2.8926],\n",
      "        [2.2721, 2.2001],\n",
      "        [2.7302, 2.6474],\n",
      "        [2.3743, 2.4548],\n",
      "        [2.6538, 2.6259],\n",
      "        [2.2073, 2.4267],\n",
      "        [2.4162, 2.2700],\n",
      "        [2.3656, 2.5719],\n",
      "        [2.4657, 2.9025],\n",
      "        [2.6853, 2.9193],\n",
      "        [2.9953, 2.5307],\n",
      "        [2.5889, 2.7498],\n",
      "        [2.4774, 2.9121],\n",
      "        [2.5953, 2.7559],\n",
      "        [2.8298, 2.4025],\n",
      "        [3.0546, 2.3035],\n",
      "        [2.2691, 2.5507],\n",
      "        [2.7857, 2.4761],\n",
      "        [2.6609, 2.7961],\n",
      "        [2.3433, 2.7869],\n",
      "        [2.8392, 2.5902]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5685, 2.0077],\n",
      "        [2.4553, 2.4248],\n",
      "        [2.9087, 2.4130],\n",
      "        [2.4279, 2.1863],\n",
      "        [2.2130, 2.4720],\n",
      "        [2.5910, 2.6538],\n",
      "        [2.7356, 2.5467],\n",
      "        [2.2193, 2.5622],\n",
      "        [2.8349, 2.4122],\n",
      "        [2.2914, 2.4463],\n",
      "        [2.6807, 2.6106],\n",
      "        [2.2121, 2.3381],\n",
      "        [2.7845, 2.3654],\n",
      "        [2.4920, 2.4519],\n",
      "        [2.9997, 1.9008],\n",
      "        [2.9470, 1.7004],\n",
      "        [2.6044, 2.7721],\n",
      "        [3.0873, 2.3921],\n",
      "        [2.6620, 1.9314],\n",
      "        [2.5646, 2.3891],\n",
      "        [2.7367, 2.5417],\n",
      "        [3.1428, 2.7315],\n",
      "        [3.0150, 3.0493],\n",
      "        [2.7087, 2.9048],\n",
      "        [2.5279, 2.5661],\n",
      "        [2.2561, 2.9260],\n",
      "        [2.5720, 2.2486],\n",
      "        [2.4489, 2.6709],\n",
      "        [2.8290, 2.3285],\n",
      "        [2.5963, 2.5211],\n",
      "        [2.3291, 2.4982],\n",
      "        [2.1374, 3.0389],\n",
      "        [2.5113, 2.4719],\n",
      "        [2.5741, 2.5873],\n",
      "        [2.2534, 2.1707],\n",
      "        [2.3978, 3.0733],\n",
      "        [2.2906, 2.5383],\n",
      "        [2.1700, 2.9797],\n",
      "        [2.8326, 2.8074],\n",
      "        [3.0293, 2.8495],\n",
      "        [2.4634, 2.5292],\n",
      "        [2.4349, 2.5393],\n",
      "        [2.2657, 2.8007],\n",
      "        [2.7429, 2.7378],\n",
      "        [2.4207, 2.7722],\n",
      "        [2.3081, 2.7628],\n",
      "        [2.8106, 2.8764],\n",
      "        [2.1595, 2.7930],\n",
      "        [2.4092, 2.4794],\n",
      "        [2.5414, 2.0861],\n",
      "        [2.3735, 2.0885],\n",
      "        [2.1316, 2.8725],\n",
      "        [2.0293, 2.8301],\n",
      "        [2.4333, 2.3916],\n",
      "        [2.6096, 2.4848],\n",
      "        [2.8595, 2.4915],\n",
      "        [2.7366, 2.5323],\n",
      "        [2.5443, 2.9280],\n",
      "        [3.1861, 2.7139],\n",
      "        [2.4580, 2.8936],\n",
      "        [2.7617, 2.3683],\n",
      "        [2.6253, 2.5843],\n",
      "        [2.6190, 2.6302],\n",
      "        [2.6070, 2.7065],\n",
      "        [3.1126, 2.3337],\n",
      "        [2.5746, 2.6055],\n",
      "        [2.4054, 2.7609],\n",
      "        [2.4354, 2.5011],\n",
      "        [2.2079, 2.4821],\n",
      "        [2.6284, 2.4761],\n",
      "        [2.1710, 2.4349],\n",
      "        [2.9387, 2.7749],\n",
      "        [2.8807, 2.5417],\n",
      "        [2.3598, 2.3984],\n",
      "        [2.5794, 2.2859],\n",
      "        [2.5065, 2.6157],\n",
      "        [2.5355, 3.0383],\n",
      "        [2.6570, 2.7951],\n",
      "        [2.4681, 2.8403],\n",
      "        [3.0464, 2.7306],\n",
      "        [2.2420, 2.5606],\n",
      "        [2.7342, 2.4597],\n",
      "        [3.3135, 3.0952],\n",
      "        [2.7956, 2.2926],\n",
      "        [2.8103, 2.4970],\n",
      "        [2.6201, 2.1062],\n",
      "        [2.6806, 2.3166],\n",
      "        [2.7153, 2.5181],\n",
      "        [2.2232, 2.2104],\n",
      "        [3.1153, 2.8714],\n",
      "        [2.6868, 2.5627],\n",
      "        [2.9588, 2.4393],\n",
      "        [2.7040, 2.9016],\n",
      "        [2.5659, 2.8672],\n",
      "        [3.0610, 2.3968],\n",
      "        [2.6142, 2.7761],\n",
      "        [2.3053, 2.2895],\n",
      "        [2.7508, 2.4574],\n",
      "        [2.6878, 2.2698],\n",
      "        [2.3650, 2.6194]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3069, 2.1503],\n",
      "        [2.6789, 2.3112],\n",
      "        [2.7945, 2.5071],\n",
      "        [2.4598, 2.6435],\n",
      "        [2.5176, 2.3019],\n",
      "        [2.5371, 2.8368],\n",
      "        [3.0608, 2.0303],\n",
      "        [2.3087, 2.4838],\n",
      "        [2.5315, 2.0728],\n",
      "        [2.8490, 2.3739],\n",
      "        [2.8427, 2.7448],\n",
      "        [1.9203, 2.7226],\n",
      "        [2.5500, 2.7439],\n",
      "        [2.3964, 2.7967],\n",
      "        [2.3385, 2.7919],\n",
      "        [2.6317, 2.9851],\n",
      "        [2.3119, 2.7529],\n",
      "        [2.5921, 2.5958],\n",
      "        [2.4387, 2.5918],\n",
      "        [2.7430, 2.9123],\n",
      "        [2.1329, 2.6016],\n",
      "        [2.6146, 2.5877],\n",
      "        [2.6091, 2.6553],\n",
      "        [2.3613, 2.8726],\n",
      "        [2.4148, 2.5387],\n",
      "        [2.3913, 2.6239],\n",
      "        [2.2505, 2.4274],\n",
      "        [2.1801, 1.9678],\n",
      "        [2.0537, 2.4779],\n",
      "        [2.1580, 2.5994],\n",
      "        [2.6788, 2.3503],\n",
      "        [2.4271, 2.3127],\n",
      "        [2.6455, 2.2290],\n",
      "        [2.8680, 2.6590],\n",
      "        [2.3251, 2.5625],\n",
      "        [2.3650, 2.5221],\n",
      "        [2.6332, 2.1941],\n",
      "        [2.2796, 2.3445],\n",
      "        [2.5354, 2.7004],\n",
      "        [3.1145, 2.8625],\n",
      "        [2.3416, 2.5348],\n",
      "        [2.2923, 2.6905],\n",
      "        [2.5766, 2.3210],\n",
      "        [2.2810, 2.3125],\n",
      "        [2.8307, 2.5788],\n",
      "        [2.4734, 2.0920],\n",
      "        [2.6132, 2.3354],\n",
      "        [3.0801, 2.7879],\n",
      "        [2.7507, 2.7787],\n",
      "        [2.5327, 2.4975],\n",
      "        [3.0256, 2.4705],\n",
      "        [2.7183, 2.8136],\n",
      "        [2.8166, 2.9732],\n",
      "        [2.9556, 1.8825],\n",
      "        [2.4886, 2.6461],\n",
      "        [2.4362, 2.9175],\n",
      "        [2.8558, 2.5739],\n",
      "        [2.8213, 2.6381],\n",
      "        [2.4830, 2.3545],\n",
      "        [2.6433, 2.2131],\n",
      "        [2.2587, 2.5003],\n",
      "        [2.4946, 2.1891],\n",
      "        [2.3957, 2.6102],\n",
      "        [3.0604, 1.9975],\n",
      "        [2.5172, 2.2590],\n",
      "        [2.6791, 2.8379],\n",
      "        [2.4996, 2.7239],\n",
      "        [2.1435, 2.4551],\n",
      "        [2.5594, 2.2902],\n",
      "        [2.5457, 3.3757],\n",
      "        [2.9672, 2.6500],\n",
      "        [2.3546, 2.8557],\n",
      "        [2.5751, 2.6276],\n",
      "        [2.6910, 2.9061],\n",
      "        [2.4564, 2.4399],\n",
      "        [2.3106, 2.8196],\n",
      "        [2.6976, 2.4516],\n",
      "        [2.7089, 2.8780],\n",
      "        [2.6744, 2.4966],\n",
      "        [2.5155, 2.6299],\n",
      "        [2.3209, 2.4710],\n",
      "        [2.1858, 2.7655],\n",
      "        [2.5031, 2.5681],\n",
      "        [2.7030, 2.6604],\n",
      "        [2.4307, 2.6640],\n",
      "        [2.7110, 2.5513],\n",
      "        [2.2958, 1.9248],\n",
      "        [2.7224, 2.3719],\n",
      "        [2.5540, 2.9545],\n",
      "        [2.7264, 2.6137],\n",
      "        [2.9064, 2.5126],\n",
      "        [3.0391, 2.1784],\n",
      "        [2.4970, 2.8023],\n",
      "        [2.0540, 2.2615],\n",
      "        [2.6407, 2.7184],\n",
      "        [2.4532, 2.5274],\n",
      "        [2.3721, 2.1931],\n",
      "        [2.5893, 2.6777],\n",
      "        [2.6295, 2.5728],\n",
      "        [2.6271, 2.7524]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.9897, 2.6989],\n",
      "        [2.7051, 2.5666],\n",
      "        [2.5900, 2.7331],\n",
      "        [2.5889, 2.6335],\n",
      "        [2.6035, 2.7129],\n",
      "        [2.7293, 1.8128],\n",
      "        [2.6214, 2.8359],\n",
      "        [2.8149, 2.5985],\n",
      "        [2.8823, 2.7595],\n",
      "        [2.7998, 2.8776],\n",
      "        [2.6332, 2.6035],\n",
      "        [2.6449, 2.3892],\n",
      "        [2.3654, 2.7169],\n",
      "        [2.7924, 2.8886],\n",
      "        [2.3092, 2.5165],\n",
      "        [2.7315, 2.4602],\n",
      "        [2.7753, 2.7004],\n",
      "        [2.1684, 2.7308],\n",
      "        [2.0855, 2.7999],\n",
      "        [2.6416, 2.9064],\n",
      "        [2.0155, 2.5093],\n",
      "        [2.6109, 2.7110],\n",
      "        [2.3760, 2.6911],\n",
      "        [2.7417, 1.9818],\n",
      "        [2.9180, 2.5425],\n",
      "        [2.1287, 3.0369],\n",
      "        [2.1661, 2.3541],\n",
      "        [2.6937, 2.2075],\n",
      "        [2.7086, 2.4131],\n",
      "        [2.7711, 2.7275],\n",
      "        [2.8789, 2.0270],\n",
      "        [2.3009, 2.7616],\n",
      "        [2.2907, 2.5052],\n",
      "        [2.8685, 2.5682],\n",
      "        [2.3632, 2.8899],\n",
      "        [2.5478, 2.8424],\n",
      "        [2.9139, 2.6275],\n",
      "        [2.5863, 2.4213],\n",
      "        [2.7450, 2.7290],\n",
      "        [2.2707, 2.6803],\n",
      "        [2.8372, 2.4395],\n",
      "        [1.9007, 2.4170],\n",
      "        [2.3554, 2.6040],\n",
      "        [2.5632, 2.3632],\n",
      "        [2.6057, 2.6930],\n",
      "        [3.1818, 2.4926],\n",
      "        [2.6867, 2.2856],\n",
      "        [2.5486, 2.4707],\n",
      "        [2.5200, 2.6211],\n",
      "        [2.1559, 2.2941],\n",
      "        [2.9516, 2.6468],\n",
      "        [2.0469, 2.8691],\n",
      "        [2.2813, 2.6243],\n",
      "        [2.4777, 2.6096],\n",
      "        [2.7647, 2.4641],\n",
      "        [2.7722, 2.7973],\n",
      "        [2.8596, 2.1731],\n",
      "        [3.0739, 2.5985],\n",
      "        [2.6792, 2.5752],\n",
      "        [2.4430, 3.0627],\n",
      "        [2.7266, 2.5880],\n",
      "        [2.2904, 2.0568],\n",
      "        [2.4603, 2.4536],\n",
      "        [2.9009, 2.4997],\n",
      "        [2.7290, 2.7667],\n",
      "        [2.3739, 2.1499],\n",
      "        [2.3978, 2.6186],\n",
      "        [2.1049, 2.4459],\n",
      "        [2.5982, 2.6777],\n",
      "        [2.7714, 2.5712],\n",
      "        [2.0688, 2.8161],\n",
      "        [2.7010, 2.4621],\n",
      "        [2.7179, 2.2607],\n",
      "        [2.2828, 2.6354],\n",
      "        [2.2333, 2.6833],\n",
      "        [2.8318, 2.4945],\n",
      "        [2.6848, 2.6409],\n",
      "        [2.0201, 2.6150],\n",
      "        [2.4412, 2.7649],\n",
      "        [2.3958, 2.7724],\n",
      "        [2.3988, 2.6242],\n",
      "        [2.8103, 2.5472],\n",
      "        [2.7237, 2.6934],\n",
      "        [2.4191, 2.5445],\n",
      "        [2.6511, 2.2541],\n",
      "        [2.6483, 2.2495],\n",
      "        [2.3372, 2.5675],\n",
      "        [2.5820, 2.2595],\n",
      "        [2.3792, 3.0846],\n",
      "        [2.6036, 2.0425],\n",
      "        [2.7702, 2.8919],\n",
      "        [2.1779, 2.7147],\n",
      "        [2.5795, 2.1154],\n",
      "        [2.4384, 2.5832],\n",
      "        [2.4134, 2.6096],\n",
      "        [2.5270, 2.8221],\n",
      "        [2.6119, 2.6039],\n",
      "        [2.1704, 2.4717],\n",
      "        [2.5243, 2.3449],\n",
      "        [2.6614, 2.7244]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8878, 3.0622],\n",
      "        [2.9231, 3.1132],\n",
      "        [2.9922, 2.2581],\n",
      "        [2.6597, 2.6679],\n",
      "        [2.6996, 2.0817],\n",
      "        [2.4099, 2.4966],\n",
      "        [2.6111, 2.4243],\n",
      "        [2.5142, 2.2270],\n",
      "        [2.6605, 2.5240],\n",
      "        [2.3300, 2.5323],\n",
      "        [2.6556, 2.7806],\n",
      "        [2.4048, 2.7834],\n",
      "        [2.2438, 2.6881],\n",
      "        [2.5005, 2.4358],\n",
      "        [2.3136, 2.5068],\n",
      "        [2.9482, 2.4888],\n",
      "        [2.2214, 2.3637],\n",
      "        [2.9797, 2.5255],\n",
      "        [2.6504, 2.3859],\n",
      "        [2.5173, 2.7890],\n",
      "        [2.5542, 2.6678],\n",
      "        [2.4239, 2.6150],\n",
      "        [2.3877, 2.1962],\n",
      "        [3.0273, 2.1439],\n",
      "        [3.1474, 2.8334],\n",
      "        [2.4153, 2.7577],\n",
      "        [2.6835, 2.6795],\n",
      "        [2.6185, 2.5728],\n",
      "        [2.5967, 2.5715],\n",
      "        [2.6218, 2.7664],\n",
      "        [2.3098, 2.5865],\n",
      "        [2.6383, 2.5094],\n",
      "        [2.3835, 2.7387],\n",
      "        [2.7039, 2.8066],\n",
      "        [2.2623, 2.2125],\n",
      "        [1.9135, 2.5232],\n",
      "        [2.7313, 2.5389],\n",
      "        [2.6235, 2.5029],\n",
      "        [2.4476, 2.4428],\n",
      "        [2.4456, 2.7464],\n",
      "        [3.1278, 2.3950],\n",
      "        [2.2788, 2.8672],\n",
      "        [2.7467, 2.6566],\n",
      "        [2.7935, 2.4946],\n",
      "        [2.5688, 2.2355],\n",
      "        [2.6468, 2.6125],\n",
      "        [2.3535, 2.3053],\n",
      "        [2.7466, 2.5962],\n",
      "        [2.5122, 2.3274],\n",
      "        [2.4699, 2.8116],\n",
      "        [2.4894, 2.7474],\n",
      "        [2.6431, 2.2703],\n",
      "        [2.7919, 2.3957],\n",
      "        [3.1077, 3.3591],\n",
      "        [2.7274, 2.5637],\n",
      "        [2.5162, 2.9163],\n",
      "        [3.0068, 2.6779],\n",
      "        [2.6377, 2.3093],\n",
      "        [3.2082, 2.7029],\n",
      "        [2.5642, 2.4777],\n",
      "        [2.5170, 2.3772],\n",
      "        [2.3922, 2.4805],\n",
      "        [2.3846, 2.2907],\n",
      "        [2.4822, 2.7258],\n",
      "        [2.8094, 2.4264],\n",
      "        [2.4443, 2.8800],\n",
      "        [2.2380, 2.4617],\n",
      "        [2.6158, 2.2653],\n",
      "        [2.7974, 2.0969],\n",
      "        [2.4869, 2.4391],\n",
      "        [2.1885, 2.9749],\n",
      "        [2.5666, 2.3493],\n",
      "        [2.8282, 2.0959],\n",
      "        [2.4259, 2.8021],\n",
      "        [2.4152, 2.8598],\n",
      "        [2.4615, 2.4293],\n",
      "        [2.4058, 2.5876],\n",
      "        [2.0500, 2.7301],\n",
      "        [2.8007, 2.6957],\n",
      "        [3.2216, 2.3349],\n",
      "        [2.8514, 2.8918],\n",
      "        [2.1546, 2.6776],\n",
      "        [2.1827, 2.6258],\n",
      "        [2.7469, 2.2553],\n",
      "        [1.9757, 2.6857],\n",
      "        [2.6381, 2.4384],\n",
      "        [2.3407, 2.2309],\n",
      "        [2.2050, 2.5800],\n",
      "        [2.6673, 2.2997],\n",
      "        [2.9606, 2.9121],\n",
      "        [2.6805, 2.8493],\n",
      "        [2.6851, 2.1637],\n",
      "        [2.5766, 2.5290],\n",
      "        [2.4970, 2.5705],\n",
      "        [2.6137, 2.3282],\n",
      "        [2.4998, 2.5965],\n",
      "        [2.6352, 2.3468],\n",
      "        [2.9990, 2.4477],\n",
      "        [2.5226, 2.3193],\n",
      "        [2.3096, 2.3710]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 25 complete in 0:01:13.912781; est. finish at 2021-11-29 21:56:16.489763\n",
      "Validation: 0.47 train | 0.494 dev\n",
      "### Epoch: 26 ###\n",
      "y:  tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[3.0566, 3.1860],\n",
      "        [2.4060, 2.4354],\n",
      "        [2.7231, 2.5485],\n",
      "        [2.2911, 2.6475],\n",
      "        [1.9805, 2.6127],\n",
      "        [2.3787, 2.4293],\n",
      "        [2.3591, 2.9757],\n",
      "        [2.5471, 2.4114],\n",
      "        [2.8327, 2.4972],\n",
      "        [2.4282, 2.3492],\n",
      "        [2.6165, 2.6702],\n",
      "        [2.5221, 2.8952],\n",
      "        [3.0096, 3.0308],\n",
      "        [2.5446, 2.4038],\n",
      "        [2.5452, 2.7720],\n",
      "        [2.4894, 2.4274],\n",
      "        [2.4479, 2.3566],\n",
      "        [2.7369, 2.6853],\n",
      "        [2.4894, 2.3205],\n",
      "        [2.2552, 2.6399],\n",
      "        [2.4553, 2.1553],\n",
      "        [2.6496, 3.0665],\n",
      "        [2.6829, 2.2457],\n",
      "        [2.9514, 2.4113],\n",
      "        [2.7848, 2.9141],\n",
      "        [2.5730, 2.2159],\n",
      "        [2.5253, 2.7437],\n",
      "        [2.7285, 2.4786],\n",
      "        [2.6177, 2.3473],\n",
      "        [2.7486, 2.8426],\n",
      "        [2.6559, 2.8609],\n",
      "        [2.6384, 2.4471],\n",
      "        [2.2406, 2.1714],\n",
      "        [2.6006, 2.8702],\n",
      "        [2.6608, 2.6768],\n",
      "        [2.6672, 2.5809],\n",
      "        [2.4727, 2.7286],\n",
      "        [2.3251, 2.8511],\n",
      "        [2.4296, 2.3665],\n",
      "        [2.8873, 2.4597],\n",
      "        [3.0403, 2.5642],\n",
      "        [2.7231, 2.7645],\n",
      "        [2.3156, 2.8136],\n",
      "        [2.6749, 2.7839],\n",
      "        [2.4480, 2.4134],\n",
      "        [2.6670, 2.6588],\n",
      "        [2.2208, 2.7325],\n",
      "        [2.3438, 2.7101],\n",
      "        [2.2346, 2.5559],\n",
      "        [2.9007, 2.3045],\n",
      "        [2.3625, 2.4675],\n",
      "        [2.7485, 2.4461],\n",
      "        [2.8515, 1.9993],\n",
      "        [2.5697, 2.6178],\n",
      "        [2.8915, 2.7377],\n",
      "        [2.8198, 2.0153],\n",
      "        [2.3414, 2.7721],\n",
      "        [2.3257, 2.5431],\n",
      "        [2.6163, 2.5697],\n",
      "        [2.6233, 2.9732],\n",
      "        [2.7542, 2.5875],\n",
      "        [2.8662, 2.6587],\n",
      "        [2.5573, 2.4941],\n",
      "        [2.8381, 2.3093],\n",
      "        [2.9630, 2.6246],\n",
      "        [2.3315, 2.4473],\n",
      "        [2.4376, 2.4672],\n",
      "        [2.4017, 2.4434],\n",
      "        [2.2802, 2.3197],\n",
      "        [2.6780, 2.7797],\n",
      "        [2.6987, 2.4673],\n",
      "        [2.2844, 3.0250],\n",
      "        [2.5047, 2.4909],\n",
      "        [3.0494, 2.3985],\n",
      "        [2.1887, 2.1880],\n",
      "        [2.2212, 2.5173],\n",
      "        [2.3449, 2.5999],\n",
      "        [2.8396, 2.2363],\n",
      "        [2.2309, 2.8006],\n",
      "        [2.3206, 2.6716],\n",
      "        [2.9825, 2.2503],\n",
      "        [2.4316, 2.5553],\n",
      "        [2.7392, 2.3111],\n",
      "        [2.7454, 2.1233],\n",
      "        [2.4006, 2.5299],\n",
      "        [2.7351, 2.8322],\n",
      "        [2.7613, 2.8692],\n",
      "        [2.4224, 2.5359],\n",
      "        [2.8964, 2.6216],\n",
      "        [2.3538, 2.6945],\n",
      "        [2.7763, 2.5517],\n",
      "        [2.4192, 2.3008],\n",
      "        [2.5535, 3.0084],\n",
      "        [2.8608, 2.4153],\n",
      "        [3.1411, 2.7560],\n",
      "        [2.4695, 2.6120],\n",
      "        [2.3062, 2.5046],\n",
      "        [2.9071, 2.5517],\n",
      "        [2.6574, 2.4410],\n",
      "        [1.9884, 2.6505]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.9400, 2.5970],\n",
      "        [2.7520, 2.3867],\n",
      "        [2.6519, 2.3164],\n",
      "        [2.7414, 2.8995],\n",
      "        [2.2580, 2.7458],\n",
      "        [2.7425, 2.6083],\n",
      "        [2.2310, 2.5313],\n",
      "        [2.8531, 2.4334],\n",
      "        [2.3784, 2.9867],\n",
      "        [2.4000, 2.4450],\n",
      "        [2.8671, 2.7596],\n",
      "        [2.5546, 2.4507],\n",
      "        [2.4194, 2.5187],\n",
      "        [2.1830, 2.5316],\n",
      "        [2.5797, 2.4698],\n",
      "        [2.4504, 2.5574],\n",
      "        [2.9650, 2.5360],\n",
      "        [2.7288, 2.6590],\n",
      "        [2.3700, 2.6908],\n",
      "        [2.9336, 2.4410],\n",
      "        [2.4793, 2.9616],\n",
      "        [2.8148, 2.7428],\n",
      "        [2.6142, 2.7970],\n",
      "        [2.5348, 2.6587],\n",
      "        [2.4396, 2.7828],\n",
      "        [2.6247, 2.8822],\n",
      "        [2.5028, 2.4940],\n",
      "        [2.4720, 2.2153],\n",
      "        [2.6272, 2.4225],\n",
      "        [2.5697, 2.7724],\n",
      "        [2.6288, 2.2726],\n",
      "        [2.1221, 2.2224],\n",
      "        [2.9185, 2.4777],\n",
      "        [2.2107, 2.4128],\n",
      "        [2.7134, 2.4359],\n",
      "        [2.8530, 2.6450],\n",
      "        [2.6235, 3.1228],\n",
      "        [2.4196, 2.7697],\n",
      "        [2.7065, 2.9775],\n",
      "        [2.9275, 3.0062],\n",
      "        [2.8036, 2.5977],\n",
      "        [2.4537, 2.6008],\n",
      "        [2.8730, 2.6465],\n",
      "        [2.2687, 2.2655],\n",
      "        [2.6111, 2.5871],\n",
      "        [2.6912, 2.5285],\n",
      "        [2.0728, 2.3642],\n",
      "        [2.1687, 2.6207],\n",
      "        [2.4268, 2.2385],\n",
      "        [2.5479, 2.7750],\n",
      "        [2.7124, 2.3625],\n",
      "        [2.7221, 3.2473],\n",
      "        [2.3950, 2.4329],\n",
      "        [2.2378, 2.5821],\n",
      "        [2.5211, 2.0214],\n",
      "        [2.0506, 2.5243],\n",
      "        [2.3547, 2.1595],\n",
      "        [2.6307, 2.6100],\n",
      "        [2.7833, 2.7546],\n",
      "        [2.4713, 2.9738],\n",
      "        [2.5467, 2.3797],\n",
      "        [2.1083, 2.8895],\n",
      "        [2.2394, 2.4010],\n",
      "        [2.7347, 2.0763],\n",
      "        [2.4230, 2.6743],\n",
      "        [2.4941, 2.9310],\n",
      "        [2.4710, 2.6623],\n",
      "        [2.4604, 2.7072],\n",
      "        [2.8494, 2.7554],\n",
      "        [2.5544, 2.5377],\n",
      "        [2.4635, 2.2698],\n",
      "        [2.7414, 3.5245],\n",
      "        [2.5374, 2.3758],\n",
      "        [2.5925, 2.6694],\n",
      "        [2.5457, 2.0411],\n",
      "        [2.9316, 2.4464],\n",
      "        [2.3383, 2.4976],\n",
      "        [2.4877, 2.9742],\n",
      "        [2.7527, 2.3258],\n",
      "        [3.1537, 2.8133],\n",
      "        [2.2885, 2.7400],\n",
      "        [2.5892, 2.1606],\n",
      "        [2.7564, 2.6004],\n",
      "        [2.7189, 3.0512],\n",
      "        [2.6146, 2.2806],\n",
      "        [2.4166, 2.2538],\n",
      "        [2.6165, 2.9307],\n",
      "        [2.5797, 2.6266],\n",
      "        [2.0159, 2.3879],\n",
      "        [2.2438, 2.4528],\n",
      "        [2.4230, 2.7957],\n",
      "        [2.4744, 2.8544],\n",
      "        [2.0453, 2.3484],\n",
      "        [2.6986, 2.8389],\n",
      "        [2.3702, 2.7388],\n",
      "        [2.8683, 2.6362],\n",
      "        [2.1595, 2.9598],\n",
      "        [2.5159, 2.6936],\n",
      "        [2.6337, 2.6431],\n",
      "        [2.2083, 2.3727]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5276, 2.3599],\n",
      "        [2.7806, 3.0942],\n",
      "        [3.1314, 2.5545],\n",
      "        [2.8640, 2.4559],\n",
      "        [2.5327, 2.4704],\n",
      "        [2.7835, 2.0755],\n",
      "        [2.7278, 2.5356],\n",
      "        [2.5898, 2.5252],\n",
      "        [2.8823, 2.5021],\n",
      "        [2.5469, 2.3603],\n",
      "        [2.8766, 2.4868],\n",
      "        [2.2283, 2.4406],\n",
      "        [2.4901, 3.1022],\n",
      "        [2.4833, 2.4438],\n",
      "        [2.5976, 2.6236],\n",
      "        [2.9532, 2.5109],\n",
      "        [2.6342, 2.3801],\n",
      "        [2.8056, 2.6716],\n",
      "        [2.7152, 2.4949],\n",
      "        [2.5750, 2.3016],\n",
      "        [2.7063, 2.8241],\n",
      "        [2.4940, 2.5999],\n",
      "        [2.0953, 2.6721],\n",
      "        [2.2943, 2.3862],\n",
      "        [2.6025, 2.5077],\n",
      "        [3.0036, 2.3066],\n",
      "        [2.3176, 2.7562],\n",
      "        [2.9050, 2.5466],\n",
      "        [2.4527, 2.8479],\n",
      "        [2.1551, 2.6612],\n",
      "        [2.6837, 2.4036],\n",
      "        [2.6609, 2.1867],\n",
      "        [2.6462, 2.6889],\n",
      "        [2.4650, 2.7149],\n",
      "        [2.7809, 2.1215],\n",
      "        [1.9374, 2.9224],\n",
      "        [2.8929, 2.3172],\n",
      "        [2.6776, 2.2433],\n",
      "        [3.1823, 2.8595],\n",
      "        [2.9190, 2.8778],\n",
      "        [2.7115, 2.3804],\n",
      "        [2.5203, 2.3948],\n",
      "        [2.3643, 2.2674],\n",
      "        [2.2376, 2.6854],\n",
      "        [2.8752, 2.3763],\n",
      "        [2.9875, 3.0834],\n",
      "        [2.6036, 2.9054],\n",
      "        [2.7758, 2.8953],\n",
      "        [2.0937, 2.4040],\n",
      "        [2.9449, 2.3475],\n",
      "        [2.1614, 2.8032],\n",
      "        [2.3954, 2.5572],\n",
      "        [2.3852, 2.9034],\n",
      "        [2.2252, 2.4483],\n",
      "        [2.4915, 2.6510],\n",
      "        [2.3968, 2.4072],\n",
      "        [2.6825, 2.1483],\n",
      "        [2.8657, 2.7812],\n",
      "        [2.5514, 2.3421],\n",
      "        [2.6710, 2.6302],\n",
      "        [2.7812, 2.5105],\n",
      "        [2.1160, 3.0017],\n",
      "        [2.4747, 2.6028],\n",
      "        [2.8050, 2.0928],\n",
      "        [2.2615, 2.4354],\n",
      "        [2.4308, 2.7411],\n",
      "        [2.6422, 2.7070],\n",
      "        [2.4007, 2.7834],\n",
      "        [2.7792, 2.1134],\n",
      "        [2.4777, 2.1688],\n",
      "        [2.6435, 2.6963],\n",
      "        [2.7557, 3.2190],\n",
      "        [2.5218, 2.5699],\n",
      "        [3.0231, 2.5921],\n",
      "        [2.4131, 2.4991],\n",
      "        [2.8684, 2.6246],\n",
      "        [2.5778, 2.7004],\n",
      "        [2.2106, 2.8985],\n",
      "        [2.5758, 2.6430],\n",
      "        [2.4895, 2.1874],\n",
      "        [2.7551, 2.4814],\n",
      "        [2.8026, 2.8260],\n",
      "        [2.5847, 2.7071],\n",
      "        [2.4164, 2.6651],\n",
      "        [2.0991, 2.4031],\n",
      "        [2.3996, 2.2540],\n",
      "        [2.6969, 2.0499],\n",
      "        [2.2275, 3.0859],\n",
      "        [2.5261, 2.5561],\n",
      "        [2.6086, 2.6280],\n",
      "        [2.7027, 2.5672],\n",
      "        [2.4554, 2.4016],\n",
      "        [3.0024, 2.5790],\n",
      "        [2.6350, 2.6776],\n",
      "        [2.8245, 2.6036],\n",
      "        [2.4675, 2.2321],\n",
      "        [2.5876, 2.4119],\n",
      "        [2.7719, 2.6465],\n",
      "        [2.7003, 2.7497],\n",
      "        [2.6927, 2.6931]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7219, 2.4177],\n",
      "        [2.6497, 2.4996],\n",
      "        [2.7974, 2.6301],\n",
      "        [2.7096, 2.7929],\n",
      "        [2.8848, 2.5356],\n",
      "        [1.5407, 2.8588],\n",
      "        [2.3025, 2.8036],\n",
      "        [2.4040, 2.5988],\n",
      "        [2.7001, 2.5264],\n",
      "        [2.9214, 2.9074],\n",
      "        [2.6360, 2.5779],\n",
      "        [3.0043, 2.4360],\n",
      "        [3.0371, 2.7582],\n",
      "        [2.5269, 2.6079],\n",
      "        [2.2334, 1.9570],\n",
      "        [2.4041, 2.4958],\n",
      "        [2.8053, 2.2349],\n",
      "        [2.8746, 2.4013],\n",
      "        [3.2147, 2.8665],\n",
      "        [2.7443, 2.4254],\n",
      "        [2.3996, 2.4590],\n",
      "        [2.3464, 2.7782],\n",
      "        [2.4262, 2.3948],\n",
      "        [2.7438, 2.4194],\n",
      "        [2.4836, 2.7483],\n",
      "        [3.0562, 2.5206],\n",
      "        [2.3081, 2.3749],\n",
      "        [2.3428, 2.9519],\n",
      "        [2.0542, 2.5656],\n",
      "        [2.5980, 2.6297],\n",
      "        [2.4218, 2.5461],\n",
      "        [2.6495, 2.2198],\n",
      "        [2.1043, 2.6475],\n",
      "        [2.4486, 2.6280],\n",
      "        [2.4837, 2.3897],\n",
      "        [2.0782, 3.2668],\n",
      "        [2.8628, 2.4292],\n",
      "        [2.0895, 2.7100],\n",
      "        [2.8953, 2.7895],\n",
      "        [2.7442, 2.3820],\n",
      "        [2.3940, 2.8765],\n",
      "        [2.3299, 2.5036],\n",
      "        [2.3803, 2.6832],\n",
      "        [2.6700, 2.4983],\n",
      "        [2.2894, 2.5705],\n",
      "        [2.7737, 2.6062],\n",
      "        [2.2419, 2.6724],\n",
      "        [2.4749, 2.4483],\n",
      "        [2.0570, 2.5493],\n",
      "        [2.5074, 2.2876],\n",
      "        [2.7364, 2.1244],\n",
      "        [2.5378, 2.6676],\n",
      "        [2.3503, 2.1199],\n",
      "        [2.6449, 2.7653],\n",
      "        [2.8427, 2.2835],\n",
      "        [2.4665, 2.3859],\n",
      "        [2.5204, 2.4306],\n",
      "        [2.9340, 2.4469],\n",
      "        [2.6985, 2.5904],\n",
      "        [2.8592, 2.4376],\n",
      "        [2.5033, 2.6554],\n",
      "        [2.1210, 2.3930],\n",
      "        [2.7887, 3.0381],\n",
      "        [2.6877, 2.4127],\n",
      "        [2.5429, 2.9146],\n",
      "        [2.7854, 2.2534],\n",
      "        [2.6760, 2.8062],\n",
      "        [3.0081, 2.4100],\n",
      "        [3.0073, 2.6307],\n",
      "        [2.3430, 2.7028],\n",
      "        [2.3871, 2.6951],\n",
      "        [2.2863, 3.0405],\n",
      "        [2.8057, 2.7990],\n",
      "        [2.9047, 2.6517],\n",
      "        [2.7670, 2.7329],\n",
      "        [2.2136, 3.0347],\n",
      "        [2.3166, 2.8060],\n",
      "        [2.6232, 2.3749],\n",
      "        [2.7887, 2.6410],\n",
      "        [2.5365, 2.5885],\n",
      "        [2.7894, 2.6527],\n",
      "        [2.5018, 2.7809],\n",
      "        [2.5037, 2.7298],\n",
      "        [2.8742, 2.6202],\n",
      "        [2.6692, 2.4942],\n",
      "        [2.6583, 2.5004],\n",
      "        [2.9006, 2.7657],\n",
      "        [2.7585, 2.6226],\n",
      "        [2.5374, 2.4254],\n",
      "        [2.7589, 2.6688],\n",
      "        [2.7841, 2.4380],\n",
      "        [2.6722, 2.3888],\n",
      "        [3.0874, 2.5355],\n",
      "        [2.6437, 2.3750],\n",
      "        [2.7069, 2.1796],\n",
      "        [2.3231, 2.2723],\n",
      "        [2.4122, 2.7133],\n",
      "        [2.6736, 3.1056],\n",
      "        [2.4815, 2.3564],\n",
      "        [2.5083, 2.7144]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5613, 2.8485],\n",
      "        [2.8145, 2.2242],\n",
      "        [2.4242, 2.4112],\n",
      "        [2.4961, 3.1062],\n",
      "        [2.7516, 2.8125],\n",
      "        [2.1648, 2.5465],\n",
      "        [2.5266, 2.5999],\n",
      "        [2.9432, 2.3113],\n",
      "        [2.6516, 2.3676],\n",
      "        [2.2917, 2.6317],\n",
      "        [2.5008, 2.5757],\n",
      "        [2.8348, 2.4946],\n",
      "        [2.1451, 2.5836],\n",
      "        [2.4806, 2.7688],\n",
      "        [2.2091, 2.8812],\n",
      "        [2.7675, 2.6203],\n",
      "        [2.6250, 2.9100],\n",
      "        [2.2324, 2.6998],\n",
      "        [2.2202, 2.8544],\n",
      "        [2.5992, 2.8537],\n",
      "        [2.8188, 2.2172],\n",
      "        [2.3627, 2.7576],\n",
      "        [2.0125, 2.6241],\n",
      "        [2.6576, 2.6140],\n",
      "        [2.7784, 2.7371],\n",
      "        [2.0728, 2.5075],\n",
      "        [2.2582, 3.0123],\n",
      "        [2.5460, 2.2927],\n",
      "        [2.7318, 2.1131],\n",
      "        [2.8540, 2.4736],\n",
      "        [2.6974, 2.6317],\n",
      "        [2.1858, 2.7898],\n",
      "        [2.8048, 2.4305],\n",
      "        [3.0192, 2.0823],\n",
      "        [2.6234, 2.7949],\n",
      "        [2.1432, 2.7324],\n",
      "        [2.5748, 2.5338],\n",
      "        [2.4237, 2.7981],\n",
      "        [2.4724, 2.7829],\n",
      "        [2.3213, 2.1677],\n",
      "        [2.6475, 2.6754],\n",
      "        [2.7572, 2.3760],\n",
      "        [2.5363, 2.7428],\n",
      "        [2.6546, 2.5134],\n",
      "        [2.5292, 2.1707],\n",
      "        [2.7712, 2.4440],\n",
      "        [2.5063, 2.9369],\n",
      "        [2.2538, 2.5274],\n",
      "        [2.4525, 2.8253],\n",
      "        [3.2222, 2.7191],\n",
      "        [1.7357, 2.9781],\n",
      "        [2.3920, 2.2660],\n",
      "        [2.4510, 1.8389],\n",
      "        [2.3443, 3.0466],\n",
      "        [2.5829, 2.8633],\n",
      "        [2.8332, 2.8828],\n",
      "        [2.8130, 2.3192],\n",
      "        [2.4309, 2.4960],\n",
      "        [2.4943, 2.4961],\n",
      "        [2.2646, 2.2308],\n",
      "        [2.7235, 2.4842],\n",
      "        [2.2957, 2.7790],\n",
      "        [3.0408, 2.7968],\n",
      "        [2.9368, 2.4502],\n",
      "        [2.2301, 2.8082],\n",
      "        [2.2861, 2.4577],\n",
      "        [2.4400, 2.4383],\n",
      "        [2.4728, 2.5697],\n",
      "        [2.6777, 2.3832],\n",
      "        [2.6274, 2.8748],\n",
      "        [2.5113, 2.7778],\n",
      "        [2.8083, 2.4374],\n",
      "        [2.5890, 2.5661],\n",
      "        [2.4811, 2.5361],\n",
      "        [2.6171, 2.3421],\n",
      "        [2.4334, 2.2961],\n",
      "        [2.2520, 2.7824],\n",
      "        [2.5569, 2.6728],\n",
      "        [3.0233, 2.6940],\n",
      "        [2.6650, 2.0661],\n",
      "        [2.4961, 2.4641],\n",
      "        [2.7838, 2.7854],\n",
      "        [2.3172, 2.6865],\n",
      "        [2.6439, 2.5305],\n",
      "        [2.8903, 2.5688],\n",
      "        [2.1147, 2.7691],\n",
      "        [2.3812, 2.9606],\n",
      "        [2.2454, 2.5135],\n",
      "        [2.2532, 2.4030],\n",
      "        [2.2680, 2.2058],\n",
      "        [2.6465, 2.5574],\n",
      "        [2.4711, 2.6642],\n",
      "        [1.7385, 2.4777],\n",
      "        [2.4807, 2.2006],\n",
      "        [3.0963, 2.4971],\n",
      "        [2.5379, 2.6588],\n",
      "        [2.0831, 2.8924],\n",
      "        [2.3170, 2.4825],\n",
      "        [2.6272, 2.4416],\n",
      "        [2.3062, 2.7596]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 30 complete in 0:01:28.836239; est. finish at 2021-11-29 21:56:16.959463\n",
      "Validation: 0.49 train | 0.516 dev\n",
      "### Epoch: 31 ###\n",
      "y:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3713, 2.4656],\n",
      "        [3.0044, 2.6556],\n",
      "        [2.7330, 2.9131],\n",
      "        [2.6269, 2.6009],\n",
      "        [2.4951, 2.3893],\n",
      "        [2.6040, 2.7732],\n",
      "        [3.1608, 2.2766],\n",
      "        [2.7016, 2.6999],\n",
      "        [2.1804, 2.9095],\n",
      "        [2.7105, 2.7724],\n",
      "        [2.5324, 2.6883],\n",
      "        [2.2773, 2.2767],\n",
      "        [2.7306, 2.7231],\n",
      "        [2.8886, 2.7330],\n",
      "        [2.2272, 2.5597],\n",
      "        [2.4300, 2.6328],\n",
      "        [2.6085, 2.1789],\n",
      "        [2.7144, 2.7089],\n",
      "        [2.9660, 2.4258],\n",
      "        [2.7218, 2.7699],\n",
      "        [2.5737, 2.6320],\n",
      "        [2.7603, 2.3612],\n",
      "        [2.3566, 2.8042],\n",
      "        [2.4366, 2.4572],\n",
      "        [2.8782, 2.6645],\n",
      "        [2.5399, 2.8660],\n",
      "        [3.2014, 2.4055],\n",
      "        [2.5160, 2.4238],\n",
      "        [2.3327, 2.8468],\n",
      "        [2.4312, 2.8630],\n",
      "        [2.5639, 2.8505],\n",
      "        [2.8272, 2.4154],\n",
      "        [2.8760, 2.2056],\n",
      "        [2.8141, 2.6779],\n",
      "        [2.5289, 2.8156],\n",
      "        [2.5429, 2.6762],\n",
      "        [2.5516, 2.3939],\n",
      "        [2.4833, 2.3988],\n",
      "        [2.1718, 2.6534],\n",
      "        [2.7916, 2.7276],\n",
      "        [2.3974, 2.3510],\n",
      "        [2.5878, 2.5567],\n",
      "        [2.6435, 2.1664],\n",
      "        [2.1904, 2.5778],\n",
      "        [1.8882, 2.8366],\n",
      "        [2.6616, 3.0403],\n",
      "        [2.3628, 2.5440],\n",
      "        [2.7548, 3.1333],\n",
      "        [2.4235, 2.4859],\n",
      "        [2.4387, 2.4776],\n",
      "        [2.6493, 2.8462],\n",
      "        [2.4718, 2.5940],\n",
      "        [2.1717, 2.6980],\n",
      "        [2.1996, 2.1721],\n",
      "        [3.1688, 2.4183],\n",
      "        [2.5556, 2.7604],\n",
      "        [2.4935, 2.3039],\n",
      "        [2.8761, 2.4158],\n",
      "        [2.0976, 2.6444],\n",
      "        [2.9061, 2.2568],\n",
      "        [2.5225, 2.5608],\n",
      "        [2.5391, 2.2839],\n",
      "        [2.7488, 2.5332],\n",
      "        [2.5387, 2.1158],\n",
      "        [2.7524, 2.8429],\n",
      "        [2.5454, 2.5231],\n",
      "        [3.0450, 2.7091],\n",
      "        [2.1355, 2.6648],\n",
      "        [2.2496, 2.6806],\n",
      "        [2.3796, 2.3220],\n",
      "        [2.2909, 2.5335],\n",
      "        [2.2194, 2.9966],\n",
      "        [2.5041, 2.7469],\n",
      "        [2.7742, 2.5198],\n",
      "        [2.8948, 2.7826],\n",
      "        [2.5255, 2.3902],\n",
      "        [2.0180, 2.7636],\n",
      "        [2.4221, 2.4049],\n",
      "        [2.3657, 2.8311],\n",
      "        [2.7664, 2.6563],\n",
      "        [3.0039, 2.0652],\n",
      "        [2.3450, 2.8002],\n",
      "        [2.6697, 2.6161],\n",
      "        [2.4398, 2.5704],\n",
      "        [2.3791, 2.1354],\n",
      "        [2.1012, 2.2214],\n",
      "        [2.6393, 2.7852],\n",
      "        [2.3831, 3.0464],\n",
      "        [2.7671, 2.7607],\n",
      "        [2.6360, 2.4523],\n",
      "        [2.4916, 2.8109],\n",
      "        [2.3098, 2.1826],\n",
      "        [2.5910, 2.8276],\n",
      "        [2.5172, 2.6331],\n",
      "        [2.1110, 2.1238],\n",
      "        [2.7135, 2.8763],\n",
      "        [2.5701, 2.3284],\n",
      "        [2.6650, 2.9502],\n",
      "        [2.0153, 2.0023],\n",
      "        [2.7725, 2.4932]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6621, 2.4135],\n",
      "        [2.7673, 2.1894],\n",
      "        [2.5697, 3.0446],\n",
      "        [2.3746, 1.8087],\n",
      "        [2.8087, 2.3722],\n",
      "        [3.1576, 2.6202],\n",
      "        [2.1962, 2.3884],\n",
      "        [2.2348, 2.4034],\n",
      "        [2.4073, 2.4210],\n",
      "        [2.4977, 2.2593],\n",
      "        [2.5096, 2.7819],\n",
      "        [2.1238, 3.1392],\n",
      "        [2.4996, 2.9178],\n",
      "        [2.4736, 2.4025],\n",
      "        [2.8807, 2.3379],\n",
      "        [2.6914, 2.2038],\n",
      "        [2.5957, 2.6530],\n",
      "        [2.8120, 2.5005],\n",
      "        [2.0374, 2.6407],\n",
      "        [2.5743, 2.9549],\n",
      "        [2.1720, 2.7067],\n",
      "        [2.6862, 2.7736],\n",
      "        [2.3695, 2.7538],\n",
      "        [2.7874, 2.4371],\n",
      "        [2.7400, 2.7182],\n",
      "        [2.3980, 2.4069],\n",
      "        [2.3122, 2.1357],\n",
      "        [2.7366, 1.9654],\n",
      "        [2.3333, 2.5649],\n",
      "        [2.6629, 2.5995],\n",
      "        [2.3259, 2.5105],\n",
      "        [2.6965, 2.3904],\n",
      "        [2.5558, 2.8530],\n",
      "        [2.5970, 2.2449],\n",
      "        [2.5836, 3.0985],\n",
      "        [2.4965, 2.5511],\n",
      "        [2.3409, 2.2624],\n",
      "        [2.7613, 2.4642],\n",
      "        [3.0296, 2.6487],\n",
      "        [2.9325, 2.5317],\n",
      "        [2.5334, 2.1788],\n",
      "        [2.3818, 2.4720],\n",
      "        [2.6178, 2.5157],\n",
      "        [2.9531, 2.2535],\n",
      "        [2.4249, 2.4711],\n",
      "        [2.7011, 2.5651],\n",
      "        [2.4916, 2.7184],\n",
      "        [2.7411, 2.1308],\n",
      "        [2.9252, 2.8057],\n",
      "        [2.5864, 2.9398],\n",
      "        [2.0141, 2.8869],\n",
      "        [2.5469, 2.7450],\n",
      "        [2.5539, 2.8934],\n",
      "        [2.8206, 2.1391],\n",
      "        [2.7716, 2.4697],\n",
      "        [2.7776, 2.4585],\n",
      "        [2.3613, 2.3066],\n",
      "        [2.9565, 2.3797],\n",
      "        [2.4379, 2.6700],\n",
      "        [2.2648, 2.3992],\n",
      "        [2.3614, 2.1419],\n",
      "        [2.8832, 2.4933],\n",
      "        [2.6589, 2.1305],\n",
      "        [3.0928, 2.7255],\n",
      "        [2.6640, 2.5411],\n",
      "        [2.6608, 2.8649],\n",
      "        [2.1652, 2.2596],\n",
      "        [2.0594, 2.6369],\n",
      "        [2.4956, 2.8631],\n",
      "        [2.4986, 2.7092],\n",
      "        [2.8624, 2.5003],\n",
      "        [2.9947, 2.4304],\n",
      "        [3.0329, 2.4930],\n",
      "        [2.2564, 2.6811],\n",
      "        [2.7084, 2.5582],\n",
      "        [2.4051, 3.0690],\n",
      "        [2.2287, 2.5773],\n",
      "        [2.1260, 3.1896],\n",
      "        [2.5275, 2.5074],\n",
      "        [2.3597, 2.7352],\n",
      "        [2.5494, 3.0210],\n",
      "        [2.4364, 2.7382],\n",
      "        [2.6219, 2.3473],\n",
      "        [2.8262, 2.6247],\n",
      "        [2.2649, 2.4921],\n",
      "        [2.1814, 2.4474],\n",
      "        [2.5605, 2.8847],\n",
      "        [2.3656, 2.9328],\n",
      "        [2.9991, 2.4206],\n",
      "        [2.9246, 2.4126],\n",
      "        [2.4249, 2.7853],\n",
      "        [2.5636, 2.3069],\n",
      "        [2.6998, 2.9493],\n",
      "        [2.5034, 2.1719],\n",
      "        [2.4335, 2.3455],\n",
      "        [2.7123, 2.4355],\n",
      "        [2.6347, 2.9013],\n",
      "        [2.7809, 2.9458],\n",
      "        [2.3263, 2.4076],\n",
      "        [2.6933, 2.6993]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6993, 2.5678],\n",
      "        [2.3899, 2.3857],\n",
      "        [3.0132, 2.3081],\n",
      "        [2.5082, 2.5177],\n",
      "        [2.4391, 2.5920],\n",
      "        [2.0639, 2.4582],\n",
      "        [2.2728, 2.7001],\n",
      "        [2.1740, 2.5577],\n",
      "        [2.4303, 2.9646],\n",
      "        [2.7736, 2.6299],\n",
      "        [2.1698, 2.3469],\n",
      "        [2.3761, 2.3282],\n",
      "        [2.7936, 2.5916],\n",
      "        [2.3363, 2.3867],\n",
      "        [2.8167, 2.3726],\n",
      "        [2.7821, 2.4864],\n",
      "        [2.6741, 2.1388],\n",
      "        [2.6383, 2.3510],\n",
      "        [2.7072, 2.2689],\n",
      "        [2.5626, 2.6519],\n",
      "        [2.6652, 2.9558],\n",
      "        [2.6394, 3.0742],\n",
      "        [2.4921, 2.5578],\n",
      "        [2.8262, 2.1404],\n",
      "        [2.5704, 2.9050],\n",
      "        [2.4133, 2.4089],\n",
      "        [2.9490, 2.6159],\n",
      "        [2.6281, 2.7099],\n",
      "        [2.5014, 2.3694],\n",
      "        [2.2437, 2.7087],\n",
      "        [2.4039, 2.5943],\n",
      "        [2.4210, 2.3658],\n",
      "        [2.5506, 2.7209],\n",
      "        [2.6440, 2.7669],\n",
      "        [2.4883, 2.6904],\n",
      "        [2.8445, 2.4029],\n",
      "        [2.6775, 2.6802],\n",
      "        [2.2066, 2.5282],\n",
      "        [2.8156, 3.0439],\n",
      "        [2.6100, 2.4686],\n",
      "        [2.7707, 2.5779],\n",
      "        [2.7756, 2.8087],\n",
      "        [2.5702, 2.6956],\n",
      "        [2.3359, 2.2678],\n",
      "        [2.4365, 2.5934],\n",
      "        [2.5444, 2.4613],\n",
      "        [2.3712, 2.4825],\n",
      "        [3.1469, 2.5079],\n",
      "        [2.3805, 2.7038],\n",
      "        [2.4848, 2.1498],\n",
      "        [2.6671, 2.5518],\n",
      "        [2.4196, 2.4036],\n",
      "        [2.5812, 2.7335],\n",
      "        [2.7113, 2.5197],\n",
      "        [2.6481, 2.5304],\n",
      "        [3.0347, 3.0237],\n",
      "        [2.2734, 2.3363],\n",
      "        [2.9565, 2.6743],\n",
      "        [2.6506, 2.8176],\n",
      "        [2.5264, 2.8395],\n",
      "        [2.9835, 2.5406],\n",
      "        [2.5212, 2.2445],\n",
      "        [2.9250, 2.4783],\n",
      "        [2.7394, 2.7695],\n",
      "        [2.5034, 2.4099],\n",
      "        [2.7119, 2.5837],\n",
      "        [2.4538, 2.5917],\n",
      "        [2.3711, 2.3836],\n",
      "        [2.5248, 2.1658],\n",
      "        [3.0829, 2.6694],\n",
      "        [2.6841, 2.4929],\n",
      "        [2.6626, 2.8787],\n",
      "        [2.5541, 2.7506],\n",
      "        [2.6670, 2.4256],\n",
      "        [2.8711, 2.4226],\n",
      "        [2.3294, 2.8131],\n",
      "        [2.6961, 2.2951],\n",
      "        [2.9767, 2.2325],\n",
      "        [2.8045, 2.1744],\n",
      "        [2.3601, 2.3537],\n",
      "        [3.1203, 2.9636],\n",
      "        [2.5591, 2.2179],\n",
      "        [2.8504, 2.1990],\n",
      "        [2.6585, 2.4872],\n",
      "        [2.6860, 2.3414],\n",
      "        [2.8987, 2.6793],\n",
      "        [2.4391, 2.9950],\n",
      "        [2.4632, 2.6340],\n",
      "        [2.4179, 2.3424],\n",
      "        [2.5392, 2.3288],\n",
      "        [2.9212, 2.8146],\n",
      "        [2.4330, 2.3809],\n",
      "        [2.3596, 2.0263],\n",
      "        [2.4651, 2.4737],\n",
      "        [2.6320, 2.5932],\n",
      "        [2.6230, 2.4570],\n",
      "        [2.6817, 2.1002],\n",
      "        [2.4402, 2.3085],\n",
      "        [3.3096, 2.7247],\n",
      "        [2.6787, 2.4093]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5859, 2.2592],\n",
      "        [2.1103, 2.4998],\n",
      "        [2.5447, 2.8999],\n",
      "        [2.7582, 2.5163],\n",
      "        [2.5963, 2.5694],\n",
      "        [2.5037, 2.6964],\n",
      "        [2.6250, 2.5977],\n",
      "        [2.4504, 1.9095],\n",
      "        [2.6309, 2.4281],\n",
      "        [3.0097, 2.3960],\n",
      "        [2.2123, 2.8925],\n",
      "        [2.2637, 2.7752],\n",
      "        [2.6361, 2.5398],\n",
      "        [2.8523, 2.6115],\n",
      "        [2.3062, 2.4665],\n",
      "        [2.2904, 2.7303],\n",
      "        [2.4172, 2.4899],\n",
      "        [3.0007, 2.5510],\n",
      "        [2.6310, 2.7322],\n",
      "        [3.0624, 2.3314],\n",
      "        [2.5464, 3.0637],\n",
      "        [2.3889, 2.5450],\n",
      "        [2.9332, 2.5458],\n",
      "        [2.6609, 2.7240],\n",
      "        [2.7894, 2.3760],\n",
      "        [2.6997, 2.5981],\n",
      "        [1.9850, 2.7924],\n",
      "        [2.1756, 2.6367],\n",
      "        [2.5364, 2.2337],\n",
      "        [2.2503, 2.4129],\n",
      "        [1.9000, 2.6977],\n",
      "        [2.7155, 2.8208],\n",
      "        [2.8336, 2.4709],\n",
      "        [2.1756, 2.5065],\n",
      "        [2.5519, 2.1201],\n",
      "        [2.3883, 2.5196],\n",
      "        [2.5025, 3.0770],\n",
      "        [2.7097, 2.4662],\n",
      "        [2.4053, 2.8208],\n",
      "        [2.2875, 2.9867],\n",
      "        [2.0406, 2.2847],\n",
      "        [2.6021, 2.9888],\n",
      "        [2.8513, 2.4046],\n",
      "        [2.7639, 2.7467],\n",
      "        [2.5749, 2.5528],\n",
      "        [2.6814, 2.3815],\n",
      "        [2.4062, 2.2939],\n",
      "        [2.4181, 2.5840],\n",
      "        [3.0503, 2.1124],\n",
      "        [2.4632, 2.7162],\n",
      "        [2.7361, 3.1867],\n",
      "        [2.7050, 2.7033],\n",
      "        [2.5104, 2.7969],\n",
      "        [2.6758, 2.3917],\n",
      "        [2.3254, 2.6446],\n",
      "        [2.6453, 2.2414],\n",
      "        [2.3504, 2.1936],\n",
      "        [2.0013, 2.4833],\n",
      "        [2.6170, 2.8140],\n",
      "        [2.2958, 2.3817],\n",
      "        [2.2466, 2.3564],\n",
      "        [2.7711, 2.3770],\n",
      "        [2.5347, 2.6794],\n",
      "        [2.5108, 2.8214],\n",
      "        [2.7128, 2.2420],\n",
      "        [2.3355, 2.2148],\n",
      "        [2.0825, 2.7728],\n",
      "        [2.6306, 2.0499],\n",
      "        [2.6839, 2.5432],\n",
      "        [2.8314, 2.2606],\n",
      "        [2.2866, 2.7999],\n",
      "        [2.9911, 2.5449],\n",
      "        [2.2937, 2.8789],\n",
      "        [2.6692, 2.7034],\n",
      "        [2.2435, 2.4057],\n",
      "        [2.7600, 2.6282],\n",
      "        [2.8887, 3.0784],\n",
      "        [2.5753, 2.7090],\n",
      "        [2.3693, 2.2077],\n",
      "        [2.5234, 2.7987],\n",
      "        [2.3594, 2.4215],\n",
      "        [2.6457, 2.5766],\n",
      "        [2.5225, 2.6024],\n",
      "        [2.4264, 2.8134],\n",
      "        [2.7663, 2.5537],\n",
      "        [2.6711, 2.3391],\n",
      "        [2.3219, 2.5733],\n",
      "        [2.4936, 2.5457],\n",
      "        [2.9452, 2.5091],\n",
      "        [2.7701, 2.5893],\n",
      "        [2.6718, 2.5240],\n",
      "        [2.3416, 2.7960],\n",
      "        [2.6057, 2.4567],\n",
      "        [2.7873, 2.5359],\n",
      "        [2.8784, 2.3658],\n",
      "        [1.8979, 2.9305],\n",
      "        [2.7925, 2.6119],\n",
      "        [2.3775, 2.3203],\n",
      "        [2.6223, 2.6225],\n",
      "        [2.7215, 2.1438]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7401, 2.3890],\n",
      "        [2.4207, 2.6015],\n",
      "        [2.5034, 2.5107],\n",
      "        [2.4189, 2.3500],\n",
      "        [2.7025, 2.4694],\n",
      "        [2.1490, 2.7189],\n",
      "        [2.4764, 2.4376],\n",
      "        [2.9603, 2.1276],\n",
      "        [2.4938, 2.4446],\n",
      "        [2.6873, 2.0768],\n",
      "        [2.5994, 2.2966],\n",
      "        [2.6483, 2.2950],\n",
      "        [2.4672, 2.5763],\n",
      "        [2.4206, 2.3367],\n",
      "        [2.5241, 2.8216],\n",
      "        [2.6480, 2.7460],\n",
      "        [2.7387, 2.3735],\n",
      "        [2.4053, 2.5493],\n",
      "        [2.3106, 2.5914],\n",
      "        [2.5980, 2.4414],\n",
      "        [2.5812, 2.3871],\n",
      "        [2.5136, 2.1369],\n",
      "        [2.3317, 2.2666],\n",
      "        [2.7014, 2.6091],\n",
      "        [2.8582, 2.3055],\n",
      "        [2.8521, 2.4267],\n",
      "        [2.6284, 2.2671],\n",
      "        [2.2290, 2.7334],\n",
      "        [2.4698, 2.6291],\n",
      "        [2.8160, 2.6600],\n",
      "        [2.7341, 2.5481],\n",
      "        [2.6877, 2.9016],\n",
      "        [2.5708, 2.5284],\n",
      "        [2.6235, 1.8867],\n",
      "        [2.7613, 2.6423],\n",
      "        [2.5707, 2.4887],\n",
      "        [2.8439, 2.8979],\n",
      "        [2.7079, 2.3375],\n",
      "        [2.4074, 2.8109],\n",
      "        [2.2753, 1.8568],\n",
      "        [2.5628, 2.7233],\n",
      "        [2.4929, 2.5195],\n",
      "        [2.6996, 2.7170],\n",
      "        [2.4575, 2.6177],\n",
      "        [2.3369, 2.6685],\n",
      "        [2.5129, 2.4781],\n",
      "        [2.5314, 2.3288],\n",
      "        [2.5474, 2.5910],\n",
      "        [2.4810, 2.6604],\n",
      "        [2.4000, 2.8570],\n",
      "        [2.5213, 2.5496],\n",
      "        [2.4477, 2.5885],\n",
      "        [2.5736, 2.2989],\n",
      "        [2.4909, 2.7383],\n",
      "        [2.9832, 2.7651],\n",
      "        [2.5533, 2.4743],\n",
      "        [2.9483, 2.5290],\n",
      "        [3.0063, 2.5685],\n",
      "        [2.8232, 2.6030],\n",
      "        [2.6360, 2.5414],\n",
      "        [2.3620, 3.0260],\n",
      "        [2.9895, 2.7313],\n",
      "        [2.5055, 2.2441],\n",
      "        [2.8302, 2.3650],\n",
      "        [3.0423, 3.1972],\n",
      "        [2.2577, 2.6645],\n",
      "        [2.5876, 2.9062],\n",
      "        [2.5298, 2.8968],\n",
      "        [2.9152, 2.4871],\n",
      "        [2.7789, 2.6933],\n",
      "        [2.3922, 2.6129],\n",
      "        [2.4180, 2.2144],\n",
      "        [2.4456, 2.6157],\n",
      "        [2.5567, 2.6654],\n",
      "        [2.4996, 2.3433],\n",
      "        [2.5393, 3.0230],\n",
      "        [2.6514, 2.3307],\n",
      "        [2.8451, 2.1844],\n",
      "        [2.1614, 2.2269],\n",
      "        [2.3728, 2.1789],\n",
      "        [2.4700, 2.8564],\n",
      "        [2.6023, 3.0809],\n",
      "        [2.3942, 2.6229],\n",
      "        [2.3317, 2.5960],\n",
      "        [2.8683, 1.7575],\n",
      "        [2.8709, 2.4630],\n",
      "        [2.2490, 2.5910],\n",
      "        [2.3165, 2.2064],\n",
      "        [1.8920, 2.9847],\n",
      "        [2.2851, 2.4460],\n",
      "        [2.2748, 2.5905],\n",
      "        [2.4778, 2.4060],\n",
      "        [2.5180, 2.2092],\n",
      "        [2.7649, 2.5615],\n",
      "        [1.9479, 2.9910],\n",
      "        [2.5785, 2.2119],\n",
      "        [2.7556, 2.4165],\n",
      "        [2.2583, 2.6475],\n",
      "        [2.3152, 2.2755],\n",
      "        [2.5145, 2.2704]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 35 complete in 0:01:44.075035; est. finish at 2021-11-29 21:56:18.195863\n",
      "Validation: 0.472 train | 0.518 dev\n",
      "### Epoch: 36 ###\n",
      "y:  tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5407, 2.0808],\n",
      "        [2.6410, 2.4703],\n",
      "        [2.3181, 2.8884],\n",
      "        [2.5178, 2.4639],\n",
      "        [2.4901, 2.7915],\n",
      "        [2.5802, 2.9025],\n",
      "        [2.2290, 2.6858],\n",
      "        [2.0611, 2.7080],\n",
      "        [2.5464, 2.1506],\n",
      "        [2.5161, 2.0452],\n",
      "        [2.2580, 2.7514],\n",
      "        [2.2009, 2.1799],\n",
      "        [3.0356, 2.6437],\n",
      "        [2.3138, 2.5309],\n",
      "        [2.3638, 2.7377],\n",
      "        [2.7347, 2.7241],\n",
      "        [2.0594, 2.6316],\n",
      "        [2.2998, 2.5255],\n",
      "        [2.6980, 3.0613],\n",
      "        [2.7268, 2.2951],\n",
      "        [2.6432, 2.7333],\n",
      "        [2.2971, 2.0996],\n",
      "        [3.0102, 2.8543],\n",
      "        [2.2054, 2.7332],\n",
      "        [2.3923, 2.2605],\n",
      "        [2.9208, 2.4896],\n",
      "        [2.0955, 2.9809],\n",
      "        [2.1282, 2.8261],\n",
      "        [3.0693, 2.7123],\n",
      "        [2.8969, 2.3950],\n",
      "        [2.3978, 2.4947],\n",
      "        [2.4135, 2.2767],\n",
      "        [2.0463, 2.4314],\n",
      "        [2.5089, 2.3203],\n",
      "        [2.5484, 2.8007],\n",
      "        [2.7750, 2.3065],\n",
      "        [2.5770, 2.1876],\n",
      "        [2.4807, 2.6304],\n",
      "        [2.4792, 2.4308],\n",
      "        [2.4831, 2.5079],\n",
      "        [2.1553, 2.3753],\n",
      "        [2.8668, 2.5700],\n",
      "        [2.4652, 2.8959],\n",
      "        [2.5301, 2.6541],\n",
      "        [2.5799, 3.0354],\n",
      "        [2.9537, 2.7271],\n",
      "        [2.5977, 2.8178],\n",
      "        [2.3611, 2.8335],\n",
      "        [2.7415, 2.5428],\n",
      "        [2.8243, 3.1974],\n",
      "        [2.6046, 2.3266],\n",
      "        [2.6227, 2.5413],\n",
      "        [2.3753, 2.4305],\n",
      "        [2.3701, 2.5790],\n",
      "        [2.6754, 2.2576],\n",
      "        [2.4926, 2.7701],\n",
      "        [2.6049, 2.4841],\n",
      "        [2.3762, 2.6621],\n",
      "        [2.7091, 2.9235],\n",
      "        [2.4960, 2.4397],\n",
      "        [2.5709, 2.9277],\n",
      "        [2.6280, 2.3696],\n",
      "        [2.4901, 2.8986],\n",
      "        [2.6790, 2.4412],\n",
      "        [2.5086, 2.6669],\n",
      "        [2.5405, 2.3881],\n",
      "        [2.3339, 2.3589],\n",
      "        [2.3254, 3.0647],\n",
      "        [2.5143, 2.9120],\n",
      "        [2.7950, 2.3574],\n",
      "        [2.5765, 2.3517],\n",
      "        [2.2978, 2.4950],\n",
      "        [2.8222, 2.8240],\n",
      "        [2.3252, 2.7594],\n",
      "        [2.2178, 2.9809],\n",
      "        [2.4875, 2.5320],\n",
      "        [2.4513, 2.3366],\n",
      "        [2.2829, 2.3538],\n",
      "        [2.5855, 2.5483],\n",
      "        [2.6359, 1.9838],\n",
      "        [2.5338, 2.3346],\n",
      "        [2.6348, 2.7798],\n",
      "        [2.3397, 2.5331],\n",
      "        [2.5755, 2.5892],\n",
      "        [2.8097, 2.5909],\n",
      "        [2.3671, 2.6236],\n",
      "        [2.6429, 2.4280],\n",
      "        [2.5264, 3.2231],\n",
      "        [2.4258, 2.7701],\n",
      "        [2.5398, 2.5285],\n",
      "        [2.4264, 2.4950],\n",
      "        [2.6029, 2.0269],\n",
      "        [2.4428, 2.5239],\n",
      "        [2.5752, 2.3202],\n",
      "        [2.2747, 2.8594],\n",
      "        [2.3928, 2.4248],\n",
      "        [2.8975, 2.2170],\n",
      "        [2.1867, 2.7848],\n",
      "        [2.4948, 2.7095],\n",
      "        [2.6334, 2.6824]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.9101, 2.0649],\n",
      "        [2.6443, 2.7140],\n",
      "        [2.9325, 2.4765],\n",
      "        [2.2629, 2.0492],\n",
      "        [2.7163, 2.3698],\n",
      "        [2.4078, 2.4428],\n",
      "        [2.5772, 2.7334],\n",
      "        [2.3615, 2.8265],\n",
      "        [2.2624, 2.7879],\n",
      "        [2.6903, 2.9387],\n",
      "        [2.5502, 2.5591],\n",
      "        [2.4672, 2.4086],\n",
      "        [2.7804, 2.4392],\n",
      "        [2.6463, 2.2883],\n",
      "        [2.8241, 2.7404],\n",
      "        [2.7617, 2.0613],\n",
      "        [2.7737, 2.7111],\n",
      "        [2.4599, 2.6804],\n",
      "        [2.3513, 2.6589],\n",
      "        [2.6492, 2.3845],\n",
      "        [2.8161, 2.7320],\n",
      "        [2.3599, 2.5498],\n",
      "        [2.9259, 2.6410],\n",
      "        [2.5058, 2.8696],\n",
      "        [2.1931, 2.7025],\n",
      "        [2.7972, 2.4811],\n",
      "        [2.5983, 2.5506],\n",
      "        [1.9488, 2.4845],\n",
      "        [2.5988, 2.8168],\n",
      "        [2.3900, 2.6297],\n",
      "        [2.7838, 2.6964],\n",
      "        [2.3544, 2.4375],\n",
      "        [2.4103, 2.8617],\n",
      "        [2.4302, 1.6820],\n",
      "        [2.7939, 2.5412],\n",
      "        [2.5776, 2.5082],\n",
      "        [2.7016, 2.7051],\n",
      "        [2.5925, 2.4329],\n",
      "        [2.5585, 2.5686],\n",
      "        [2.8733, 2.4766],\n",
      "        [2.8284, 2.3236],\n",
      "        [2.7262, 2.8503],\n",
      "        [2.4654, 2.8286],\n",
      "        [2.3674, 2.4842],\n",
      "        [2.7184, 2.2838],\n",
      "        [2.5803, 2.7248],\n",
      "        [2.4729, 3.0119],\n",
      "        [2.2792, 2.6813],\n",
      "        [2.9043, 2.7541],\n",
      "        [2.5523, 2.4948],\n",
      "        [2.2406, 2.4644],\n",
      "        [2.8351, 2.9296],\n",
      "        [2.3967, 2.1372],\n",
      "        [2.7173, 2.0620],\n",
      "        [2.5590, 2.6675],\n",
      "        [2.4425, 2.2629],\n",
      "        [2.5504, 2.5972],\n",
      "        [2.8563, 2.6220],\n",
      "        [2.3126, 2.7517],\n",
      "        [2.8570, 2.5719],\n",
      "        [2.8310, 2.7740],\n",
      "        [2.6300, 2.5927],\n",
      "        [2.5612, 2.5751],\n",
      "        [2.5881, 2.3164],\n",
      "        [2.5526, 2.3187],\n",
      "        [2.6831, 2.5508],\n",
      "        [2.5292, 2.8662],\n",
      "        [2.5593, 2.5503],\n",
      "        [2.4510, 2.6684],\n",
      "        [2.7248, 3.0179],\n",
      "        [2.0725, 2.5496],\n",
      "        [3.0834, 2.8253],\n",
      "        [2.6171, 2.1147],\n",
      "        [2.6636, 2.5482],\n",
      "        [2.1778, 1.9716],\n",
      "        [2.5434, 3.0977],\n",
      "        [2.7284, 2.2880],\n",
      "        [2.4093, 2.4991],\n",
      "        [2.1995, 2.5270],\n",
      "        [2.6400, 3.0264],\n",
      "        [2.7474, 2.7076],\n",
      "        [2.1976, 2.5935],\n",
      "        [2.3854, 2.6294],\n",
      "        [2.6073, 2.7591],\n",
      "        [2.5585, 2.4579],\n",
      "        [2.6933, 2.2734],\n",
      "        [2.9061, 2.8706],\n",
      "        [2.7283, 2.6092],\n",
      "        [2.7376, 2.9174],\n",
      "        [2.8223, 2.2158],\n",
      "        [2.7450, 2.6626],\n",
      "        [2.4489, 2.8084],\n",
      "        [2.8678, 3.0243],\n",
      "        [2.4632, 2.4139],\n",
      "        [2.3932, 2.3606],\n",
      "        [2.7836, 2.3656],\n",
      "        [2.6413, 2.6992],\n",
      "        [2.8340, 2.3926],\n",
      "        [2.7373, 2.5130],\n",
      "        [2.7464, 2.6380]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7897, 2.3650],\n",
      "        [2.7614, 2.4945],\n",
      "        [2.7025, 2.9960],\n",
      "        [2.7004, 2.4766],\n",
      "        [2.2088, 2.3750],\n",
      "        [2.2029, 2.5050],\n",
      "        [2.5499, 2.5495],\n",
      "        [2.7081, 2.4749],\n",
      "        [2.4612, 2.3584],\n",
      "        [2.5925, 2.4646],\n",
      "        [2.7546, 2.3508],\n",
      "        [2.4929, 2.8664],\n",
      "        [2.7466, 2.7150],\n",
      "        [3.0630, 2.4188],\n",
      "        [2.4113, 2.4983],\n",
      "        [2.5872, 2.7677],\n",
      "        [2.4527, 2.7736],\n",
      "        [2.4407, 2.4946],\n",
      "        [2.6563, 1.9645],\n",
      "        [2.8098, 2.6029],\n",
      "        [2.5057, 2.5251],\n",
      "        [2.2976, 2.4825],\n",
      "        [1.9707, 2.3909],\n",
      "        [2.5469, 2.5866],\n",
      "        [2.5579, 2.7090],\n",
      "        [2.5356, 2.7302],\n",
      "        [2.9525, 2.4008],\n",
      "        [2.9083, 2.0893],\n",
      "        [2.7542, 2.7338],\n",
      "        [2.4172, 2.6272],\n",
      "        [2.3308, 2.5953],\n",
      "        [2.8094, 2.8885],\n",
      "        [2.1228, 2.4213],\n",
      "        [2.8479, 2.3037],\n",
      "        [2.2118, 2.1373],\n",
      "        [2.7390, 2.8848],\n",
      "        [2.2569, 2.1783],\n",
      "        [2.8742, 3.0435],\n",
      "        [2.5160, 2.3602],\n",
      "        [2.8793, 2.5942],\n",
      "        [2.6350, 2.4323],\n",
      "        [2.5676, 2.8028],\n",
      "        [2.8169, 2.5631],\n",
      "        [2.3377, 2.5039],\n",
      "        [2.8593, 2.5125],\n",
      "        [2.1505, 2.1489],\n",
      "        [2.3190, 2.6880],\n",
      "        [3.0540, 2.7494],\n",
      "        [2.9114, 2.6373],\n",
      "        [2.2913, 2.9395],\n",
      "        [2.3750, 2.4392],\n",
      "        [2.6927, 2.5167],\n",
      "        [2.0686, 2.5556],\n",
      "        [2.4057, 2.8096],\n",
      "        [2.6197, 2.6243],\n",
      "        [2.7474, 2.7327],\n",
      "        [2.3075, 2.3542],\n",
      "        [2.3484, 2.3613],\n",
      "        [2.4591, 2.4621],\n",
      "        [2.4037, 2.2829],\n",
      "        [2.4253, 2.6113],\n",
      "        [2.3351, 2.5690],\n",
      "        [2.4803, 2.7080],\n",
      "        [2.3723, 2.3254],\n",
      "        [2.7183, 2.1885],\n",
      "        [2.2968, 2.5912],\n",
      "        [2.4149, 2.4348],\n",
      "        [2.9078, 2.4879],\n",
      "        [2.4418, 2.7826],\n",
      "        [2.5848, 2.0099],\n",
      "        [2.2929, 2.5514],\n",
      "        [2.5872, 2.6914],\n",
      "        [2.3633, 2.3647],\n",
      "        [2.8860, 2.7310],\n",
      "        [2.6008, 2.6826],\n",
      "        [2.4662, 2.8659],\n",
      "        [2.6167, 2.8938],\n",
      "        [2.9388, 1.8895],\n",
      "        [2.5472, 2.5756],\n",
      "        [2.5789, 2.4281],\n",
      "        [2.7085, 2.8946],\n",
      "        [2.4630, 2.6117],\n",
      "        [2.0559, 2.3859],\n",
      "        [1.8669, 3.0523],\n",
      "        [3.2281, 2.7259],\n",
      "        [2.4580, 2.8779],\n",
      "        [2.4235, 2.7729],\n",
      "        [2.5487, 2.4780],\n",
      "        [2.1751, 2.7357],\n",
      "        [2.0839, 2.0355],\n",
      "        [2.2557, 2.3809],\n",
      "        [2.5805, 2.7914],\n",
      "        [2.5537, 2.7739],\n",
      "        [2.1114, 2.1230],\n",
      "        [1.9374, 2.4707],\n",
      "        [3.1309, 2.3074],\n",
      "        [3.0028, 2.3608],\n",
      "        [2.4750, 2.6499],\n",
      "        [2.5300, 2.5925],\n",
      "        [2.2113, 2.3452]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3309, 2.4521],\n",
      "        [2.4011, 2.7463],\n",
      "        [2.0735, 2.8092],\n",
      "        [2.5468, 2.5271],\n",
      "        [2.5063, 2.5380],\n",
      "        [2.2021, 1.9954],\n",
      "        [1.9437, 2.6295],\n",
      "        [3.0496, 2.4290],\n",
      "        [2.5346, 2.6657],\n",
      "        [2.6621, 2.2184],\n",
      "        [2.8990, 2.5151],\n",
      "        [2.8176, 2.4519],\n",
      "        [2.6980, 2.3279],\n",
      "        [2.4072, 2.5012],\n",
      "        [2.5451, 2.6751],\n",
      "        [2.7078, 2.4597],\n",
      "        [2.3797, 3.0046],\n",
      "        [2.0299, 2.3077],\n",
      "        [2.3964, 2.3151],\n",
      "        [2.0044, 2.6733],\n",
      "        [2.7461, 2.1221],\n",
      "        [3.0364, 2.8660],\n",
      "        [2.8238, 2.6001],\n",
      "        [3.0824, 2.2971],\n",
      "        [2.5146, 2.4206],\n",
      "        [2.4713, 2.3419],\n",
      "        [2.2263, 1.9759],\n",
      "        [2.4516, 3.1703],\n",
      "        [2.4738, 2.4959],\n",
      "        [2.5560, 2.8328],\n",
      "        [2.6217, 2.4538],\n",
      "        [2.5906, 2.5573],\n",
      "        [2.3589, 3.0360],\n",
      "        [2.7662, 2.2864],\n",
      "        [2.2929, 2.2628],\n",
      "        [2.6756, 2.7456],\n",
      "        [2.3857, 2.8353],\n",
      "        [2.7838, 1.9976],\n",
      "        [2.5324, 2.3461],\n",
      "        [2.4044, 2.5642],\n",
      "        [2.6627, 2.8610],\n",
      "        [2.5030, 2.5567],\n",
      "        [2.5343, 3.1334],\n",
      "        [2.6173, 2.4866],\n",
      "        [2.5006, 2.9441],\n",
      "        [2.6209, 2.5985],\n",
      "        [2.8079, 2.5688],\n",
      "        [2.6820, 2.9275],\n",
      "        [2.7449, 2.2329],\n",
      "        [2.3417, 2.3559],\n",
      "        [2.4956, 2.7622],\n",
      "        [2.7840, 2.7879],\n",
      "        [2.7758, 2.9506],\n",
      "        [2.3184, 2.4721],\n",
      "        [2.7870, 2.4953],\n",
      "        [2.6178, 3.2826],\n",
      "        [2.2988, 2.4015],\n",
      "        [2.7417, 2.7896],\n",
      "        [2.8328, 2.7998],\n",
      "        [2.5113, 2.9805],\n",
      "        [2.4593, 2.5736],\n",
      "        [2.6101, 2.4420],\n",
      "        [2.7414, 2.7819],\n",
      "        [2.4714, 2.1984],\n",
      "        [2.5388, 2.5126],\n",
      "        [2.3691, 2.2443],\n",
      "        [2.5105, 2.5027],\n",
      "        [2.9950, 2.8563],\n",
      "        [2.1125, 2.5466],\n",
      "        [2.1040, 2.6935],\n",
      "        [2.0296, 2.3847],\n",
      "        [2.5332, 2.4600],\n",
      "        [2.2271, 2.3889],\n",
      "        [2.3891, 2.2224],\n",
      "        [2.8895, 2.2104],\n",
      "        [2.4419, 2.5500],\n",
      "        [2.3021, 2.7505],\n",
      "        [2.8107, 2.5638],\n",
      "        [2.7369, 2.3909],\n",
      "        [2.3563, 2.4500],\n",
      "        [2.9085, 2.8591],\n",
      "        [2.3114, 2.6265],\n",
      "        [2.5877, 2.8326],\n",
      "        [2.7391, 2.5169],\n",
      "        [2.1294, 2.2271],\n",
      "        [3.1072, 2.5213],\n",
      "        [3.1732, 2.9119],\n",
      "        [2.7831, 2.1482],\n",
      "        [2.3552, 2.6694],\n",
      "        [2.3718, 2.6792],\n",
      "        [2.7730, 3.2074],\n",
      "        [2.4721, 2.2942],\n",
      "        [2.7366, 2.7023],\n",
      "        [2.2844, 2.5608],\n",
      "        [2.4398, 2.0876],\n",
      "        [2.7400, 2.7118],\n",
      "        [2.6939, 2.2458],\n",
      "        [2.2522, 2.3532],\n",
      "        [2.2029, 2.8537],\n",
      "        [2.4790, 2.1866]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5522, 2.7043],\n",
      "        [2.4217, 2.5266],\n",
      "        [2.9562, 2.8074],\n",
      "        [2.2548, 2.6149],\n",
      "        [2.8151, 2.8375],\n",
      "        [2.6106, 3.0339],\n",
      "        [2.9891, 2.5507],\n",
      "        [2.5718, 2.7605],\n",
      "        [3.0182, 2.4466],\n",
      "        [2.8244, 2.7647],\n",
      "        [2.5446, 2.6462],\n",
      "        [2.9143, 2.4028],\n",
      "        [2.3937, 2.5375],\n",
      "        [2.1421, 2.6798],\n",
      "        [2.8113, 2.1202],\n",
      "        [2.7228, 2.7670],\n",
      "        [2.8396, 2.4480],\n",
      "        [2.6006, 2.7357],\n",
      "        [2.3092, 2.7319],\n",
      "        [2.7769, 3.0289],\n",
      "        [2.5672, 2.9804],\n",
      "        [2.5694, 2.4978],\n",
      "        [2.8234, 2.6787],\n",
      "        [2.4093, 2.3901],\n",
      "        [2.1002, 2.8034],\n",
      "        [2.6142, 2.3413],\n",
      "        [2.3133, 2.5064],\n",
      "        [2.4702, 2.8396],\n",
      "        [2.5973, 2.9082],\n",
      "        [2.3848, 2.7859],\n",
      "        [2.1784, 2.4205],\n",
      "        [2.6494, 2.5149],\n",
      "        [2.5344, 2.7115],\n",
      "        [2.6321, 2.9551],\n",
      "        [2.3638, 2.7013],\n",
      "        [2.4568, 2.9294],\n",
      "        [2.6736, 2.5906],\n",
      "        [2.6794, 2.5970],\n",
      "        [2.4609, 2.5727],\n",
      "        [2.2903, 2.3337],\n",
      "        [2.2116, 2.4766],\n",
      "        [2.2827, 2.3160],\n",
      "        [2.0937, 2.0632],\n",
      "        [1.8837, 2.5286],\n",
      "        [2.4641, 2.4045],\n",
      "        [2.8375, 2.8847],\n",
      "        [2.8084, 2.5662],\n",
      "        [2.5742, 2.8326],\n",
      "        [2.4915, 2.2465],\n",
      "        [2.8063, 2.8022],\n",
      "        [2.4681, 2.9563],\n",
      "        [2.1083, 2.3207],\n",
      "        [2.3664, 2.6301],\n",
      "        [2.6382, 2.6635],\n",
      "        [2.2344, 2.4277],\n",
      "        [2.2486, 2.5743],\n",
      "        [2.1505, 3.1364],\n",
      "        [2.7247, 2.6354],\n",
      "        [2.9078, 2.6520],\n",
      "        [2.2620, 2.7742],\n",
      "        [2.7725, 2.8739],\n",
      "        [2.2445, 2.5135],\n",
      "        [2.8689, 2.0992],\n",
      "        [2.5686, 2.2161],\n",
      "        [2.7094, 2.5178],\n",
      "        [2.8745, 2.7406],\n",
      "        [2.6874, 2.7547],\n",
      "        [2.7251, 3.0876],\n",
      "        [2.5635, 2.6978],\n",
      "        [2.5935, 2.3580],\n",
      "        [2.5181, 2.6490],\n",
      "        [2.6826, 2.6129],\n",
      "        [2.1521, 2.0499],\n",
      "        [2.8623, 2.5503],\n",
      "        [2.7567, 3.1474],\n",
      "        [2.3149, 2.6249],\n",
      "        [2.8681, 2.5795],\n",
      "        [2.7473, 2.7113],\n",
      "        [2.4018, 2.0211],\n",
      "        [2.7581, 2.1031],\n",
      "        [2.1105, 2.5256],\n",
      "        [1.7586, 2.2249],\n",
      "        [2.8354, 2.7483],\n",
      "        [2.9233, 2.4882],\n",
      "        [2.4927, 2.4953],\n",
      "        [2.8191, 2.4995],\n",
      "        [2.4256, 2.8320],\n",
      "        [2.5970, 2.1306],\n",
      "        [2.5292, 2.3241],\n",
      "        [2.8054, 2.8574],\n",
      "        [2.8485, 2.9056],\n",
      "        [2.7895, 2.6013],\n",
      "        [2.4683, 2.2611],\n",
      "        [2.7168, 2.3828],\n",
      "        [2.7820, 2.0026],\n",
      "        [2.7112, 2.5915],\n",
      "        [2.1614, 2.5067],\n",
      "        [2.7739, 2.7509],\n",
      "        [2.8884, 2.5003],\n",
      "        [2.3513, 2.9763]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 40 complete in 0:01:59.045615; est. finish at 2021-11-29 21:56:18.452663\n",
      "Validation: 0.53 train | 0.504 dev\n",
      "### Epoch: 41 ###\n",
      "y:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7155, 2.7788],\n",
      "        [2.6123, 2.3206],\n",
      "        [2.2334, 2.3083],\n",
      "        [2.4805, 2.3719],\n",
      "        [2.5757, 2.0743],\n",
      "        [2.6230, 2.6147],\n",
      "        [2.8989, 2.6912],\n",
      "        [2.5167, 2.4843],\n",
      "        [2.5357, 2.4210],\n",
      "        [2.7214, 2.3236],\n",
      "        [3.0158, 2.8839],\n",
      "        [2.5489, 2.5698],\n",
      "        [2.3436, 2.1481],\n",
      "        [2.2393, 2.9956],\n",
      "        [2.5799, 2.5549],\n",
      "        [2.9356, 2.4131],\n",
      "        [2.5193, 2.5763],\n",
      "        [2.7468, 2.3687],\n",
      "        [2.5078, 2.7351],\n",
      "        [2.3667, 2.2560],\n",
      "        [2.2590, 2.0759],\n",
      "        [2.8924, 2.2374],\n",
      "        [2.6703, 2.5186],\n",
      "        [2.7427, 2.5281],\n",
      "        [2.4920, 2.2382],\n",
      "        [2.6148, 2.5278],\n",
      "        [2.4034, 2.2607],\n",
      "        [2.5261, 2.6710],\n",
      "        [2.7194, 2.6419],\n",
      "        [3.0465, 2.7863],\n",
      "        [2.5465, 2.3330],\n",
      "        [2.5417, 2.5904],\n",
      "        [2.3278, 3.1572],\n",
      "        [2.1808, 2.9540],\n",
      "        [2.3654, 2.5666],\n",
      "        [2.9166, 2.1795],\n",
      "        [2.2909, 2.4071],\n",
      "        [2.8784, 2.2924],\n",
      "        [2.4063, 2.8009],\n",
      "        [2.5143, 2.5751],\n",
      "        [2.7557, 2.4599],\n",
      "        [2.8390, 2.4768],\n",
      "        [2.5826, 2.5323],\n",
      "        [2.6398, 2.0762],\n",
      "        [2.6431, 2.5616],\n",
      "        [2.8695, 2.7953],\n",
      "        [2.2747, 2.4036],\n",
      "        [2.6887, 2.7937],\n",
      "        [2.7557, 3.0195],\n",
      "        [2.7650, 2.5004],\n",
      "        [2.3778, 2.2379],\n",
      "        [2.3697, 2.6089],\n",
      "        [2.2654, 2.0387],\n",
      "        [2.5180, 2.2871],\n",
      "        [2.6432, 2.2565],\n",
      "        [2.8906, 2.4293],\n",
      "        [2.4171, 2.2433],\n",
      "        [2.2200, 2.5483],\n",
      "        [2.5919, 2.3096],\n",
      "        [2.5988, 2.4369],\n",
      "        [2.8656, 3.1455],\n",
      "        [2.0994, 2.8010],\n",
      "        [2.3596, 2.5367],\n",
      "        [2.8224, 2.8189],\n",
      "        [2.4576, 2.4421],\n",
      "        [2.3103, 2.0499],\n",
      "        [2.7992, 2.7720],\n",
      "        [2.3757, 2.3040],\n",
      "        [2.4852, 2.4527],\n",
      "        [2.6768, 2.9260],\n",
      "        [2.6327, 2.7324],\n",
      "        [2.2375, 2.5213],\n",
      "        [2.6704, 2.5356],\n",
      "        [2.3985, 1.9286],\n",
      "        [2.7103, 2.3059],\n",
      "        [2.8114, 2.5931],\n",
      "        [2.5097, 2.1925],\n",
      "        [2.5213, 2.6052],\n",
      "        [2.6134, 2.7765],\n",
      "        [2.6477, 3.1418],\n",
      "        [2.2472, 2.4614],\n",
      "        [2.5811, 2.6434],\n",
      "        [2.1637, 2.3189],\n",
      "        [2.6231, 2.6018],\n",
      "        [2.2650, 2.7562],\n",
      "        [2.7013, 2.5321],\n",
      "        [2.6563, 2.6735],\n",
      "        [2.3437, 2.2219],\n",
      "        [2.6235, 2.8099],\n",
      "        [2.3510, 2.9896],\n",
      "        [2.3510, 2.1387],\n",
      "        [2.1975, 2.6981],\n",
      "        [2.5659, 2.3750],\n",
      "        [2.3826, 3.1065],\n",
      "        [1.9401, 2.8707],\n",
      "        [2.2734, 2.2460],\n",
      "        [2.9720, 2.7984],\n",
      "        [2.4792, 2.7896],\n",
      "        [2.8682, 2.5241],\n",
      "        [2.5404, 2.7474]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.0360, 2.7811],\n",
      "        [3.2681, 2.3527],\n",
      "        [2.8152, 2.4888],\n",
      "        [2.3552, 2.5191],\n",
      "        [2.8385, 2.8432],\n",
      "        [2.4693, 2.6709],\n",
      "        [2.7720, 2.7249],\n",
      "        [2.5109, 2.4205],\n",
      "        [2.7152, 2.4845],\n",
      "        [2.4741, 2.8194],\n",
      "        [2.4289, 2.3013],\n",
      "        [2.2929, 2.4855],\n",
      "        [2.6414, 2.4881],\n",
      "        [2.2430, 2.2928],\n",
      "        [2.8980, 2.3443],\n",
      "        [2.4849, 2.9596],\n",
      "        [2.9171, 2.7408],\n",
      "        [2.1592, 2.2988],\n",
      "        [2.6125, 2.6811],\n",
      "        [2.6284, 1.9698],\n",
      "        [3.2102, 2.8729],\n",
      "        [2.7355, 2.7180],\n",
      "        [2.5970, 2.3960],\n",
      "        [2.7771, 2.6209],\n",
      "        [3.0059, 2.4423],\n",
      "        [2.0307, 2.4815],\n",
      "        [2.5925, 2.4561],\n",
      "        [2.2662, 2.5085],\n",
      "        [2.9000, 2.1817],\n",
      "        [2.5471, 2.4273],\n",
      "        [2.4028, 2.5584],\n",
      "        [2.9800, 2.1653],\n",
      "        [2.4586, 2.6408],\n",
      "        [2.2639, 2.8967],\n",
      "        [2.8394, 2.3645],\n",
      "        [2.4892, 2.7519],\n",
      "        [2.5119, 2.7620],\n",
      "        [2.5868, 2.4167],\n",
      "        [2.8858, 2.7571],\n",
      "        [2.7370, 2.4672],\n",
      "        [2.7370, 2.3932],\n",
      "        [2.3153, 2.5978],\n",
      "        [2.3115, 2.2132],\n",
      "        [2.4793, 2.6198],\n",
      "        [2.5958, 2.8349],\n",
      "        [2.5890, 2.4428],\n",
      "        [2.5890, 2.4583],\n",
      "        [2.1484, 2.8602],\n",
      "        [2.8808, 2.2310],\n",
      "        [2.5917, 2.9051],\n",
      "        [2.6595, 2.3772],\n",
      "        [1.7466, 2.3315],\n",
      "        [2.6260, 2.5185],\n",
      "        [2.5328, 2.5675],\n",
      "        [2.1020, 2.7232],\n",
      "        [2.5027, 2.4966],\n",
      "        [2.5163, 2.2061],\n",
      "        [2.1183, 2.7229],\n",
      "        [2.3153, 2.7926],\n",
      "        [2.3627, 2.6210],\n",
      "        [2.2333, 2.4177],\n",
      "        [2.5591, 2.6509],\n",
      "        [2.5367, 2.2966],\n",
      "        [2.5970, 2.3007],\n",
      "        [1.9613, 2.6891],\n",
      "        [2.2357, 3.0794],\n",
      "        [2.7890, 2.7342],\n",
      "        [2.6790, 3.1658],\n",
      "        [2.6291, 2.3821],\n",
      "        [2.7369, 2.6271],\n",
      "        [2.5929, 2.2385],\n",
      "        [2.2759, 2.4922],\n",
      "        [2.7623, 1.9808],\n",
      "        [2.5105, 2.6568],\n",
      "        [2.7379, 2.9590],\n",
      "        [2.3913, 2.5902],\n",
      "        [2.4313, 2.5503],\n",
      "        [1.9392, 2.2641],\n",
      "        [3.0417, 2.7594],\n",
      "        [2.3584, 2.7986],\n",
      "        [2.3312, 2.7425],\n",
      "        [2.7081, 2.6164],\n",
      "        [2.2571, 2.8493],\n",
      "        [2.4439, 2.7634],\n",
      "        [2.5470, 2.3011],\n",
      "        [2.7932, 2.4752],\n",
      "        [2.6736, 2.0546],\n",
      "        [2.7743, 2.3012],\n",
      "        [2.4308, 2.1798],\n",
      "        [2.3699, 2.2990],\n",
      "        [2.6380, 2.3492],\n",
      "        [2.4810, 3.1879],\n",
      "        [2.3313, 3.0669],\n",
      "        [2.5483, 2.8023],\n",
      "        [2.6530, 2.9860],\n",
      "        [2.1336, 2.1450],\n",
      "        [2.6981, 2.5737],\n",
      "        [2.4967, 2.5805],\n",
      "        [2.3813, 2.7215],\n",
      "        [2.7308, 2.1231]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7580, 2.5165],\n",
      "        [2.6093, 2.6435],\n",
      "        [2.8826, 2.5341],\n",
      "        [2.5556, 2.9248],\n",
      "        [2.7742, 2.4775],\n",
      "        [2.3775, 2.3896],\n",
      "        [2.5266, 2.6415],\n",
      "        [2.3607, 2.5993],\n",
      "        [2.7766, 2.8780],\n",
      "        [2.8184, 3.3129],\n",
      "        [2.2288, 2.6111],\n",
      "        [2.4090, 2.6624],\n",
      "        [2.9093, 2.3281],\n",
      "        [2.6714, 2.7963],\n",
      "        [2.4843, 2.5727],\n",
      "        [2.7166, 2.8155],\n",
      "        [2.1321, 2.4077],\n",
      "        [2.7257, 2.6910],\n",
      "        [2.9985, 3.1908],\n",
      "        [1.9503, 2.9446],\n",
      "        [2.8029, 2.5385],\n",
      "        [2.2374, 2.2603],\n",
      "        [2.4494, 2.7441],\n",
      "        [2.2055, 2.6283],\n",
      "        [2.5423, 2.7789],\n",
      "        [2.6159, 2.6241],\n",
      "        [2.6986, 2.3768],\n",
      "        [2.6379, 2.3119],\n",
      "        [2.7722, 2.4916],\n",
      "        [3.1139, 2.5477],\n",
      "        [2.4590, 2.3818],\n",
      "        [2.5418, 2.5046],\n",
      "        [2.6151, 2.6561],\n",
      "        [2.8097, 1.9733],\n",
      "        [2.6082, 2.4663],\n",
      "        [2.0707, 2.5925],\n",
      "        [2.7309, 2.7436],\n",
      "        [2.2748, 2.1922],\n",
      "        [2.2980, 2.7374],\n",
      "        [2.4763, 2.7786],\n",
      "        [2.0523, 2.4978],\n",
      "        [2.3820, 2.5710],\n",
      "        [2.6539, 2.0906],\n",
      "        [2.4356, 1.9721],\n",
      "        [2.5374, 2.4667],\n",
      "        [2.8271, 2.5649],\n",
      "        [2.3598, 2.6215],\n",
      "        [2.9698, 2.7793],\n",
      "        [2.2955, 2.5337],\n",
      "        [2.5903, 2.6283],\n",
      "        [2.3066, 2.3252],\n",
      "        [2.4402, 2.6258],\n",
      "        [2.9387, 2.3175],\n",
      "        [2.4497, 2.0681],\n",
      "        [2.3520, 3.0039],\n",
      "        [2.3116, 2.5914],\n",
      "        [2.3511, 2.4395],\n",
      "        [2.5802, 2.6063],\n",
      "        [2.9265, 2.5516],\n",
      "        [2.9171, 2.4399],\n",
      "        [2.7219, 2.5705],\n",
      "        [2.8967, 2.6705],\n",
      "        [2.1413, 2.9779],\n",
      "        [2.4944, 2.8276],\n",
      "        [2.9431, 2.2191],\n",
      "        [2.7256, 2.3711],\n",
      "        [2.8155, 2.7827],\n",
      "        [2.6869, 2.3197],\n",
      "        [2.1977, 2.0360],\n",
      "        [2.3381, 2.6529],\n",
      "        [2.5843, 2.8079],\n",
      "        [2.0355, 2.4494],\n",
      "        [2.3654, 2.7423],\n",
      "        [2.6229, 2.7924],\n",
      "        [3.0808, 2.4665],\n",
      "        [2.4130, 2.4052],\n",
      "        [2.6849, 2.7866],\n",
      "        [2.2987, 2.4528],\n",
      "        [2.2985, 2.7249],\n",
      "        [2.4027, 2.8096],\n",
      "        [2.0692, 2.8849],\n",
      "        [2.8357, 2.6720],\n",
      "        [2.7391, 2.4761],\n",
      "        [2.7519, 2.0013],\n",
      "        [2.4405, 2.3971],\n",
      "        [2.5018, 2.6211],\n",
      "        [2.4575, 2.8272],\n",
      "        [2.4770, 2.7588],\n",
      "        [2.5098, 2.8864],\n",
      "        [2.8422, 2.6192],\n",
      "        [2.3638, 2.6111],\n",
      "        [2.5963, 2.6076],\n",
      "        [2.9731, 2.6739],\n",
      "        [2.7517, 2.2849],\n",
      "        [2.4942, 2.6239],\n",
      "        [2.2213, 2.4452],\n",
      "        [2.6008, 2.5721],\n",
      "        [2.1501, 2.6347],\n",
      "        [2.4382, 2.4989],\n",
      "        [2.8708, 2.9640]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[3.2024, 2.5311],\n",
      "        [2.9806, 2.4843],\n",
      "        [2.7856, 2.6379],\n",
      "        [2.8248, 2.3490],\n",
      "        [2.3044, 2.8503],\n",
      "        [2.3442, 2.4733],\n",
      "        [2.8701, 2.5069],\n",
      "        [2.6735, 2.4776],\n",
      "        [2.2277, 2.5074],\n",
      "        [2.4408, 2.6155],\n",
      "        [2.4016, 2.6719],\n",
      "        [2.1154, 2.6709],\n",
      "        [2.5345, 2.4714],\n",
      "        [2.9273, 2.5134],\n",
      "        [2.8058, 2.6920],\n",
      "        [3.0533, 2.7200],\n",
      "        [2.6048, 3.1281],\n",
      "        [2.6406, 2.9008],\n",
      "        [2.7768, 2.0713],\n",
      "        [2.3440, 2.9145],\n",
      "        [2.9612, 2.4854],\n",
      "        [2.5047, 2.1814],\n",
      "        [2.7126, 2.1626],\n",
      "        [2.4713, 2.7770],\n",
      "        [2.4724, 2.7010],\n",
      "        [2.3635, 2.8308],\n",
      "        [2.7938, 2.5334],\n",
      "        [2.4690, 2.1906],\n",
      "        [2.7498, 2.6921],\n",
      "        [2.3255, 2.9094],\n",
      "        [2.9468, 2.8678],\n",
      "        [2.5223, 2.6139],\n",
      "        [2.4871, 2.2351],\n",
      "        [2.9131, 2.3839],\n",
      "        [2.2198, 2.5310],\n",
      "        [2.7291, 2.9281],\n",
      "        [2.7941, 2.2052],\n",
      "        [2.4103, 2.8922],\n",
      "        [2.5421, 2.3483],\n",
      "        [2.4537, 2.7932],\n",
      "        [2.4531, 2.4194],\n",
      "        [2.4976, 2.4156],\n",
      "        [2.6403, 2.6816],\n",
      "        [3.0168, 3.0171],\n",
      "        [2.3003, 2.6709],\n",
      "        [2.8686, 2.2703],\n",
      "        [2.4970, 2.1015],\n",
      "        [2.6222, 2.7630],\n",
      "        [2.4223, 2.6855],\n",
      "        [2.2787, 2.1271],\n",
      "        [2.8027, 2.4613],\n",
      "        [2.4550, 2.4883],\n",
      "        [2.6259, 2.1110],\n",
      "        [2.6524, 2.1951],\n",
      "        [2.8896, 2.3660],\n",
      "        [2.3679, 2.5713],\n",
      "        [2.5649, 2.4694],\n",
      "        [2.5279, 2.2098],\n",
      "        [2.3501, 2.9522],\n",
      "        [2.2258, 2.3077],\n",
      "        [2.4796, 2.6660],\n",
      "        [2.6555, 2.4062],\n",
      "        [2.6139, 2.8706],\n",
      "        [2.7189, 2.8702],\n",
      "        [2.6592, 2.6055],\n",
      "        [2.8231, 2.3535],\n",
      "        [2.5837, 3.1089],\n",
      "        [2.0801, 2.6262],\n",
      "        [2.9115, 2.8481],\n",
      "        [2.6954, 2.2134],\n",
      "        [2.9759, 2.1326],\n",
      "        [1.8146, 2.7078],\n",
      "        [2.5308, 2.8183],\n",
      "        [2.6340, 2.1091],\n",
      "        [2.7117, 2.5440],\n",
      "        [2.7859, 2.9759],\n",
      "        [2.8432, 2.3783],\n",
      "        [2.7321, 2.5605],\n",
      "        [2.1721, 2.4900],\n",
      "        [2.6009, 2.2159],\n",
      "        [2.4799, 2.6292],\n",
      "        [2.4210, 2.3711],\n",
      "        [2.4320, 2.9254],\n",
      "        [2.3403, 2.4990],\n",
      "        [2.3937, 2.6547],\n",
      "        [2.4306, 2.1142],\n",
      "        [2.3332, 2.7175],\n",
      "        [3.0238, 2.6495],\n",
      "        [2.3292, 2.3767],\n",
      "        [2.0844, 2.7016],\n",
      "        [2.6308, 2.5306],\n",
      "        [2.6480, 2.6162],\n",
      "        [2.5138, 2.8919],\n",
      "        [2.2216, 2.3396],\n",
      "        [2.4984, 2.3733],\n",
      "        [2.6990, 2.4975],\n",
      "        [2.1552, 2.6474],\n",
      "        [2.5157, 2.8345],\n",
      "        [2.5658, 2.9001],\n",
      "        [2.7389, 2.2814]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.4585, 2.7045],\n",
      "        [2.7399, 2.9743],\n",
      "        [2.6242, 2.7791],\n",
      "        [2.8537, 2.7218],\n",
      "        [2.6911, 2.6708],\n",
      "        [2.5159, 2.6933],\n",
      "        [2.4841, 3.0677],\n",
      "        [2.3178, 2.5822],\n",
      "        [2.9445, 3.2914],\n",
      "        [2.7364, 2.7889],\n",
      "        [2.8860, 2.9057],\n",
      "        [2.3258, 3.0312],\n",
      "        [2.6926, 2.2682],\n",
      "        [2.9602, 2.6181],\n",
      "        [2.2204, 2.4508],\n",
      "        [2.2672, 2.0631],\n",
      "        [2.7276, 2.8737],\n",
      "        [2.4575, 2.3687],\n",
      "        [2.7003, 1.9717],\n",
      "        [2.5004, 2.3140],\n",
      "        [2.5463, 1.8020],\n",
      "        [2.9099, 2.6178],\n",
      "        [2.4572, 2.5407],\n",
      "        [2.9726, 2.1079],\n",
      "        [2.2861, 2.5731],\n",
      "        [2.1884, 2.2434],\n",
      "        [2.2567, 2.4950],\n",
      "        [2.7125, 2.5336],\n",
      "        [2.5873, 2.4734],\n",
      "        [2.4070, 2.7325],\n",
      "        [2.3474, 2.6184],\n",
      "        [2.2805, 2.8164],\n",
      "        [2.8853, 2.6190],\n",
      "        [2.8322, 2.5795],\n",
      "        [2.6683, 2.6962],\n",
      "        [2.1673, 2.4919],\n",
      "        [2.3686, 2.8412],\n",
      "        [2.3156, 2.3802],\n",
      "        [2.7653, 2.1897],\n",
      "        [2.7634, 2.2128],\n",
      "        [2.6187, 2.5926],\n",
      "        [2.4745, 2.5327],\n",
      "        [2.4667, 2.4488],\n",
      "        [2.9507, 2.5551],\n",
      "        [2.2841, 2.8606],\n",
      "        [2.6879, 2.3974],\n",
      "        [2.2985, 2.4241],\n",
      "        [2.2544, 2.3357],\n",
      "        [2.5367, 2.7682],\n",
      "        [2.5062, 2.6100],\n",
      "        [2.6674, 2.6405],\n",
      "        [2.0326, 2.3227],\n",
      "        [2.4888, 2.5813],\n",
      "        [2.4275, 2.1480],\n",
      "        [2.5282, 2.6495],\n",
      "        [2.4038, 2.4776],\n",
      "        [2.6195, 2.7266],\n",
      "        [3.1083, 2.3878],\n",
      "        [2.7859, 2.3712],\n",
      "        [2.2005, 2.1489],\n",
      "        [2.7551, 2.8018],\n",
      "        [2.8670, 2.2908],\n",
      "        [2.7170, 2.6062],\n",
      "        [2.7728, 2.8655],\n",
      "        [2.7370, 2.0688],\n",
      "        [2.5252, 2.7400],\n",
      "        [2.8744, 2.5794],\n",
      "        [2.1595, 1.8501],\n",
      "        [2.5694, 2.4436],\n",
      "        [2.7202, 2.2873],\n",
      "        [2.4128, 2.8949],\n",
      "        [2.1056, 2.6469],\n",
      "        [2.3392, 2.9526],\n",
      "        [2.7035, 2.6643],\n",
      "        [2.4678, 3.0960],\n",
      "        [2.7786, 2.5518],\n",
      "        [2.5083, 2.2715],\n",
      "        [2.9309, 3.0512],\n",
      "        [2.9982, 2.6274],\n",
      "        [2.7472, 2.2885],\n",
      "        [2.2111, 2.3150],\n",
      "        [3.0689, 2.7974],\n",
      "        [2.7517, 2.3870],\n",
      "        [2.5929, 2.7414],\n",
      "        [2.3242, 2.6205],\n",
      "        [2.2940, 2.7531],\n",
      "        [2.4674, 2.2233],\n",
      "        [2.4884, 2.8740],\n",
      "        [2.5027, 2.2391],\n",
      "        [2.3759, 2.4051],\n",
      "        [2.5408, 2.5335],\n",
      "        [2.6860, 2.4623],\n",
      "        [2.7512, 2.5792],\n",
      "        [2.6172, 2.7966],\n",
      "        [2.2070, 2.4187],\n",
      "        [2.6141, 2.5114],\n",
      "        [2.7134, 2.5803],\n",
      "        [2.9784, 2.7061],\n",
      "        [2.3728, 2.8623],\n",
      "        [2.5959, 2.3982]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 45 complete in 0:02:13.119378; est. finish at 2021-11-29 21:56:16.659463\n",
      "Validation: 0.488 train | 0.508 dev\n",
      "### Epoch: 46 ###\n",
      "y:  tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5331, 2.4152],\n",
      "        [2.3594, 2.8024],\n",
      "        [2.6507, 2.5768],\n",
      "        [2.1908, 3.0500],\n",
      "        [2.5671, 2.4538],\n",
      "        [2.6668, 2.7207],\n",
      "        [2.7303, 2.2431],\n",
      "        [2.3218, 2.3569],\n",
      "        [2.3281, 2.2934],\n",
      "        [2.4152, 2.6251],\n",
      "        [2.3366, 2.4617],\n",
      "        [2.3027, 2.5843],\n",
      "        [2.3399, 2.3656],\n",
      "        [2.6658, 2.5771],\n",
      "        [2.1064, 2.5147],\n",
      "        [2.5452, 2.5509],\n",
      "        [2.8057, 2.5894],\n",
      "        [2.6356, 2.3107],\n",
      "        [2.4530, 2.6155],\n",
      "        [2.7849, 2.4153],\n",
      "        [2.4522, 2.8764],\n",
      "        [2.1470, 2.6965],\n",
      "        [2.2432, 2.6770],\n",
      "        [2.5222, 2.9123],\n",
      "        [2.3694, 2.7426],\n",
      "        [2.5919, 2.9159],\n",
      "        [2.5380, 2.3607],\n",
      "        [3.0036, 2.7813],\n",
      "        [2.5518, 2.4041],\n",
      "        [2.2245, 3.0380],\n",
      "        [1.9696, 2.4653],\n",
      "        [2.4051, 2.1970],\n",
      "        [2.4524, 2.4710],\n",
      "        [2.9449, 2.5169],\n",
      "        [1.9498, 2.6463],\n",
      "        [2.8127, 2.6422],\n",
      "        [2.6710, 2.4710],\n",
      "        [2.3949, 2.6687],\n",
      "        [2.6780, 2.6225],\n",
      "        [2.3732, 2.5334],\n",
      "        [2.6370, 2.2826],\n",
      "        [2.8320, 2.2934],\n",
      "        [2.7546, 2.7816],\n",
      "        [2.4153, 2.6602],\n",
      "        [2.1743, 2.5282],\n",
      "        [2.7116, 2.9558],\n",
      "        [2.7505, 2.8650],\n",
      "        [2.0681, 2.0156],\n",
      "        [2.6774, 2.6615],\n",
      "        [2.6122, 2.4703],\n",
      "        [2.3873, 2.9964],\n",
      "        [2.3796, 2.5357],\n",
      "        [3.0849, 2.7234],\n",
      "        [2.5074, 3.1239],\n",
      "        [2.3271, 2.6963],\n",
      "        [3.0681, 2.3798],\n",
      "        [2.5135, 2.9278],\n",
      "        [2.6698, 2.6877],\n",
      "        [2.3102, 2.5683],\n",
      "        [2.1149, 2.7728],\n",
      "        [2.0930, 2.6534],\n",
      "        [2.5990, 1.8639],\n",
      "        [2.6575, 2.5852],\n",
      "        [2.1588, 2.5719],\n",
      "        [2.1947, 3.0033],\n",
      "        [2.5412, 2.5161],\n",
      "        [2.4267, 2.2598],\n",
      "        [2.5998, 2.5455],\n",
      "        [2.3923, 2.6235],\n",
      "        [2.0196, 2.2259],\n",
      "        [2.3433, 2.4348],\n",
      "        [2.2960, 2.7277],\n",
      "        [2.3176, 1.9829],\n",
      "        [2.5891, 2.6942],\n",
      "        [2.4368, 2.4110],\n",
      "        [2.6875, 2.2091],\n",
      "        [3.0419, 2.3548],\n",
      "        [3.0220, 2.7752],\n",
      "        [2.5154, 2.6817],\n",
      "        [3.0762, 2.4450],\n",
      "        [2.6690, 2.4050],\n",
      "        [2.1690, 2.4877],\n",
      "        [2.5547, 2.8514],\n",
      "        [1.9330, 2.5958],\n",
      "        [2.3516, 2.3324],\n",
      "        [2.4892, 3.1019],\n",
      "        [2.7031, 2.5075],\n",
      "        [2.9205, 2.2992],\n",
      "        [2.7324, 2.7636],\n",
      "        [2.3774, 2.7668],\n",
      "        [2.8339, 2.4871],\n",
      "        [2.1980, 2.6535],\n",
      "        [2.4693, 3.0511],\n",
      "        [2.4871, 2.5011],\n",
      "        [2.3894, 2.5216],\n",
      "        [2.3006, 2.6339],\n",
      "        [2.5257, 2.8828],\n",
      "        [2.7917, 2.5120],\n",
      "        [2.7176, 2.7173],\n",
      "        [2.1808, 2.3415]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.4631, 2.5647],\n",
      "        [3.0664, 2.8773],\n",
      "        [2.6000, 2.8211],\n",
      "        [2.1685, 2.2466],\n",
      "        [2.3664, 2.4226],\n",
      "        [3.0557, 2.4752],\n",
      "        [2.3736, 2.3837],\n",
      "        [2.8698, 2.5107],\n",
      "        [2.5532, 3.0484],\n",
      "        [2.2817, 2.2080],\n",
      "        [2.8255, 2.6609],\n",
      "        [2.6531, 3.1458],\n",
      "        [2.9184, 2.6681],\n",
      "        [2.8244, 2.5609],\n",
      "        [2.8820, 2.3655],\n",
      "        [2.6770, 2.3016],\n",
      "        [2.6090, 2.8553],\n",
      "        [2.3870, 2.8645],\n",
      "        [2.9418, 2.5688],\n",
      "        [2.5460, 2.8146],\n",
      "        [2.4704, 2.4754],\n",
      "        [2.4513, 2.4698],\n",
      "        [2.3693, 2.9548],\n",
      "        [2.7404, 2.4703],\n",
      "        [2.8116, 2.3932],\n",
      "        [1.9920, 2.7717],\n",
      "        [2.5162, 2.6451],\n",
      "        [2.4666, 2.5765],\n",
      "        [2.1783, 2.4386],\n",
      "        [2.4396, 2.4522],\n",
      "        [2.8900, 2.9297],\n",
      "        [2.1700, 2.6147],\n",
      "        [2.4558, 3.1226],\n",
      "        [2.4954, 3.1993],\n",
      "        [2.5025, 2.4654],\n",
      "        [2.2992, 2.4917],\n",
      "        [2.8070, 2.8414],\n",
      "        [2.0749, 2.7280],\n",
      "        [2.9430, 2.1910],\n",
      "        [1.9925, 2.3982],\n",
      "        [2.7692, 2.2881],\n",
      "        [2.5138, 2.4409],\n",
      "        [2.9135, 2.8164],\n",
      "        [2.6700, 2.9007],\n",
      "        [2.6309, 2.2027],\n",
      "        [1.8845, 2.1809],\n",
      "        [2.2166, 2.4572],\n",
      "        [2.8366, 2.1182],\n",
      "        [2.9988, 2.7750],\n",
      "        [2.9392, 2.3758],\n",
      "        [1.9129, 2.5659],\n",
      "        [2.8704, 2.6391],\n",
      "        [2.2568, 2.6434],\n",
      "        [2.5785, 2.2933],\n",
      "        [2.5298, 2.4812],\n",
      "        [2.3769, 1.9402],\n",
      "        [2.3986, 2.5151],\n",
      "        [2.7501, 2.8881],\n",
      "        [2.5155, 3.0415],\n",
      "        [2.4073, 2.8778],\n",
      "        [2.5413, 2.2912],\n",
      "        [2.4694, 2.7327],\n",
      "        [2.5580, 2.6158],\n",
      "        [2.7426, 2.5860],\n",
      "        [2.7321, 2.9092],\n",
      "        [2.4606, 2.6546],\n",
      "        [2.8377, 2.7023],\n",
      "        [2.4740, 2.8779],\n",
      "        [2.3577, 2.4721],\n",
      "        [2.4187, 2.8769],\n",
      "        [2.5234, 2.6632],\n",
      "        [2.3722, 2.5186],\n",
      "        [2.9957, 2.3319],\n",
      "        [2.1368, 2.2204],\n",
      "        [2.5440, 2.2130],\n",
      "        [2.9211, 2.5254],\n",
      "        [2.6725, 2.6760],\n",
      "        [2.2299, 2.8064],\n",
      "        [2.3325, 2.3706],\n",
      "        [2.5893, 2.6687],\n",
      "        [3.0739, 2.6995],\n",
      "        [2.1919, 1.9855],\n",
      "        [2.3896, 2.3502],\n",
      "        [2.6620, 2.6074],\n",
      "        [2.8921, 2.2892],\n",
      "        [2.4252, 2.8374],\n",
      "        [2.8371, 2.4044],\n",
      "        [2.4771, 2.5889],\n",
      "        [2.3352, 2.6814],\n",
      "        [2.4053, 2.3477],\n",
      "        [2.6911, 2.8310],\n",
      "        [2.8240, 2.6053],\n",
      "        [2.4977, 2.3927],\n",
      "        [2.6730, 2.4664],\n",
      "        [2.8620, 2.8235],\n",
      "        [2.5646, 3.0149],\n",
      "        [2.7564, 2.5044],\n",
      "        [2.5214, 2.2478],\n",
      "        [2.0492, 2.7813],\n",
      "        [2.6088, 2.5687]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7189, 2.8562],\n",
      "        [2.7911, 2.4464],\n",
      "        [2.5696, 2.2148],\n",
      "        [2.5640, 2.5452],\n",
      "        [2.1082, 2.9974],\n",
      "        [2.4381, 2.7296],\n",
      "        [2.8262, 2.8113],\n",
      "        [2.6651, 2.2379],\n",
      "        [2.6687, 2.7684],\n",
      "        [2.2597, 2.2398],\n",
      "        [2.6822, 2.7699],\n",
      "        [2.4263, 2.5655],\n",
      "        [2.3605, 2.5624],\n",
      "        [2.7082, 2.4639],\n",
      "        [2.5564, 2.1770],\n",
      "        [2.8985, 2.5879],\n",
      "        [2.5516, 2.7782],\n",
      "        [2.3342, 2.6683],\n",
      "        [2.7911, 2.7128],\n",
      "        [2.5097, 2.3212],\n",
      "        [2.4586, 2.6380],\n",
      "        [2.5669, 2.6408],\n",
      "        [2.0233, 2.8613],\n",
      "        [1.9383, 2.8259],\n",
      "        [2.2804, 2.4019],\n",
      "        [2.3563, 2.3945],\n",
      "        [2.4365, 1.9148],\n",
      "        [2.6707, 2.6758],\n",
      "        [2.4926, 2.9577],\n",
      "        [2.8411, 2.5272],\n",
      "        [2.9322, 2.5266],\n",
      "        [2.6225, 2.6024],\n",
      "        [2.9464, 2.9382],\n",
      "        [2.3669, 2.8665],\n",
      "        [2.6086, 2.7870],\n",
      "        [2.4455, 2.6507],\n",
      "        [2.5689, 2.7948],\n",
      "        [2.3497, 2.6134],\n",
      "        [2.7763, 2.4363],\n",
      "        [2.3396, 2.7513],\n",
      "        [2.4255, 2.4570],\n",
      "        [2.9163, 2.8829],\n",
      "        [2.5107, 2.4337],\n",
      "        [2.2202, 2.4951],\n",
      "        [2.3197, 2.3259],\n",
      "        [2.3846, 2.6314],\n",
      "        [2.5011, 2.2787],\n",
      "        [2.6435, 2.3462],\n",
      "        [2.1855, 2.9034],\n",
      "        [2.4809, 2.9718],\n",
      "        [2.7821, 2.5372],\n",
      "        [2.7893, 2.4882],\n",
      "        [2.2057, 2.5373],\n",
      "        [2.8230, 2.5202],\n",
      "        [2.6273, 2.6019],\n",
      "        [2.4246, 2.4207],\n",
      "        [2.5524, 2.7817],\n",
      "        [2.4683, 2.2468],\n",
      "        [2.5155, 2.5177],\n",
      "        [2.4241, 2.7568],\n",
      "        [2.5642, 2.6059],\n",
      "        [2.3909, 2.4533],\n",
      "        [2.5986, 2.8090],\n",
      "        [2.4371, 2.5106],\n",
      "        [3.0008, 2.7029],\n",
      "        [2.6875, 2.4321],\n",
      "        [3.0102, 2.5880],\n",
      "        [2.7396, 2.5567],\n",
      "        [2.5058, 2.4553],\n",
      "        [2.6304, 2.9625],\n",
      "        [2.2387, 2.8228],\n",
      "        [2.9746, 2.7574],\n",
      "        [2.8122, 3.0508],\n",
      "        [2.5114, 2.2262],\n",
      "        [2.8081, 2.4892],\n",
      "        [2.4114, 2.3786],\n",
      "        [3.0281, 3.0458],\n",
      "        [2.9772, 2.8084],\n",
      "        [2.2575, 2.3201],\n",
      "        [2.6253, 2.3637],\n",
      "        [2.5914, 2.6491],\n",
      "        [2.5312, 2.6066],\n",
      "        [2.4214, 2.3367],\n",
      "        [2.7421, 2.6538],\n",
      "        [2.6835, 2.3831],\n",
      "        [2.6229, 2.5072],\n",
      "        [2.4497, 2.5139],\n",
      "        [2.7810, 3.0069],\n",
      "        [2.2468, 2.6372],\n",
      "        [2.6753, 2.6200],\n",
      "        [2.7498, 2.7712],\n",
      "        [2.9367, 2.5418],\n",
      "        [2.6402, 2.2672],\n",
      "        [2.5988, 2.5237],\n",
      "        [2.1441, 2.1583],\n",
      "        [2.5204, 2.5866],\n",
      "        [2.7179, 2.6671],\n",
      "        [2.6734, 2.5251],\n",
      "        [3.3480, 2.3994],\n",
      "        [2.3363, 2.2342]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[3.2452, 2.9057],\n",
      "        [2.2613, 3.0947],\n",
      "        [2.1916, 2.5627],\n",
      "        [2.4272, 2.7881],\n",
      "        [2.8855, 2.8348],\n",
      "        [2.5342, 2.7361],\n",
      "        [2.5157, 2.5345],\n",
      "        [2.2898, 2.5726],\n",
      "        [2.4717, 2.7406],\n",
      "        [2.7320, 2.6351],\n",
      "        [2.5892, 2.3455],\n",
      "        [2.2629, 2.1986],\n",
      "        [2.6648, 2.7991],\n",
      "        [2.7717, 2.4096],\n",
      "        [2.6706, 2.5269],\n",
      "        [3.0231, 2.2549],\n",
      "        [2.1372, 2.5007],\n",
      "        [2.5017, 2.5505],\n",
      "        [1.9105, 2.3562],\n",
      "        [2.5314, 2.6010],\n",
      "        [2.5624, 2.3559],\n",
      "        [2.6976, 2.3264],\n",
      "        [2.5265, 2.4868],\n",
      "        [2.5716, 2.6289],\n",
      "        [2.8511, 2.4701],\n",
      "        [2.4990, 2.1213],\n",
      "        [2.6156, 2.7375],\n",
      "        [2.1615, 2.9675],\n",
      "        [2.5347, 2.1361],\n",
      "        [2.4911, 2.7654],\n",
      "        [2.6292, 2.7060],\n",
      "        [2.3870, 2.4572],\n",
      "        [2.6459, 2.4002],\n",
      "        [2.7097, 2.3682],\n",
      "        [2.5330, 2.9998],\n",
      "        [2.6404, 2.5693],\n",
      "        [2.2599, 2.3193],\n",
      "        [2.4121, 2.4950],\n",
      "        [2.7125, 2.6681],\n",
      "        [2.4183, 2.0780],\n",
      "        [2.7809, 2.9669],\n",
      "        [2.9163, 2.6853],\n",
      "        [2.8676, 2.5526],\n",
      "        [2.6561, 2.7268],\n",
      "        [2.5426, 2.3966],\n",
      "        [2.6539, 2.6153],\n",
      "        [2.5648, 2.8865],\n",
      "        [2.4040, 2.7047],\n",
      "        [2.6341, 2.7250],\n",
      "        [2.9346, 2.3620],\n",
      "        [2.8155, 2.1790],\n",
      "        [2.4460, 2.6521],\n",
      "        [2.6362, 2.7407],\n",
      "        [2.5667, 2.5497],\n",
      "        [2.4536, 2.4251],\n",
      "        [2.6123, 3.1384],\n",
      "        [2.6108, 2.3041],\n",
      "        [2.8694, 2.6548],\n",
      "        [2.6383, 2.2371],\n",
      "        [2.3884, 2.1607],\n",
      "        [2.2147, 2.5194],\n",
      "        [2.5077, 2.6730],\n",
      "        [2.2356, 2.4241],\n",
      "        [2.5802, 2.4898],\n",
      "        [2.5214, 2.4630],\n",
      "        [2.1986, 2.3786],\n",
      "        [2.6423, 2.0810],\n",
      "        [2.8156, 2.5052],\n",
      "        [2.4481, 2.5805],\n",
      "        [2.6357, 2.2045],\n",
      "        [2.3770, 2.8066],\n",
      "        [2.3533, 2.6700],\n",
      "        [2.7136, 2.5147],\n",
      "        [2.6143, 2.5871],\n",
      "        [2.6447, 2.6447],\n",
      "        [2.3087, 2.3065],\n",
      "        [2.5894, 2.6488],\n",
      "        [2.4991, 2.6563],\n",
      "        [2.8806, 2.2273],\n",
      "        [2.8747, 2.4767],\n",
      "        [2.5361, 2.2113],\n",
      "        [2.0824, 2.6367],\n",
      "        [2.8261, 2.7204],\n",
      "        [2.5858, 2.5922],\n",
      "        [2.4871, 3.1530],\n",
      "        [3.1102, 2.8348],\n",
      "        [2.5126, 2.2572],\n",
      "        [2.6756, 3.0776],\n",
      "        [2.6135, 2.8966],\n",
      "        [2.1788, 2.4539],\n",
      "        [3.0559, 2.3816],\n",
      "        [2.3542, 2.6176],\n",
      "        [2.1594, 2.6685],\n",
      "        [2.6704, 2.3964],\n",
      "        [2.5426, 2.7852],\n",
      "        [2.4660, 2.4727],\n",
      "        [2.5659, 2.6245],\n",
      "        [2.4390, 2.7250],\n",
      "        [2.6560, 2.4806],\n",
      "        [2.6035, 3.2155]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.1318, 2.3434],\n",
      "        [2.4661, 2.7223],\n",
      "        [2.8341, 2.7702],\n",
      "        [2.6778, 2.3768],\n",
      "        [2.2918, 2.9087],\n",
      "        [2.6854, 2.4670],\n",
      "        [2.2245, 2.4268],\n",
      "        [2.7518, 3.4374],\n",
      "        [2.5904, 2.4466],\n",
      "        [2.4998, 2.6379],\n",
      "        [2.3516, 2.2207],\n",
      "        [2.2236, 2.6884],\n",
      "        [2.2268, 2.6397],\n",
      "        [3.3020, 2.6337],\n",
      "        [2.5758, 2.7404],\n",
      "        [2.8433, 2.6367],\n",
      "        [2.6967, 2.2025],\n",
      "        [2.4866, 2.6250],\n",
      "        [2.7938, 2.8102],\n",
      "        [2.5553, 2.2395],\n",
      "        [2.5377, 2.2754],\n",
      "        [2.5594, 2.5986],\n",
      "        [2.7784, 2.7503],\n",
      "        [2.5718, 2.8242],\n",
      "        [2.8873, 2.4605],\n",
      "        [2.3282, 2.8075],\n",
      "        [2.7530, 2.5290],\n",
      "        [2.6762, 2.1101],\n",
      "        [2.8337, 2.6843],\n",
      "        [2.6337, 2.5609],\n",
      "        [2.2951, 2.4859],\n",
      "        [2.2991, 2.7207],\n",
      "        [2.4903, 2.4822],\n",
      "        [2.0283, 2.2043],\n",
      "        [2.4777, 2.7461],\n",
      "        [2.7013, 2.6414],\n",
      "        [2.5842, 2.6620],\n",
      "        [2.9634, 2.6686],\n",
      "        [2.8394, 2.6539],\n",
      "        [2.5787, 2.4936],\n",
      "        [2.4131, 2.8850],\n",
      "        [2.5287, 2.6671],\n",
      "        [2.5551, 2.5743],\n",
      "        [2.7066, 2.4826],\n",
      "        [2.5964, 2.5667],\n",
      "        [2.5609, 2.3539],\n",
      "        [2.6899, 2.5490],\n",
      "        [2.7578, 2.1567],\n",
      "        [2.6461, 2.1589],\n",
      "        [2.5916, 2.8451],\n",
      "        [3.0712, 2.4363],\n",
      "        [2.4168, 2.6726],\n",
      "        [3.0447, 2.2971],\n",
      "        [1.7983, 2.5439],\n",
      "        [2.9711, 1.9359],\n",
      "        [2.9627, 2.3884],\n",
      "        [2.6994, 2.5642],\n",
      "        [2.6815, 2.6878],\n",
      "        [2.7174, 2.7948],\n",
      "        [2.2451, 2.3778],\n",
      "        [2.6718, 2.5047],\n",
      "        [2.4309, 2.6586],\n",
      "        [2.7584, 2.8516],\n",
      "        [2.8083, 2.4821],\n",
      "        [2.4888, 2.6395],\n",
      "        [3.2594, 2.5892],\n",
      "        [2.2297, 2.5124],\n",
      "        [2.8777, 2.5520],\n",
      "        [3.0246, 2.5446],\n",
      "        [2.4599, 2.4382],\n",
      "        [2.2852, 2.6446],\n",
      "        [2.8048, 2.2857],\n",
      "        [2.2920, 2.6139],\n",
      "        [2.7845, 2.4675],\n",
      "        [2.4487, 2.8319],\n",
      "        [2.2527, 2.5537],\n",
      "        [2.6654, 2.3995],\n",
      "        [2.4513, 2.6333],\n",
      "        [2.6744, 2.6480],\n",
      "        [1.9771, 2.3756],\n",
      "        [3.0047, 2.4998],\n",
      "        [2.2448, 2.8441],\n",
      "        [2.6717, 2.6430],\n",
      "        [2.5427, 2.7587],\n",
      "        [2.3366, 2.6173],\n",
      "        [2.9596, 2.7239],\n",
      "        [2.2110, 2.5115],\n",
      "        [2.7418, 2.4899],\n",
      "        [2.3753, 2.2232],\n",
      "        [2.3869, 2.1047],\n",
      "        [2.3908, 2.3653],\n",
      "        [2.8510, 2.2592],\n",
      "        [2.5132, 2.7469],\n",
      "        [2.6753, 2.0862],\n",
      "        [2.8045, 2.6257],\n",
      "        [2.5393, 2.8774],\n",
      "        [2.3416, 2.7937],\n",
      "        [2.8791, 2.3393],\n",
      "        [2.5671, 2.2206],\n",
      "        [2.5952, 2.4750]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 50 complete in 0:02:24.294267; est. finish at 2021-11-29 21:56:09.427163\n",
      "Validation: 0.442 train | 0.5 dev\n",
      "### Epoch: 51 ###\n",
      "y:  tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5023, 2.9145],\n",
      "        [2.5063, 2.3631],\n",
      "        [2.9036, 2.4067],\n",
      "        [2.4057, 2.2401],\n",
      "        [2.6515, 2.3882],\n",
      "        [2.9768, 2.5059],\n",
      "        [2.3260, 2.5078],\n",
      "        [2.5812, 2.1534],\n",
      "        [2.2216, 2.6952],\n",
      "        [2.4227, 2.5112],\n",
      "        [2.5534, 2.7334],\n",
      "        [2.4457, 2.4518],\n",
      "        [2.6000, 2.7519],\n",
      "        [1.8961, 2.7349],\n",
      "        [2.7955, 2.6880],\n",
      "        [2.9114, 2.7919],\n",
      "        [2.6746, 2.4717],\n",
      "        [2.8740, 2.0216],\n",
      "        [2.2569, 2.6795],\n",
      "        [2.7169, 2.6022],\n",
      "        [2.4471, 2.3412],\n",
      "        [2.5369, 2.2335],\n",
      "        [2.7849, 2.4343],\n",
      "        [2.8621, 2.9260],\n",
      "        [2.4541, 2.7552],\n",
      "        [2.2946, 2.7306],\n",
      "        [2.6386, 2.9801],\n",
      "        [2.7052, 2.8543],\n",
      "        [1.9253, 2.4929],\n",
      "        [2.4718, 2.4156],\n",
      "        [2.8522, 2.2574],\n",
      "        [2.8066, 2.3580],\n",
      "        [1.9176, 2.5061],\n",
      "        [2.8494, 2.5120],\n",
      "        [2.7108, 2.2182],\n",
      "        [2.6799, 2.5549],\n",
      "        [2.6134, 2.0516],\n",
      "        [2.4590, 2.5590],\n",
      "        [2.6312, 2.3706],\n",
      "        [2.8511, 2.3211],\n",
      "        [2.5600, 2.7935],\n",
      "        [2.3128, 2.9389],\n",
      "        [2.8231, 2.3420],\n",
      "        [2.5783, 2.6050],\n",
      "        [2.6801, 2.4592],\n",
      "        [2.4388, 2.7687],\n",
      "        [2.5460, 2.6582],\n",
      "        [2.5046, 2.4211],\n",
      "        [2.5337, 2.3066],\n",
      "        [2.3774, 2.5851],\n",
      "        [2.5130, 2.8379],\n",
      "        [2.4248, 2.4396],\n",
      "        [3.0147, 2.7269],\n",
      "        [2.7968, 2.7640],\n",
      "        [2.3369, 2.0831],\n",
      "        [2.5032, 2.3671],\n",
      "        [2.7021, 2.5523],\n",
      "        [2.4286, 2.8222],\n",
      "        [2.3905, 3.1960],\n",
      "        [2.4641, 2.1502],\n",
      "        [2.8734, 3.0152],\n",
      "        [2.8528, 2.5226],\n",
      "        [2.1100, 2.5227],\n",
      "        [2.4077, 2.7794],\n",
      "        [2.6624, 2.4589],\n",
      "        [2.5513, 2.4525],\n",
      "        [2.1009, 2.0376],\n",
      "        [2.8536, 2.3251],\n",
      "        [2.3995, 2.2556],\n",
      "        [2.3293, 2.7315],\n",
      "        [2.6010, 2.2546],\n",
      "        [2.7778, 2.4292],\n",
      "        [2.5325, 2.4429],\n",
      "        [3.0036, 2.6197],\n",
      "        [2.4274, 2.9788],\n",
      "        [2.6442, 2.6086],\n",
      "        [2.4782, 2.3203],\n",
      "        [2.2456, 2.8347],\n",
      "        [2.7088, 2.6143],\n",
      "        [2.7366, 2.4911],\n",
      "        [2.3684, 2.7080],\n",
      "        [2.5343, 2.4496],\n",
      "        [2.6046, 2.7495],\n",
      "        [2.4911, 2.3615],\n",
      "        [2.1953, 2.4308],\n",
      "        [2.8995, 2.3595],\n",
      "        [2.7790, 2.4769],\n",
      "        [2.8748, 2.0398],\n",
      "        [2.2642, 2.2292],\n",
      "        [2.6129, 2.6255],\n",
      "        [2.6417, 2.5879],\n",
      "        [2.5097, 2.7116],\n",
      "        [2.6539, 2.5035],\n",
      "        [2.7969, 2.5282],\n",
      "        [2.5975, 2.6037],\n",
      "        [2.5183, 2.5737],\n",
      "        [2.8148, 2.7750],\n",
      "        [2.6263, 2.6806],\n",
      "        [2.5064, 2.4525],\n",
      "        [2.7485, 2.5345]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5817, 2.7110],\n",
      "        [2.6008, 2.4521],\n",
      "        [2.4301, 2.3847],\n",
      "        [2.3831, 2.5230],\n",
      "        [2.3818, 2.1689],\n",
      "        [2.5779, 2.8426],\n",
      "        [2.9973, 2.5728],\n",
      "        [2.5919, 2.0652],\n",
      "        [2.4430, 2.9256],\n",
      "        [2.2040, 2.1759],\n",
      "        [2.4108, 2.5806],\n",
      "        [2.3349, 2.2130],\n",
      "        [2.9157, 2.8173],\n",
      "        [2.8214, 2.3513],\n",
      "        [2.0264, 2.8091],\n",
      "        [2.7372, 2.7508],\n",
      "        [2.4632, 2.9196],\n",
      "        [2.5473, 2.4024],\n",
      "        [2.7898, 2.8611],\n",
      "        [2.3002, 2.8623],\n",
      "        [2.5863, 2.3607],\n",
      "        [2.5745, 2.6674],\n",
      "        [2.7852, 2.4420],\n",
      "        [2.4285, 2.6893],\n",
      "        [2.6272, 3.0771],\n",
      "        [2.6627, 3.0848],\n",
      "        [2.7964, 2.3915],\n",
      "        [2.1397, 2.9035],\n",
      "        [2.0736, 2.2275],\n",
      "        [2.2465, 2.8658],\n",
      "        [2.2602, 2.1200],\n",
      "        [2.3140, 2.2577],\n",
      "        [2.1536, 2.5615],\n",
      "        [2.0611, 2.2762],\n",
      "        [2.3948, 2.3033],\n",
      "        [2.9105, 2.1360],\n",
      "        [2.8608, 2.4034],\n",
      "        [2.6388, 2.5475],\n",
      "        [2.5514, 2.5573],\n",
      "        [2.8872, 2.8969],\n",
      "        [2.8159, 2.2137],\n",
      "        [2.2079, 2.6657],\n",
      "        [2.7151, 2.5848],\n",
      "        [2.6432, 2.1266],\n",
      "        [2.4201, 2.2244],\n",
      "        [2.9220, 2.9318],\n",
      "        [2.2043, 2.4892],\n",
      "        [2.4002, 2.9455],\n",
      "        [2.6000, 2.4607],\n",
      "        [2.6022, 2.7111],\n",
      "        [2.3401, 2.4418],\n",
      "        [2.7195, 2.8696],\n",
      "        [2.4423, 2.4687],\n",
      "        [2.7287, 2.8456],\n",
      "        [2.3048, 2.4196],\n",
      "        [2.7397, 3.1280],\n",
      "        [2.6617, 2.5769],\n",
      "        [2.2643, 2.7357],\n",
      "        [2.5751, 2.7316],\n",
      "        [2.4567, 2.5619],\n",
      "        [2.6519, 2.7884],\n",
      "        [2.4708, 2.8559],\n",
      "        [2.7489, 3.0669],\n",
      "        [2.3118, 2.7544],\n",
      "        [2.4652, 2.5700],\n",
      "        [2.7174, 2.2434],\n",
      "        [2.8070, 2.3823],\n",
      "        [2.6077, 3.0348],\n",
      "        [2.5702, 2.5157],\n",
      "        [2.6667, 2.6631],\n",
      "        [2.3991, 2.3693],\n",
      "        [2.5635, 2.4069],\n",
      "        [2.5710, 2.9552],\n",
      "        [2.5300, 2.2664],\n",
      "        [2.6134, 2.6488],\n",
      "        [2.7426, 2.9551],\n",
      "        [2.7470, 2.8630],\n",
      "        [2.1608, 2.7840],\n",
      "        [2.4528, 2.8938],\n",
      "        [2.0492, 2.4901],\n",
      "        [2.3396, 2.5372],\n",
      "        [2.4797, 3.0461],\n",
      "        [2.5278, 2.6093],\n",
      "        [2.2111, 2.8039],\n",
      "        [2.3787, 2.2892],\n",
      "        [2.8094, 2.4524],\n",
      "        [2.2330, 2.7139],\n",
      "        [2.2346, 2.2835],\n",
      "        [2.2935, 2.8550],\n",
      "        [2.7918, 3.2940],\n",
      "        [2.7501, 2.6204],\n",
      "        [2.8011, 2.3405],\n",
      "        [2.3646, 2.1896],\n",
      "        [2.6160, 2.6775],\n",
      "        [2.4322, 2.5719],\n",
      "        [2.4763, 2.6494],\n",
      "        [2.7980, 2.1701],\n",
      "        [2.6866, 2.5952],\n",
      "        [2.6394, 2.7296],\n",
      "        [2.8214, 2.3066]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6513, 2.5091],\n",
      "        [2.7368, 2.7403],\n",
      "        [2.3702, 2.1500],\n",
      "        [2.7521, 2.6175],\n",
      "        [2.3066, 2.6649],\n",
      "        [2.6710, 2.9291],\n",
      "        [2.4280, 3.0362],\n",
      "        [2.7935, 2.4958],\n",
      "        [2.4870, 2.1393],\n",
      "        [2.7001, 2.4059],\n",
      "        [2.1506, 2.4641],\n",
      "        [2.5060, 2.5462],\n",
      "        [2.4661, 2.3513],\n",
      "        [2.5952, 2.8384],\n",
      "        [2.6553, 2.3555],\n",
      "        [2.7160, 2.3717],\n",
      "        [2.8476, 2.8675],\n",
      "        [2.3741, 2.2656],\n",
      "        [2.7892, 2.3800],\n",
      "        [3.0438, 2.9855],\n",
      "        [2.4339, 2.5152],\n",
      "        [2.5512, 2.6278],\n",
      "        [2.6819, 2.6359],\n",
      "        [2.9030, 2.6188],\n",
      "        [2.5368, 2.4734],\n",
      "        [3.0644, 2.2878],\n",
      "        [2.8231, 2.6462],\n",
      "        [2.9207, 2.4816],\n",
      "        [2.4542, 2.4372],\n",
      "        [2.4854, 2.6828],\n",
      "        [2.8556, 2.5433],\n",
      "        [2.1760, 2.5856],\n",
      "        [2.6509, 2.4844],\n",
      "        [2.2463, 2.3384],\n",
      "        [2.3441, 2.3268],\n",
      "        [2.5292, 2.9464],\n",
      "        [2.6005, 2.7110],\n",
      "        [2.5965, 2.3638],\n",
      "        [2.5895, 2.3666],\n",
      "        [2.3330, 2.3601],\n",
      "        [2.5338, 2.8086],\n",
      "        [2.7685, 2.6913],\n",
      "        [2.2348, 2.4345],\n",
      "        [2.2828, 2.6450],\n",
      "        [2.4904, 2.2449],\n",
      "        [2.3423, 2.3033],\n",
      "        [2.4961, 2.4284],\n",
      "        [2.6007, 2.2640],\n",
      "        [2.1214, 2.6604],\n",
      "        [2.3257, 2.7661],\n",
      "        [2.2896, 2.6144],\n",
      "        [2.6456, 2.4284],\n",
      "        [2.5674, 2.2889],\n",
      "        [2.4339, 2.4435],\n",
      "        [3.1092, 2.6327],\n",
      "        [2.6883, 2.9020],\n",
      "        [2.5164, 2.6368],\n",
      "        [2.6415, 2.8949],\n",
      "        [1.7920, 2.2295],\n",
      "        [2.5777, 2.3669],\n",
      "        [2.2039, 2.8319],\n",
      "        [2.4986, 2.1491],\n",
      "        [2.5618, 2.3823],\n",
      "        [2.1232, 2.7498],\n",
      "        [3.0580, 2.1673],\n",
      "        [1.9453, 2.9225],\n",
      "        [2.7488, 2.7153],\n",
      "        [2.6928, 2.8512],\n",
      "        [2.5652, 2.4994],\n",
      "        [2.4117, 2.7400],\n",
      "        [2.3812, 2.6139],\n",
      "        [2.2289, 2.2727],\n",
      "        [2.8630, 2.6428],\n",
      "        [2.6684, 2.7520],\n",
      "        [2.2534, 2.5272],\n",
      "        [2.4539, 2.7583],\n",
      "        [2.8849, 2.8837],\n",
      "        [2.1791, 2.8154],\n",
      "        [2.6557, 2.4131],\n",
      "        [2.3480, 2.5382],\n",
      "        [2.0809, 2.0668],\n",
      "        [2.4554, 2.7064],\n",
      "        [2.5202, 2.5786],\n",
      "        [2.4450, 2.2362],\n",
      "        [2.4466, 2.6611],\n",
      "        [2.1121, 2.6406],\n",
      "        [2.6881, 2.6937],\n",
      "        [2.5084, 2.5955],\n",
      "        [2.6522, 2.1119],\n",
      "        [2.3526, 2.4831],\n",
      "        [2.2783, 2.6885],\n",
      "        [2.4847, 2.8387],\n",
      "        [2.6794, 2.3600],\n",
      "        [2.5689, 3.1607],\n",
      "        [2.6273, 2.4724],\n",
      "        [2.5982, 2.6792],\n",
      "        [3.0552, 2.4728],\n",
      "        [2.6704, 2.6315],\n",
      "        [2.3965, 2.5173],\n",
      "        [2.8058, 2.5895]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8677, 2.3485],\n",
      "        [3.0765, 2.3897],\n",
      "        [2.7909, 2.5213],\n",
      "        [2.3641, 2.3586],\n",
      "        [2.7158, 2.8751],\n",
      "        [2.9470, 2.8270],\n",
      "        [2.4068, 2.8614],\n",
      "        [2.1957, 2.3969],\n",
      "        [2.6948, 2.6345],\n",
      "        [2.3836, 2.4763],\n",
      "        [2.4832, 2.8217],\n",
      "        [2.3725, 2.6409],\n",
      "        [2.3442, 2.2621],\n",
      "        [2.6068, 3.1542],\n",
      "        [2.3335, 2.2506],\n",
      "        [3.0562, 2.5340],\n",
      "        [2.8290, 2.9521],\n",
      "        [2.8363, 2.6240],\n",
      "        [2.6659, 2.5562],\n",
      "        [2.4103, 2.7632],\n",
      "        [2.3169, 2.5770],\n",
      "        [2.2611, 2.6025],\n",
      "        [2.4547, 2.3482],\n",
      "        [2.7557, 2.7260],\n",
      "        [2.6638, 2.4885],\n",
      "        [3.1730, 2.6922],\n",
      "        [2.7271, 2.4148],\n",
      "        [2.1772, 2.4810],\n",
      "        [2.5771, 2.6126],\n",
      "        [2.7256, 3.1609],\n",
      "        [2.4798, 2.2250],\n",
      "        [2.7333, 2.9702],\n",
      "        [2.3435, 2.6498],\n",
      "        [2.5094, 2.9003],\n",
      "        [2.4013, 2.6317],\n",
      "        [2.7663, 2.6976],\n",
      "        [2.3586, 2.4509],\n",
      "        [2.3277, 2.1326],\n",
      "        [2.6240, 2.5544],\n",
      "        [2.3004, 2.3846],\n",
      "        [2.2813, 3.0282],\n",
      "        [2.4161, 2.6246],\n",
      "        [2.7511, 2.6745],\n",
      "        [2.9312, 2.4886],\n",
      "        [2.5509, 2.2226],\n",
      "        [2.5137, 2.7800],\n",
      "        [2.8368, 2.1442],\n",
      "        [2.7359, 2.8506],\n",
      "        [2.5936, 2.3181],\n",
      "        [2.4682, 2.3255],\n",
      "        [2.3125, 2.8754],\n",
      "        [2.7085, 2.3288],\n",
      "        [2.3889, 2.3853],\n",
      "        [2.1104, 2.3910],\n",
      "        [2.4080, 2.8159],\n",
      "        [2.5681, 2.1170],\n",
      "        [2.5451, 2.4712],\n",
      "        [2.4744, 2.6645],\n",
      "        [2.6025, 2.5437],\n",
      "        [2.6671, 2.7327],\n",
      "        [2.1684, 2.6236],\n",
      "        [2.4491, 2.8347],\n",
      "        [2.9518, 2.7687],\n",
      "        [2.5412, 2.2704],\n",
      "        [2.6632, 2.5498],\n",
      "        [2.6472, 2.6620],\n",
      "        [2.2553, 2.5040],\n",
      "        [2.4968, 2.2736],\n",
      "        [2.4963, 2.5582],\n",
      "        [1.9843, 2.6186],\n",
      "        [2.4006, 2.4310],\n",
      "        [2.4830, 2.2475],\n",
      "        [2.4912, 2.4345],\n",
      "        [2.6556, 2.8303],\n",
      "        [2.4905, 2.5183],\n",
      "        [2.5463, 2.7854],\n",
      "        [2.7006, 2.4173],\n",
      "        [1.8990, 2.7682],\n",
      "        [2.5367, 2.2303],\n",
      "        [2.3651, 2.9154],\n",
      "        [2.5976, 1.8989],\n",
      "        [2.6210, 2.4728],\n",
      "        [2.8489, 2.5666],\n",
      "        [2.3181, 2.9819],\n",
      "        [2.7839, 2.5444],\n",
      "        [2.7403, 2.2875],\n",
      "        [2.8883, 1.8778],\n",
      "        [2.4668, 2.8384],\n",
      "        [2.5866, 2.6666],\n",
      "        [2.4900, 2.5612],\n",
      "        [1.9378, 2.8041],\n",
      "        [2.4268, 2.6431],\n",
      "        [2.2666, 2.8851],\n",
      "        [2.1165, 2.1837],\n",
      "        [2.9095, 2.9214],\n",
      "        [2.5264, 2.3953],\n",
      "        [2.3661, 2.3120],\n",
      "        [2.4963, 2.5665],\n",
      "        [2.7021, 2.3740],\n",
      "        [2.6786, 2.0843]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7234, 3.0851],\n",
      "        [2.9934, 2.4925],\n",
      "        [2.3843, 2.4087],\n",
      "        [2.4488, 2.6716],\n",
      "        [2.3513, 2.1220],\n",
      "        [2.4964, 2.1077],\n",
      "        [2.4043, 2.3463],\n",
      "        [2.8690, 2.2774],\n",
      "        [2.5023, 2.3345],\n",
      "        [2.7759, 3.1151],\n",
      "        [1.9531, 2.4718],\n",
      "        [2.4384, 2.4479],\n",
      "        [3.0613, 2.7052],\n",
      "        [2.5931, 2.5213],\n",
      "        [2.6476, 2.9539],\n",
      "        [2.4017, 2.3506],\n",
      "        [2.6223, 2.3213],\n",
      "        [2.5165, 2.4142],\n",
      "        [1.9761, 2.6160],\n",
      "        [2.6358, 2.9563],\n",
      "        [2.6102, 2.4715],\n",
      "        [2.4549, 2.8218],\n",
      "        [2.4291, 2.8581],\n",
      "        [2.6210, 2.9970],\n",
      "        [2.7234, 2.8445],\n",
      "        [2.5123, 2.8912],\n",
      "        [2.2719, 2.3414],\n",
      "        [2.8861, 2.5627],\n",
      "        [2.8894, 2.4428],\n",
      "        [2.6552, 2.7386],\n",
      "        [2.1883, 2.7883],\n",
      "        [2.7121, 2.3099],\n",
      "        [2.5801, 2.7379],\n",
      "        [2.3211, 2.6753],\n",
      "        [2.0462, 2.8764],\n",
      "        [2.7784, 2.4334],\n",
      "        [2.7840, 2.5751],\n",
      "        [2.3710, 2.5944],\n",
      "        [2.9021, 2.6789],\n",
      "        [2.5996, 2.6494],\n",
      "        [2.4073, 2.0431],\n",
      "        [2.5770, 2.5022],\n",
      "        [2.4707, 2.4983],\n",
      "        [2.4701, 2.5993],\n",
      "        [2.4729, 2.6060],\n",
      "        [2.3080, 2.6060],\n",
      "        [2.4747, 2.2762],\n",
      "        [2.2938, 2.7191],\n",
      "        [2.6858, 2.9807],\n",
      "        [2.4420, 2.2366],\n",
      "        [2.7177, 2.8841],\n",
      "        [2.9318, 2.6132],\n",
      "        [2.5012, 2.2898],\n",
      "        [2.5160, 2.1676],\n",
      "        [2.4753, 2.8017],\n",
      "        [2.8372, 2.1809],\n",
      "        [2.5120, 3.0057],\n",
      "        [2.6153, 2.8527],\n",
      "        [2.6601, 2.1585],\n",
      "        [2.8426, 2.5085],\n",
      "        [2.5611, 2.4855],\n",
      "        [2.8632, 2.7204],\n",
      "        [2.3389, 2.5531],\n",
      "        [2.2210, 2.3577],\n",
      "        [2.1003, 2.5651],\n",
      "        [2.0316, 2.3855],\n",
      "        [2.4748, 2.7041],\n",
      "        [2.6055, 2.5051],\n",
      "        [2.3187, 2.3341],\n",
      "        [2.5318, 3.0134],\n",
      "        [2.6587, 2.6541],\n",
      "        [2.7812, 2.8225],\n",
      "        [2.4881, 2.5363],\n",
      "        [2.1324, 2.3964],\n",
      "        [2.2725, 2.8619],\n",
      "        [2.4462, 2.5717],\n",
      "        [2.6409, 2.6741],\n",
      "        [2.0406, 2.1310],\n",
      "        [2.9683, 2.3067],\n",
      "        [2.3671, 2.5034],\n",
      "        [2.3184, 2.9523],\n",
      "        [2.7464, 2.7928],\n",
      "        [2.2840, 2.1501],\n",
      "        [2.9025, 2.3350],\n",
      "        [1.9327, 2.5860],\n",
      "        [2.4260, 2.4449],\n",
      "        [2.2676, 2.3501],\n",
      "        [2.2076, 2.9877],\n",
      "        [2.3212, 2.6252],\n",
      "        [2.7049, 2.2508],\n",
      "        [2.5622, 2.5720],\n",
      "        [2.5165, 2.8712],\n",
      "        [2.4910, 2.4619],\n",
      "        [2.7052, 2.4938],\n",
      "        [2.4501, 2.2707],\n",
      "        [2.4458, 2.4779],\n",
      "        [2.8233, 2.3647],\n",
      "        [2.4571, 2.5522],\n",
      "        [2.6912, 2.6319],\n",
      "        [2.2891, 2.3774]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 55 complete in 0:02:34.990942; est. finish at 2021-11-29 21:56:02.640363\n",
      "Validation: 0.48 train | 0.502 dev\n",
      "### Epoch: 56 ###\n",
      "y:  tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.2496, 2.4272],\n",
      "        [2.3485, 2.2112],\n",
      "        [2.0144, 2.1366],\n",
      "        [2.8707, 2.4783],\n",
      "        [2.5210, 2.9900],\n",
      "        [2.4163, 2.8682],\n",
      "        [2.5854, 2.4507],\n",
      "        [2.6088, 2.2794],\n",
      "        [2.9275, 2.1972],\n",
      "        [2.6463, 3.1299],\n",
      "        [3.0062, 2.6470],\n",
      "        [2.7768, 2.7436],\n",
      "        [2.6957, 2.8329],\n",
      "        [2.8840, 2.8151],\n",
      "        [2.2507, 2.7719],\n",
      "        [2.8101, 2.5762],\n",
      "        [2.5377, 2.8326],\n",
      "        [2.5654, 2.2142],\n",
      "        [2.4716, 2.9994],\n",
      "        [2.3965, 2.3889],\n",
      "        [2.2044, 2.1184],\n",
      "        [2.6243, 2.6638],\n",
      "        [2.4357, 2.2788],\n",
      "        [2.4809, 2.7271],\n",
      "        [2.6913, 2.2345],\n",
      "        [1.9824, 2.9005],\n",
      "        [2.5135, 2.6157],\n",
      "        [2.3758, 2.8019],\n",
      "        [2.5888, 2.4782],\n",
      "        [2.3899, 2.4473],\n",
      "        [2.4345, 2.7479],\n",
      "        [2.4140, 2.6833],\n",
      "        [2.1984, 2.3906],\n",
      "        [2.5350, 2.3037],\n",
      "        [1.9926, 2.6248],\n",
      "        [2.7941, 2.5435],\n",
      "        [2.3775, 2.8933],\n",
      "        [3.0418, 2.2175],\n",
      "        [2.5088, 2.9404],\n",
      "        [2.9576, 2.6263],\n",
      "        [2.2560, 2.1769],\n",
      "        [2.6549, 2.2773],\n",
      "        [2.5526, 2.3952],\n",
      "        [2.4556, 2.3043],\n",
      "        [2.4240, 2.5110],\n",
      "        [2.3409, 2.5963],\n",
      "        [2.6247, 2.3367],\n",
      "        [2.1794, 2.4303],\n",
      "        [2.7036, 2.8448],\n",
      "        [3.3065, 2.4650],\n",
      "        [3.2015, 2.3338],\n",
      "        [2.2106, 2.4421],\n",
      "        [2.7827, 2.1682],\n",
      "        [2.7048, 2.1946],\n",
      "        [2.9198, 2.4149],\n",
      "        [2.0745, 2.3666],\n",
      "        [2.7244, 2.8986],\n",
      "        [2.7300, 2.7899],\n",
      "        [2.1327, 2.1971],\n",
      "        [2.7503, 2.1337],\n",
      "        [2.8668, 2.5832],\n",
      "        [2.6211, 2.4947],\n",
      "        [2.7455, 2.3924],\n",
      "        [2.5142, 2.6798],\n",
      "        [2.3930, 2.8226],\n",
      "        [2.4206, 2.6544],\n",
      "        [1.7760, 2.7190],\n",
      "        [2.6866, 2.6763],\n",
      "        [2.7382, 2.3720],\n",
      "        [2.5972, 2.4115],\n",
      "        [2.8023, 2.3958],\n",
      "        [2.6675, 2.2421],\n",
      "        [2.8093, 2.7071],\n",
      "        [2.4144, 2.3436],\n",
      "        [2.3767, 2.6364],\n",
      "        [2.3256, 2.6033],\n",
      "        [2.2353, 2.2465],\n",
      "        [2.6670, 2.7415],\n",
      "        [2.3005, 2.6506],\n",
      "        [2.3429, 2.3430],\n",
      "        [2.7448, 2.8273],\n",
      "        [2.4228, 2.8191],\n",
      "        [2.6943, 2.9283],\n",
      "        [2.7155, 2.1666],\n",
      "        [2.3660, 2.1903],\n",
      "        [2.5719, 2.6778],\n",
      "        [2.6679, 2.3505],\n",
      "        [2.2910, 2.5673],\n",
      "        [2.5528, 2.9502],\n",
      "        [2.6167, 2.5156],\n",
      "        [2.5778, 2.3806],\n",
      "        [2.6295, 2.4398],\n",
      "        [2.1039, 2.1745],\n",
      "        [2.4489, 3.3829],\n",
      "        [2.1307, 2.6188],\n",
      "        [2.4609, 2.2048],\n",
      "        [2.7806, 2.5688],\n",
      "        [2.8808, 2.5377],\n",
      "        [2.3619, 2.4268],\n",
      "        [2.3889, 2.6475]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6124, 2.6460],\n",
      "        [2.1475, 2.2223],\n",
      "        [2.5139, 2.3463],\n",
      "        [2.7022, 2.3829],\n",
      "        [2.7836, 2.6368],\n",
      "        [1.8198, 2.4078],\n",
      "        [2.6383, 2.9991],\n",
      "        [1.9473, 2.6802],\n",
      "        [2.6842, 2.5513],\n",
      "        [2.8326, 2.6364],\n",
      "        [2.5312, 2.8511],\n",
      "        [2.3965, 2.6116],\n",
      "        [2.5585, 2.7690],\n",
      "        [2.1554, 2.6309],\n",
      "        [2.5193, 2.8136],\n",
      "        [2.6459, 2.9035],\n",
      "        [2.7353, 2.5863],\n",
      "        [2.5102, 3.0524],\n",
      "        [2.6523, 2.8095],\n",
      "        [2.6787, 2.5960],\n",
      "        [2.3689, 3.0372],\n",
      "        [2.5489, 2.8579],\n",
      "        [2.6680, 2.6863],\n",
      "        [2.5921, 2.6608],\n",
      "        [2.1409, 2.6451],\n",
      "        [2.5615, 2.4693],\n",
      "        [3.2042, 2.5968],\n",
      "        [2.2886, 2.6803],\n",
      "        [3.1031, 2.5410],\n",
      "        [2.6839, 2.4986],\n",
      "        [2.5611, 2.3949],\n",
      "        [2.3927, 2.3629],\n",
      "        [2.5127, 2.6708],\n",
      "        [2.7308, 2.7845],\n",
      "        [2.2157, 2.1394],\n",
      "        [2.5543, 2.6995],\n",
      "        [2.4863, 2.7619],\n",
      "        [2.6833, 2.6195],\n",
      "        [2.9623, 2.4148],\n",
      "        [2.4839, 2.5548],\n",
      "        [2.3467, 2.7745],\n",
      "        [1.9082, 2.3159],\n",
      "        [2.6735, 2.9572],\n",
      "        [2.0387, 2.3072],\n",
      "        [2.6441, 2.3998],\n",
      "        [3.0249, 2.6816],\n",
      "        [2.7717, 2.7083],\n",
      "        [2.7835, 2.4096],\n",
      "        [2.4941, 2.7502],\n",
      "        [2.6147, 2.5068],\n",
      "        [2.8017, 2.8088],\n",
      "        [2.3228, 2.1942],\n",
      "        [2.3486, 2.2781],\n",
      "        [2.2907, 2.5943],\n",
      "        [2.2858, 2.3317],\n",
      "        [2.6370, 2.2879],\n",
      "        [2.7680, 2.4720],\n",
      "        [2.4722, 2.4769],\n",
      "        [2.4499, 2.5365],\n",
      "        [2.9060, 2.6055],\n",
      "        [2.2171, 2.8547],\n",
      "        [2.3059, 2.6775],\n",
      "        [2.1489, 2.6279],\n",
      "        [2.6812, 2.6877],\n",
      "        [2.1671, 2.3504],\n",
      "        [2.2240, 2.5220],\n",
      "        [2.2501, 2.9354],\n",
      "        [2.5494, 2.9092],\n",
      "        [2.2168, 2.2219],\n",
      "        [2.4098, 2.7084],\n",
      "        [2.9872, 2.4272],\n",
      "        [2.2805, 2.8892],\n",
      "        [2.6502, 2.4100],\n",
      "        [2.2482, 2.2692],\n",
      "        [2.8211, 2.6585],\n",
      "        [2.3687, 2.2525],\n",
      "        [2.4109, 2.0437],\n",
      "        [1.9000, 2.8204],\n",
      "        [2.6987, 2.3331],\n",
      "        [2.7329, 2.6254],\n",
      "        [2.8258, 2.9259],\n",
      "        [2.3324, 2.6020],\n",
      "        [2.4268, 2.6637],\n",
      "        [2.6774, 2.7483],\n",
      "        [2.7600, 2.0103],\n",
      "        [3.0338, 2.8815],\n",
      "        [2.8703, 2.7649],\n",
      "        [2.0711, 2.5646],\n",
      "        [2.7151, 2.6587],\n",
      "        [2.7926, 3.0182],\n",
      "        [2.1933, 2.2947],\n",
      "        [3.0632, 2.6016],\n",
      "        [2.3939, 2.4860],\n",
      "        [2.6263, 2.9152],\n",
      "        [1.9311, 2.2976],\n",
      "        [2.4744, 2.3754],\n",
      "        [2.1410, 2.2685],\n",
      "        [2.5740, 2.1074],\n",
      "        [2.4844, 2.3477],\n",
      "        [2.3091, 2.6978]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5854, 2.3222],\n",
      "        [2.2479, 2.5719],\n",
      "        [2.5604, 2.9625],\n",
      "        [2.3173, 2.7835],\n",
      "        [2.8812, 2.2866],\n",
      "        [2.8573, 2.5081],\n",
      "        [2.5870, 2.2594],\n",
      "        [2.9892, 2.3628],\n",
      "        [2.5748, 2.6253],\n",
      "        [2.6118, 2.4488],\n",
      "        [2.4200, 2.8887],\n",
      "        [2.5677, 2.8768],\n",
      "        [2.7596, 2.3600],\n",
      "        [2.5889, 2.4681],\n",
      "        [2.8110, 2.5097],\n",
      "        [2.7019, 2.2246],\n",
      "        [2.4007, 2.9195],\n",
      "        [2.3741, 2.6136],\n",
      "        [2.6117, 2.7381],\n",
      "        [2.2340, 3.0273],\n",
      "        [2.2115, 2.7017],\n",
      "        [2.7731, 2.4563],\n",
      "        [2.5271, 2.3041],\n",
      "        [2.4717, 2.4094],\n",
      "        [2.5939, 2.2661],\n",
      "        [2.5047, 2.7103],\n",
      "        [2.4384, 2.8453],\n",
      "        [2.1983, 2.4184],\n",
      "        [2.1215, 2.5004],\n",
      "        [2.1122, 2.5822],\n",
      "        [2.8137, 2.5579],\n",
      "        [2.4081, 2.5423],\n",
      "        [2.4500, 2.9112],\n",
      "        [2.9118, 2.4718],\n",
      "        [3.0431, 2.7456],\n",
      "        [2.7049, 2.4539],\n",
      "        [2.0579, 2.1741],\n",
      "        [2.2828, 2.4345],\n",
      "        [2.5084, 2.9536],\n",
      "        [2.4461, 2.4012],\n",
      "        [2.5676, 2.9169],\n",
      "        [2.8080, 2.1617],\n",
      "        [2.1204, 2.4732],\n",
      "        [2.9719, 2.5385],\n",
      "        [2.3723, 3.0863],\n",
      "        [2.2495, 2.4173],\n",
      "        [2.5710, 2.4489],\n",
      "        [2.8224, 2.6158],\n",
      "        [2.7124, 2.0489],\n",
      "        [2.3470, 2.3625],\n",
      "        [2.5884, 2.6192],\n",
      "        [3.0521, 2.2127],\n",
      "        [2.5134, 2.8636],\n",
      "        [2.5033, 3.0045],\n",
      "        [2.9743, 2.3709],\n",
      "        [2.5550, 2.7575],\n",
      "        [2.9095, 2.7669],\n",
      "        [2.6004, 2.1330],\n",
      "        [2.5178, 2.3424],\n",
      "        [2.7675, 2.6428],\n",
      "        [2.0762, 2.1751],\n",
      "        [2.4357, 2.3293],\n",
      "        [2.9370, 2.7787],\n",
      "        [2.1955, 2.7066],\n",
      "        [2.3260, 2.6086],\n",
      "        [2.2369, 2.4092],\n",
      "        [3.0470, 2.4542],\n",
      "        [2.4965, 2.4974],\n",
      "        [3.1208, 3.2989],\n",
      "        [2.3400, 2.1169],\n",
      "        [2.9425, 1.9902],\n",
      "        [2.6375, 2.7799],\n",
      "        [2.7952, 2.6654],\n",
      "        [2.6322, 2.5971],\n",
      "        [2.2395, 2.6369],\n",
      "        [2.3743, 2.5603],\n",
      "        [2.8485, 2.5597],\n",
      "        [2.2091, 2.1632],\n",
      "        [2.5835, 2.5902],\n",
      "        [2.4839, 2.9510],\n",
      "        [2.2148, 2.6196],\n",
      "        [2.1749, 2.9741],\n",
      "        [2.4074, 2.6648],\n",
      "        [2.7579, 3.1390],\n",
      "        [2.8649, 2.6614],\n",
      "        [2.8838, 2.6928],\n",
      "        [2.8219, 3.1520],\n",
      "        [2.4047, 2.6017],\n",
      "        [2.8064, 2.8450],\n",
      "        [2.7410, 2.0766],\n",
      "        [2.2565, 3.0621],\n",
      "        [2.2822, 2.8760],\n",
      "        [2.9506, 2.5519],\n",
      "        [2.4062, 2.8679],\n",
      "        [2.8863, 2.7504],\n",
      "        [2.7445, 1.9380],\n",
      "        [2.6810, 2.4663],\n",
      "        [2.4709, 2.5323],\n",
      "        [2.3265, 2.7293],\n",
      "        [2.3179, 2.1844]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.2818, 2.4193],\n",
      "        [2.4804, 2.9949],\n",
      "        [2.7436, 2.2988],\n",
      "        [2.5536, 2.6801],\n",
      "        [2.5176, 2.5825],\n",
      "        [2.7388, 2.6312],\n",
      "        [2.4038, 2.0711],\n",
      "        [2.7122, 2.2118],\n",
      "        [3.0201, 2.6625],\n",
      "        [2.6886, 2.4917],\n",
      "        [2.5888, 2.6584],\n",
      "        [2.5998, 2.2823],\n",
      "        [2.4557, 2.5734],\n",
      "        [3.0071, 2.3612],\n",
      "        [2.7970, 1.9646],\n",
      "        [2.6996, 2.5784],\n",
      "        [2.5378, 2.5051],\n",
      "        [2.7667, 2.6097],\n",
      "        [2.9638, 2.5894],\n",
      "        [2.3963, 2.5577],\n",
      "        [2.8549, 2.5461],\n",
      "        [2.9530, 2.3175],\n",
      "        [2.9469, 2.7308],\n",
      "        [2.8445, 2.7314],\n",
      "        [2.2840, 2.3867],\n",
      "        [2.5123, 2.4397],\n",
      "        [2.3462, 2.2830],\n",
      "        [2.5475, 2.3632],\n",
      "        [2.6345, 2.6201],\n",
      "        [2.1816, 2.3449],\n",
      "        [2.2556, 2.4430],\n",
      "        [2.5381, 2.6631],\n",
      "        [2.4868, 2.3652],\n",
      "        [2.4098, 2.5940],\n",
      "        [2.4812, 2.5399],\n",
      "        [2.5556, 2.4049],\n",
      "        [2.3377, 2.2141],\n",
      "        [2.3836, 2.5009],\n",
      "        [2.4424, 2.7175],\n",
      "        [2.6398, 2.1796],\n",
      "        [2.6317, 2.3035],\n",
      "        [2.3451, 2.8462],\n",
      "        [2.8670, 3.0227],\n",
      "        [2.3922, 2.6838],\n",
      "        [2.4106, 2.1399],\n",
      "        [2.5253, 2.1823],\n",
      "        [2.1116, 2.2447],\n",
      "        [2.4946, 2.8513],\n",
      "        [2.3946, 2.6677],\n",
      "        [2.7428, 2.6949],\n",
      "        [2.4119, 2.9680],\n",
      "        [2.4988, 3.0175],\n",
      "        [2.2515, 1.9773],\n",
      "        [2.7696, 2.7603],\n",
      "        [2.4563, 2.4602],\n",
      "        [2.8753, 2.6358],\n",
      "        [2.5838, 2.6124],\n",
      "        [2.4064, 2.7877],\n",
      "        [2.8423, 3.1548],\n",
      "        [2.7105, 2.4158],\n",
      "        [2.2308, 2.5951],\n",
      "        [2.6349, 2.3094],\n",
      "        [2.3699, 2.1332],\n",
      "        [2.8956, 2.4146],\n",
      "        [2.5057, 2.9167],\n",
      "        [2.2819, 2.9406],\n",
      "        [2.7309, 3.2097],\n",
      "        [2.6351, 2.5856],\n",
      "        [2.3034, 2.5903],\n",
      "        [2.8901, 2.9113],\n",
      "        [2.2876, 2.4230],\n",
      "        [2.3911, 2.5185],\n",
      "        [2.8092, 2.8417],\n",
      "        [2.3401, 2.3328],\n",
      "        [2.7925, 2.4994],\n",
      "        [2.5214, 2.1813],\n",
      "        [2.4011, 2.5011],\n",
      "        [2.6135, 2.4672],\n",
      "        [2.3910, 2.8131],\n",
      "        [2.8070, 2.8444],\n",
      "        [2.5322, 2.4468],\n",
      "        [2.8901, 2.6245],\n",
      "        [2.5711, 2.1036],\n",
      "        [2.2366, 2.5566],\n",
      "        [2.5876, 2.4628],\n",
      "        [2.6826, 2.3334],\n",
      "        [2.3350, 2.2767],\n",
      "        [2.5804, 2.3126],\n",
      "        [2.3989, 3.1514],\n",
      "        [2.6093, 2.4917],\n",
      "        [2.3579, 2.6313],\n",
      "        [2.6229, 2.0871],\n",
      "        [2.6561, 2.3501],\n",
      "        [2.8271, 2.1257],\n",
      "        [2.6106, 2.5306],\n",
      "        [2.6249, 2.5682],\n",
      "        [2.6061, 2.1944],\n",
      "        [3.0596, 2.6566],\n",
      "        [2.9131, 2.1207],\n",
      "        [2.6218, 2.4534]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3770, 2.7905],\n",
      "        [3.1266, 2.6450],\n",
      "        [2.2691, 2.6929],\n",
      "        [2.5697, 2.3686],\n",
      "        [2.5482, 2.5922],\n",
      "        [2.9982, 2.5808],\n",
      "        [2.0710, 2.5861],\n",
      "        [2.1716, 2.8368],\n",
      "        [2.2506, 3.0208],\n",
      "        [2.7666, 3.0644],\n",
      "        [2.4368, 2.0124],\n",
      "        [2.1553, 2.0741],\n",
      "        [2.5673, 2.0527],\n",
      "        [2.9070, 2.4162],\n",
      "        [2.2054, 3.1497],\n",
      "        [2.7181, 2.4210],\n",
      "        [2.7073, 2.5735],\n",
      "        [2.5384, 2.5267],\n",
      "        [2.5884, 2.8076],\n",
      "        [2.4932, 2.7038],\n",
      "        [2.3398, 2.4182],\n",
      "        [2.7725, 2.4999],\n",
      "        [2.5589, 2.5419],\n",
      "        [2.9626, 2.5735],\n",
      "        [2.5820, 2.4869],\n",
      "        [2.2306, 2.6348],\n",
      "        [2.8104, 2.5844],\n",
      "        [2.8455, 2.4129],\n",
      "        [2.2494, 2.7077],\n",
      "        [2.4103, 2.5479],\n",
      "        [2.6446, 2.8396],\n",
      "        [2.7862, 2.3801],\n",
      "        [2.5075, 3.1717],\n",
      "        [2.6142, 2.5797],\n",
      "        [2.3942, 2.8165],\n",
      "        [2.2361, 2.6277],\n",
      "        [2.6438, 2.4263],\n",
      "        [2.5316, 2.2070],\n",
      "        [2.6560, 2.6901],\n",
      "        [2.7919, 2.7043],\n",
      "        [2.5807, 2.2262],\n",
      "        [2.5470, 2.5380],\n",
      "        [2.5134, 2.4457],\n",
      "        [2.6870, 2.5749],\n",
      "        [2.8042, 2.5814],\n",
      "        [2.8160, 2.4431],\n",
      "        [2.7009, 2.4346],\n",
      "        [2.2432, 2.3481],\n",
      "        [2.5226, 2.6200],\n",
      "        [2.6845, 2.4747],\n",
      "        [2.4200, 2.3112],\n",
      "        [2.5652, 2.6412],\n",
      "        [2.5282, 2.3789],\n",
      "        [2.4808, 2.0780],\n",
      "        [2.2138, 2.5500],\n",
      "        [2.4945, 2.3003],\n",
      "        [2.6497, 2.4225],\n",
      "        [2.7522, 2.4856],\n",
      "        [2.4642, 2.2761],\n",
      "        [2.0493, 2.4038],\n",
      "        [2.4280, 2.5382],\n",
      "        [2.3041, 2.4545],\n",
      "        [2.1449, 2.3960],\n",
      "        [2.4178, 2.2437],\n",
      "        [2.7161, 2.7438],\n",
      "        [2.8483, 2.6887],\n",
      "        [2.5554, 2.2480],\n",
      "        [3.1539, 2.5570],\n",
      "        [2.0020, 2.2268],\n",
      "        [2.5237, 2.2402],\n",
      "        [2.7645, 2.8087],\n",
      "        [2.9214, 2.6094],\n",
      "        [2.4047, 2.0254],\n",
      "        [2.2864, 2.6098],\n",
      "        [2.2295, 2.8356],\n",
      "        [2.6314, 2.5376],\n",
      "        [2.9851, 2.3418],\n",
      "        [2.4816, 2.5347],\n",
      "        [2.8834, 2.5879],\n",
      "        [2.3512, 2.7720],\n",
      "        [2.5891, 2.6152],\n",
      "        [2.3570, 2.3366],\n",
      "        [2.6198, 3.3174],\n",
      "        [2.2299, 3.0453],\n",
      "        [2.7255, 2.6251],\n",
      "        [2.3522, 2.7034],\n",
      "        [2.4586, 2.9160],\n",
      "        [2.0958, 2.9704],\n",
      "        [2.3616, 2.4160],\n",
      "        [2.5856, 2.4792],\n",
      "        [2.4508, 2.6809],\n",
      "        [2.6605, 3.0467],\n",
      "        [2.9264, 1.8739],\n",
      "        [2.4829, 2.9735],\n",
      "        [3.0185, 2.5988],\n",
      "        [2.3323, 2.6388],\n",
      "        [2.9330, 2.8712],\n",
      "        [2.8825, 2.6002],\n",
      "        [2.5826, 2.7144],\n",
      "        [2.5236, 2.5392]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 60 complete in 0:02:47.545035; est. finish at 2021-11-29 21:56:00.080363\n",
      "Validation: 0.532 train | 0.496 dev\n",
      "### Epoch: 61 ###\n",
      "y:  tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5950, 2.3269],\n",
      "        [2.7472, 2.5188],\n",
      "        [2.2361, 2.2481],\n",
      "        [2.5179, 2.7069],\n",
      "        [2.7018, 2.3722],\n",
      "        [2.5335, 2.3314],\n",
      "        [2.3853, 2.4735],\n",
      "        [2.2456, 2.7336],\n",
      "        [2.9212, 2.3840],\n",
      "        [2.6045, 2.5125],\n",
      "        [2.5824, 2.2251],\n",
      "        [2.6354, 2.8179],\n",
      "        [2.6842, 2.7780],\n",
      "        [2.2927, 2.6363],\n",
      "        [2.8255, 2.6122],\n",
      "        [2.6009, 2.6007],\n",
      "        [2.2799, 2.4605],\n",
      "        [3.0450, 2.2461],\n",
      "        [2.0256, 2.1682],\n",
      "        [2.7650, 2.6618],\n",
      "        [2.2898, 2.5593],\n",
      "        [2.7570, 2.5874],\n",
      "        [2.8259, 2.6542],\n",
      "        [2.3644, 2.5776],\n",
      "        [3.0157, 2.7295],\n",
      "        [2.5374, 2.5258],\n",
      "        [2.2937, 2.5665],\n",
      "        [2.2345, 2.4449],\n",
      "        [2.6923, 2.7444],\n",
      "        [2.6441, 2.8615],\n",
      "        [2.6419, 2.2165],\n",
      "        [2.6781, 2.2847],\n",
      "        [2.2230, 2.4180],\n",
      "        [2.3808, 2.4820],\n",
      "        [2.3308, 2.3679],\n",
      "        [2.7265, 2.6109],\n",
      "        [2.7234, 2.4082],\n",
      "        [2.5710, 2.4094],\n",
      "        [2.3048, 2.3097],\n",
      "        [2.6134, 2.7164],\n",
      "        [2.3438, 2.7904],\n",
      "        [2.3729, 2.4056],\n",
      "        [2.1619, 2.8067],\n",
      "        [2.2548, 2.4193],\n",
      "        [2.3557, 2.8023],\n",
      "        [2.9050, 2.5655],\n",
      "        [3.0335, 2.3296],\n",
      "        [2.5062, 2.7280],\n",
      "        [2.7399, 2.2588],\n",
      "        [2.4558, 2.5392],\n",
      "        [2.7277, 2.4185],\n",
      "        [2.4828, 2.3701],\n",
      "        [2.1332, 2.9094],\n",
      "        [2.5033, 2.6311],\n",
      "        [2.4122, 2.9706],\n",
      "        [2.7727, 2.9108],\n",
      "        [2.7920, 2.4337],\n",
      "        [2.4392, 2.2658],\n",
      "        [2.5877, 2.7435],\n",
      "        [2.7106, 2.4021],\n",
      "        [2.6152, 2.2402],\n",
      "        [2.9995, 2.7073],\n",
      "        [2.7205, 2.5472],\n",
      "        [2.7225, 2.6551],\n",
      "        [2.2386, 2.6590],\n",
      "        [2.6440, 2.6058],\n",
      "        [2.5342, 3.0538],\n",
      "        [2.3740, 2.6915],\n",
      "        [2.2165, 2.6962],\n",
      "        [2.5924, 2.6518],\n",
      "        [2.6872, 2.4697],\n",
      "        [2.6530, 2.3020],\n",
      "        [2.5387, 2.5689],\n",
      "        [2.2771, 2.5031],\n",
      "        [2.4867, 3.0711],\n",
      "        [2.2256, 3.0991],\n",
      "        [2.4113, 2.4434],\n",
      "        [2.3341, 2.1177],\n",
      "        [2.2620, 2.2712],\n",
      "        [3.1730, 2.6276],\n",
      "        [2.3030, 2.3022],\n",
      "        [2.5508, 2.7959],\n",
      "        [2.6556, 2.3336],\n",
      "        [2.6459, 2.1120],\n",
      "        [2.4078, 2.3477],\n",
      "        [2.8034, 2.9000],\n",
      "        [1.9636, 2.3795],\n",
      "        [2.7379, 2.4132],\n",
      "        [2.4421, 2.6507],\n",
      "        [2.8198, 2.9455],\n",
      "        [2.2703, 2.8351],\n",
      "        [2.6948, 2.6258],\n",
      "        [2.8547, 2.7099],\n",
      "        [2.6827, 2.8658],\n",
      "        [2.4329, 2.7947],\n",
      "        [2.8252, 2.3119],\n",
      "        [2.3716, 2.5197],\n",
      "        [2.4705, 2.6960],\n",
      "        [2.4346, 2.4600],\n",
      "        [2.8260, 2.6622]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3596, 2.7246],\n",
      "        [2.5657, 2.3080],\n",
      "        [2.4407, 2.5154],\n",
      "        [2.2718, 2.4532],\n",
      "        [2.6037, 2.4423],\n",
      "        [3.0560, 2.2226],\n",
      "        [2.6841, 3.1544],\n",
      "        [2.7772, 2.5202],\n",
      "        [3.0628, 2.5274],\n",
      "        [2.8272, 2.1426],\n",
      "        [3.0158, 2.6630],\n",
      "        [2.5590, 2.6250],\n",
      "        [2.8497, 1.9794],\n",
      "        [2.7036, 2.1832],\n",
      "        [2.8871, 2.5117],\n",
      "        [2.2148, 2.3693],\n",
      "        [2.5566, 2.9023],\n",
      "        [3.4278, 2.4806],\n",
      "        [2.7922, 2.8205],\n",
      "        [2.7883, 2.2975],\n",
      "        [2.7119, 2.4834],\n",
      "        [2.4811, 2.7815],\n",
      "        [2.6525, 2.6147],\n",
      "        [2.7514, 2.5545],\n",
      "        [3.0364, 2.7148],\n",
      "        [2.1343, 2.2765],\n",
      "        [2.3090, 2.0939],\n",
      "        [2.5317, 2.5028],\n",
      "        [2.4509, 2.6939],\n",
      "        [2.5223, 2.6739],\n",
      "        [2.6560, 1.9257],\n",
      "        [2.2613, 2.3185],\n",
      "        [2.0381, 2.7256],\n",
      "        [2.7719, 2.4719],\n",
      "        [2.4349, 2.3491],\n",
      "        [2.7666, 2.5985],\n",
      "        [2.4049, 2.8855],\n",
      "        [2.6798, 2.5645],\n",
      "        [2.6410, 2.5539],\n",
      "        [2.5222, 2.5084],\n",
      "        [3.0300, 2.6192],\n",
      "        [2.3138, 2.2511],\n",
      "        [2.0693, 2.2784],\n",
      "        [2.4789, 2.8864],\n",
      "        [2.5199, 2.3470],\n",
      "        [2.2963, 2.4812],\n",
      "        [2.5050, 2.4262],\n",
      "        [2.7129, 2.4605],\n",
      "        [2.4504, 2.5016],\n",
      "        [2.3607, 2.5378],\n",
      "        [2.2969, 2.6619],\n",
      "        [2.3610, 2.4978],\n",
      "        [2.5694, 2.8965],\n",
      "        [2.2838, 2.2616],\n",
      "        [2.5543, 2.7915],\n",
      "        [2.6285, 2.7282],\n",
      "        [2.3100, 2.6088],\n",
      "        [2.9538, 2.5058],\n",
      "        [2.8241, 2.3917],\n",
      "        [2.3469, 2.3305],\n",
      "        [2.3481, 2.8892],\n",
      "        [2.7055, 2.4827],\n",
      "        [2.5013, 2.6822],\n",
      "        [2.7209, 2.1782],\n",
      "        [2.8643, 2.8128],\n",
      "        [2.7767, 2.1544],\n",
      "        [2.6450, 2.4523],\n",
      "        [2.4888, 2.7121],\n",
      "        [2.7790, 2.5311],\n",
      "        [2.8904, 2.3682],\n",
      "        [2.5775, 1.7777],\n",
      "        [2.6553, 2.4500],\n",
      "        [2.6769, 2.7017],\n",
      "        [2.6340, 2.5372],\n",
      "        [2.4785, 2.3915],\n",
      "        [2.0462, 2.8304],\n",
      "        [2.6567, 2.7343],\n",
      "        [2.2496, 2.6030],\n",
      "        [2.2422, 3.1894],\n",
      "        [2.0206, 3.2941],\n",
      "        [2.3609, 2.7891],\n",
      "        [2.7084, 2.4265],\n",
      "        [2.6419, 2.6642],\n",
      "        [2.7909, 2.2884],\n",
      "        [2.8386, 2.2984],\n",
      "        [2.6689, 2.3585],\n",
      "        [2.5483, 2.1257],\n",
      "        [2.5457, 2.3664],\n",
      "        [2.7918, 2.5587],\n",
      "        [2.9241, 2.2910],\n",
      "        [2.3297, 2.4477],\n",
      "        [2.6486, 2.8080],\n",
      "        [2.3307, 2.2645],\n",
      "        [2.8367, 2.6537],\n",
      "        [2.4622, 2.4410],\n",
      "        [2.3331, 2.6804],\n",
      "        [2.4387, 2.5440],\n",
      "        [2.8986, 2.2987],\n",
      "        [2.8571, 2.8593],\n",
      "        [2.4215, 2.6616]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.4808, 2.3773],\n",
      "        [2.4000, 2.5700],\n",
      "        [2.6312, 2.6417],\n",
      "        [2.3745, 2.8721],\n",
      "        [2.3609, 2.7475],\n",
      "        [2.6932, 2.6988],\n",
      "        [2.2054, 2.3884],\n",
      "        [2.4873, 2.0958],\n",
      "        [2.2321, 2.5760],\n",
      "        [2.6645, 2.5136],\n",
      "        [2.5311, 3.0386],\n",
      "        [2.6618, 2.6940],\n",
      "        [2.7604, 2.6447],\n",
      "        [2.6086, 2.7880],\n",
      "        [2.8155, 2.8492],\n",
      "        [2.6088, 2.5461],\n",
      "        [2.7749, 2.7772],\n",
      "        [2.9587, 2.4876],\n",
      "        [2.9272, 2.7222],\n",
      "        [2.4662, 2.7815],\n",
      "        [2.2288, 2.1872],\n",
      "        [2.6809, 2.5955],\n",
      "        [2.4210, 2.8872],\n",
      "        [2.7716, 2.4756],\n",
      "        [2.7279, 2.6795],\n",
      "        [2.6853, 2.6619],\n",
      "        [2.6980, 2.3994],\n",
      "        [2.4027, 2.5782],\n",
      "        [2.5068, 2.4600],\n",
      "        [2.4961, 2.3178],\n",
      "        [2.6428, 2.6575],\n",
      "        [2.7341, 2.2069],\n",
      "        [2.7990, 2.0655],\n",
      "        [2.5050, 2.7430],\n",
      "        [2.5541, 2.4546],\n",
      "        [2.8475, 2.4777],\n",
      "        [2.8347, 2.7350],\n",
      "        [3.1120, 2.2432],\n",
      "        [2.4270, 3.1415],\n",
      "        [2.4121, 2.4161],\n",
      "        [2.6959, 2.1994],\n",
      "        [2.0585, 2.2715],\n",
      "        [2.3624, 2.7656],\n",
      "        [2.8701, 2.5885],\n",
      "        [2.4968, 2.7735],\n",
      "        [2.6308, 2.6898],\n",
      "        [2.4831, 2.0258],\n",
      "        [2.7763, 2.7789],\n",
      "        [2.0406, 2.4108],\n",
      "        [2.2804, 2.5290],\n",
      "        [2.3072, 2.9623],\n",
      "        [2.6917, 2.8263],\n",
      "        [2.8755, 2.4097],\n",
      "        [2.7883, 2.6133],\n",
      "        [2.5400, 2.9095],\n",
      "        [2.6364, 2.5282],\n",
      "        [2.4169, 2.3834],\n",
      "        [2.6851, 2.4963],\n",
      "        [2.5412, 2.7636],\n",
      "        [2.4653, 2.1002],\n",
      "        [2.4756, 2.1252],\n",
      "        [2.3794, 2.8020],\n",
      "        [2.1929, 2.5620],\n",
      "        [2.8676, 2.4522],\n",
      "        [2.3321, 2.7857],\n",
      "        [2.2271, 2.5279],\n",
      "        [2.4202, 2.6713],\n",
      "        [2.3198, 2.7104],\n",
      "        [2.6357, 2.3986],\n",
      "        [2.5447, 2.5802],\n",
      "        [2.4835, 2.2823],\n",
      "        [2.2322, 2.6075],\n",
      "        [2.6855, 2.6268],\n",
      "        [2.6669, 2.8062],\n",
      "        [2.7988, 2.8451],\n",
      "        [2.9691, 2.1345],\n",
      "        [2.4039, 2.6177],\n",
      "        [2.6054, 2.3757],\n",
      "        [2.9138, 2.4217],\n",
      "        [2.1442, 2.6218],\n",
      "        [2.7127, 2.7024],\n",
      "        [2.7050, 2.3118],\n",
      "        [2.3646, 2.1266],\n",
      "        [2.3928, 2.9772],\n",
      "        [2.8179, 2.5934],\n",
      "        [2.2116, 2.9494],\n",
      "        [2.3469, 2.2765],\n",
      "        [2.3067, 2.8715],\n",
      "        [2.5045, 2.3317],\n",
      "        [2.4464, 2.5634],\n",
      "        [2.9129, 2.7993],\n",
      "        [2.4770, 2.4925],\n",
      "        [2.4258, 3.0659],\n",
      "        [2.6071, 2.3281],\n",
      "        [2.0210, 2.9644],\n",
      "        [2.6343, 2.3416],\n",
      "        [2.1236, 2.7988],\n",
      "        [2.5021, 2.6758],\n",
      "        [2.2755, 2.2761],\n",
      "        [2.1334, 2.2791]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7630, 2.5366],\n",
      "        [2.7707, 2.9002],\n",
      "        [2.6021, 2.7983],\n",
      "        [2.9684, 2.2547],\n",
      "        [2.8022, 2.6110],\n",
      "        [2.5527, 2.3761],\n",
      "        [2.4332, 2.4586],\n",
      "        [3.0590, 2.6063],\n",
      "        [2.1206, 2.2671],\n",
      "        [2.7747, 2.6979],\n",
      "        [2.9378, 2.7007],\n",
      "        [2.5879, 2.1471],\n",
      "        [2.2003, 2.6058],\n",
      "        [2.4674, 2.9075],\n",
      "        [2.8644, 2.4901],\n",
      "        [2.5629, 2.7162],\n",
      "        [2.3181, 2.4505],\n",
      "        [2.2270, 2.4290],\n",
      "        [2.4240, 2.5710],\n",
      "        [2.3335, 2.3619],\n",
      "        [2.7531, 3.0498],\n",
      "        [2.4212, 2.7254],\n",
      "        [2.6927, 2.5514],\n",
      "        [1.8021, 2.1839],\n",
      "        [1.9652, 2.6942],\n",
      "        [2.8572, 2.5621],\n",
      "        [2.6870, 2.9589],\n",
      "        [2.4169, 3.1014],\n",
      "        [2.2133, 2.4894],\n",
      "        [2.8621, 2.8226],\n",
      "        [2.8712, 2.6402],\n",
      "        [3.0839, 2.8159],\n",
      "        [2.4088, 2.4673],\n",
      "        [2.5221, 2.7099],\n",
      "        [2.3416, 2.4476],\n",
      "        [3.0488, 2.5963],\n",
      "        [2.6874, 2.3303],\n",
      "        [2.6439, 2.0136],\n",
      "        [2.5772, 2.7186],\n",
      "        [2.2855, 2.4929],\n",
      "        [2.6054, 2.7081],\n",
      "        [1.6326, 2.4914],\n",
      "        [2.6775, 2.4932],\n",
      "        [2.6105, 2.5263],\n",
      "        [2.6687, 2.3852],\n",
      "        [2.5620, 2.4459],\n",
      "        [2.8712, 2.6786],\n",
      "        [2.6078, 2.7439],\n",
      "        [2.7484, 2.2830],\n",
      "        [3.0352, 2.5150],\n",
      "        [2.6110, 2.6937],\n",
      "        [2.4129, 2.5413],\n",
      "        [2.2974, 2.6647],\n",
      "        [2.7937, 2.8720],\n",
      "        [2.7357, 2.3945],\n",
      "        [2.5300, 3.1480],\n",
      "        [2.7771, 2.9818],\n",
      "        [2.7944, 2.6589],\n",
      "        [2.7830, 2.4104],\n",
      "        [2.4734, 2.7610],\n",
      "        [2.6580, 2.5556],\n",
      "        [2.3862, 2.3229],\n",
      "        [2.8685, 2.0753],\n",
      "        [2.6758, 2.6406],\n",
      "        [2.4553, 2.3661],\n",
      "        [2.8276, 2.7062],\n",
      "        [2.7421, 2.3367],\n",
      "        [2.9497, 2.5422],\n",
      "        [2.8248, 2.2513],\n",
      "        [2.4461, 2.6824],\n",
      "        [2.4549, 2.7009],\n",
      "        [2.7879, 2.2508],\n",
      "        [2.7744, 2.5292],\n",
      "        [2.6123, 2.8294],\n",
      "        [3.1894, 2.0053],\n",
      "        [2.6370, 2.4315],\n",
      "        [2.2993, 2.7874],\n",
      "        [2.5280, 2.7101],\n",
      "        [2.9359, 2.2720],\n",
      "        [2.1736, 2.7968],\n",
      "        [2.4986, 2.5144],\n",
      "        [2.5937, 2.7154],\n",
      "        [2.6538, 2.3712],\n",
      "        [2.3811, 2.4539],\n",
      "        [2.1080, 2.6673],\n",
      "        [2.9851, 2.7623],\n",
      "        [2.3021, 2.7393],\n",
      "        [2.6834, 2.2002],\n",
      "        [2.2629, 3.1977],\n",
      "        [2.4612, 2.8592],\n",
      "        [2.9899, 3.2517],\n",
      "        [2.8067, 2.1061],\n",
      "        [2.2752, 2.3611],\n",
      "        [2.4106, 2.2821],\n",
      "        [2.7795, 2.7672],\n",
      "        [2.6960, 2.4581],\n",
      "        [2.7428, 2.3456],\n",
      "        [2.6528, 2.7541],\n",
      "        [2.5234, 2.9083],\n",
      "        [2.3377, 2.9072]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3307, 2.6533],\n",
      "        [2.7455, 2.1980],\n",
      "        [2.8492, 2.1827],\n",
      "        [2.7624, 3.1675],\n",
      "        [2.2913, 2.3008],\n",
      "        [1.9924, 2.7108],\n",
      "        [2.4957, 2.4338],\n",
      "        [2.7215, 2.2219],\n",
      "        [2.8836, 2.5848],\n",
      "        [2.3239, 2.3120],\n",
      "        [2.7955, 2.6092],\n",
      "        [2.5986, 2.3255],\n",
      "        [2.6094, 2.8755],\n",
      "        [2.5097, 2.6324],\n",
      "        [2.4732, 2.7369],\n",
      "        [2.2994, 2.4186],\n",
      "        [2.2828, 2.7287],\n",
      "        [2.6282, 2.2086],\n",
      "        [2.5999, 2.1895],\n",
      "        [2.8212, 2.7468],\n",
      "        [2.4482, 2.4884],\n",
      "        [2.6555, 2.3224],\n",
      "        [2.6128, 2.7319],\n",
      "        [2.7963, 2.3231],\n",
      "        [2.6406, 2.6972],\n",
      "        [2.7603, 2.5715],\n",
      "        [2.6954, 2.5055],\n",
      "        [2.3778, 2.2123],\n",
      "        [2.8495, 1.8420],\n",
      "        [2.9907, 2.1172],\n",
      "        [2.4737, 2.8050],\n",
      "        [2.5046, 2.6503],\n",
      "        [2.3618, 2.5531],\n",
      "        [2.5178, 2.4719],\n",
      "        [2.5729, 2.4948],\n",
      "        [2.3754, 2.2153],\n",
      "        [2.7347, 2.6841],\n",
      "        [2.3956, 2.6741],\n",
      "        [2.6791, 2.6169],\n",
      "        [2.4507, 2.2418],\n",
      "        [2.7448, 2.6282],\n",
      "        [2.6318, 2.9326],\n",
      "        [2.5823, 2.8321],\n",
      "        [2.3046, 2.4848],\n",
      "        [2.8636, 2.5802],\n",
      "        [2.5010, 2.6601],\n",
      "        [2.5552, 2.7606],\n",
      "        [2.5530, 2.7248],\n",
      "        [2.5969, 2.4518],\n",
      "        [2.0951, 2.8322],\n",
      "        [2.3765, 2.7177],\n",
      "        [2.5837, 2.1864],\n",
      "        [2.6405, 2.5214],\n",
      "        [2.2902, 2.3688],\n",
      "        [2.3298, 2.6507],\n",
      "        [2.6895, 2.4250],\n",
      "        [2.3276, 3.1834],\n",
      "        [2.4752, 2.5717],\n",
      "        [2.6323, 2.4651],\n",
      "        [2.5832, 2.5538],\n",
      "        [2.0243, 2.5120],\n",
      "        [2.7911, 2.4088],\n",
      "        [2.5389, 2.4244],\n",
      "        [2.6620, 2.5082],\n",
      "        [2.6603, 2.5470],\n",
      "        [2.8832, 2.0544],\n",
      "        [2.5845, 2.4697],\n",
      "        [2.3917, 2.7920],\n",
      "        [2.5632, 2.2182],\n",
      "        [2.2467, 2.9457],\n",
      "        [3.0656, 2.4612],\n",
      "        [2.4414, 2.4342],\n",
      "        [2.5193, 2.8230],\n",
      "        [2.2398, 2.9102],\n",
      "        [2.5867, 2.8658],\n",
      "        [2.2432, 2.3015],\n",
      "        [2.2534, 2.8541],\n",
      "        [2.4888, 2.5993],\n",
      "        [2.5592, 2.8149],\n",
      "        [2.3540, 2.5046],\n",
      "        [2.1876, 2.3138],\n",
      "        [2.7127, 2.8001],\n",
      "        [2.5574, 2.3948],\n",
      "        [2.4019, 2.4634],\n",
      "        [2.7187, 2.6434],\n",
      "        [2.6202, 2.5726],\n",
      "        [2.4610, 2.6105],\n",
      "        [2.2092, 3.0870],\n",
      "        [2.4604, 2.4329],\n",
      "        [2.7202, 2.2873],\n",
      "        [2.8043, 2.4803],\n",
      "        [2.4109, 2.4287],\n",
      "        [2.8602, 2.5466],\n",
      "        [2.1288, 2.1147],\n",
      "        [2.6786, 2.9024],\n",
      "        [2.6365, 3.0546],\n",
      "        [2.7640, 1.9038],\n",
      "        [2.2109, 2.6573],\n",
      "        [2.4673, 2.6778],\n",
      "        [2.6370, 2.6854]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 65 complete in 0:02:59.472360; est. finish at 2021-11-29 21:55:56.949963\n",
      "Validation: 0.49 train | 0.518 dev\n",
      "### Epoch: 66 ###\n",
      "y:  tensor([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7529, 2.2985],\n",
      "        [3.0638, 2.5397],\n",
      "        [2.5360, 2.5429],\n",
      "        [2.4588, 2.1383],\n",
      "        [2.7208, 2.4049],\n",
      "        [2.8112, 2.6840],\n",
      "        [2.8448, 1.8420],\n",
      "        [2.7420, 2.5810],\n",
      "        [2.5893, 2.5949],\n",
      "        [2.4704, 2.7562],\n",
      "        [2.2904, 2.9608],\n",
      "        [2.8537, 1.9960],\n",
      "        [2.3903, 2.4106],\n",
      "        [2.4864, 2.3814],\n",
      "        [2.3264, 2.5249],\n",
      "        [2.0912, 2.5193],\n",
      "        [2.5614, 2.2048],\n",
      "        [2.3163, 2.8371],\n",
      "        [2.5488, 2.1860],\n",
      "        [2.5349, 2.6966],\n",
      "        [2.2629, 2.7637],\n",
      "        [3.2492, 2.5008],\n",
      "        [2.5132, 2.4034],\n",
      "        [2.6517, 2.1781],\n",
      "        [2.7427, 2.7625],\n",
      "        [2.2698, 2.3779],\n",
      "        [3.1700, 2.5905],\n",
      "        [2.5077, 2.1631],\n",
      "        [2.4865, 2.6028],\n",
      "        [2.1947, 2.9011],\n",
      "        [2.4057, 2.1340],\n",
      "        [2.7670, 2.7420],\n",
      "        [2.4668, 2.7728],\n",
      "        [2.1024, 2.1937],\n",
      "        [2.5657, 2.6741],\n",
      "        [2.3959, 2.9262],\n",
      "        [2.9869, 2.5032],\n",
      "        [2.1406, 2.9991],\n",
      "        [2.2802, 2.4600],\n",
      "        [2.7898, 2.1769],\n",
      "        [2.8835, 2.0393],\n",
      "        [2.8132, 1.9979],\n",
      "        [2.5710, 2.3185],\n",
      "        [3.0233, 2.2613],\n",
      "        [2.2933, 2.5266],\n",
      "        [2.2532, 2.6815],\n",
      "        [2.6358, 2.2745],\n",
      "        [2.8258, 2.7049],\n",
      "        [2.8290, 2.5561],\n",
      "        [2.6120, 2.9642],\n",
      "        [2.8554, 2.5739],\n",
      "        [2.7631, 2.1550],\n",
      "        [1.9488, 2.7705],\n",
      "        [2.4760, 3.0590],\n",
      "        [2.8936, 2.7470],\n",
      "        [2.4482, 2.9110],\n",
      "        [2.5526, 3.2591],\n",
      "        [2.0022, 2.4448],\n",
      "        [2.8415, 2.5810],\n",
      "        [2.5012, 2.8876],\n",
      "        [2.9597, 2.6073],\n",
      "        [2.5801, 2.9704],\n",
      "        [2.0200, 2.7045],\n",
      "        [2.4178, 2.3850],\n",
      "        [2.0198, 2.5416],\n",
      "        [2.5919, 3.1106],\n",
      "        [2.6470, 2.5584],\n",
      "        [2.3898, 2.6323],\n",
      "        [2.6695, 2.3791],\n",
      "        [2.4210, 2.6429],\n",
      "        [2.5071, 1.9222],\n",
      "        [2.4709, 2.5734],\n",
      "        [2.6053, 2.7375],\n",
      "        [2.6008, 2.1600],\n",
      "        [2.5750, 2.8377],\n",
      "        [2.1839, 2.8289],\n",
      "        [2.7050, 2.5979],\n",
      "        [2.5618, 2.7671],\n",
      "        [2.5931, 2.8471],\n",
      "        [2.7021, 2.4406],\n",
      "        [2.3296, 2.4880],\n",
      "        [2.4101, 2.7563],\n",
      "        [2.4069, 2.6694],\n",
      "        [2.3079, 3.0322],\n",
      "        [2.6038, 2.4673],\n",
      "        [2.2223, 2.7153],\n",
      "        [2.5739, 2.5840],\n",
      "        [2.8865, 2.5782],\n",
      "        [2.5296, 2.3363],\n",
      "        [2.5752, 2.5898],\n",
      "        [2.5259, 2.5469],\n",
      "        [2.5117, 2.2067],\n",
      "        [2.8311, 2.6433],\n",
      "        [2.7616, 2.5894],\n",
      "        [2.9869, 2.0769],\n",
      "        [2.6634, 2.4768],\n",
      "        [2.9052, 2.5882],\n",
      "        [2.6020, 2.1972],\n",
      "        [2.6554, 2.8394],\n",
      "        [2.6847, 2.3632]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7694, 2.8998],\n",
      "        [2.3613, 2.7222],\n",
      "        [3.0367, 2.3708],\n",
      "        [2.4532, 2.8333],\n",
      "        [2.5678, 2.5014],\n",
      "        [2.2516, 2.3813],\n",
      "        [2.4019, 2.6862],\n",
      "        [2.7492, 2.6072],\n",
      "        [2.4692, 2.4182],\n",
      "        [2.4435, 2.7713],\n",
      "        [2.4417, 2.6613],\n",
      "        [2.5431, 2.7049],\n",
      "        [2.7326, 2.7238],\n",
      "        [2.5156, 2.5334],\n",
      "        [2.5389, 2.3939],\n",
      "        [2.5495, 2.2851],\n",
      "        [2.0526, 2.3958],\n",
      "        [2.4962, 2.8157],\n",
      "        [2.2385, 2.5378],\n",
      "        [2.4971, 2.3420],\n",
      "        [2.8334, 2.8932],\n",
      "        [2.4839, 2.4741],\n",
      "        [2.9302, 2.7276],\n",
      "        [2.6497, 2.4692],\n",
      "        [2.4292, 3.0340],\n",
      "        [2.7013, 3.1077],\n",
      "        [2.6338, 2.5018],\n",
      "        [2.6907, 2.0911],\n",
      "        [2.4967, 2.5701],\n",
      "        [2.6479, 2.5317],\n",
      "        [2.8324, 2.4123],\n",
      "        [2.6593, 2.5247],\n",
      "        [2.5911, 2.2615],\n",
      "        [2.5390, 2.5278],\n",
      "        [2.6458, 2.6477],\n",
      "        [2.3850, 2.5590],\n",
      "        [3.0184, 2.7816],\n",
      "        [1.9099, 2.5358],\n",
      "        [2.8232, 2.6174],\n",
      "        [2.2968, 2.8602],\n",
      "        [2.5368, 2.5152],\n",
      "        [2.5623, 2.4964],\n",
      "        [2.6568, 2.6372],\n",
      "        [2.2502, 2.4543],\n",
      "        [2.1123, 2.5435],\n",
      "        [2.5975, 2.7570],\n",
      "        [2.2831, 2.7316],\n",
      "        [2.4957, 2.5933],\n",
      "        [2.7748, 2.5665],\n",
      "        [2.8733, 2.6378],\n",
      "        [2.7163, 2.1223],\n",
      "        [2.8394, 2.7096],\n",
      "        [2.4497, 2.1905],\n",
      "        [2.3030, 2.6750],\n",
      "        [2.6948, 2.7092],\n",
      "        [2.0499, 2.8162],\n",
      "        [2.3545, 1.8825],\n",
      "        [2.7222, 1.9613],\n",
      "        [2.7186, 2.3856],\n",
      "        [2.9494, 3.0084],\n",
      "        [2.6630, 2.6402],\n",
      "        [2.5326, 2.7959],\n",
      "        [2.8321, 2.4827],\n",
      "        [2.5009, 2.4237],\n",
      "        [1.9689, 2.7157],\n",
      "        [2.9186, 2.6109],\n",
      "        [3.0400, 3.0696],\n",
      "        [2.2030, 2.5838],\n",
      "        [2.6290, 2.6035],\n",
      "        [2.7310, 2.7590],\n",
      "        [2.3655, 2.6397],\n",
      "        [2.4591, 2.4189],\n",
      "        [2.5669, 2.4123],\n",
      "        [2.0789, 2.6554],\n",
      "        [2.5262, 2.3674],\n",
      "        [2.3140, 2.7607],\n",
      "        [2.7142, 2.4585],\n",
      "        [2.4507, 2.7344],\n",
      "        [2.9747, 2.3337],\n",
      "        [2.4145, 3.1302],\n",
      "        [2.7831, 2.3787],\n",
      "        [2.4798, 2.8839],\n",
      "        [2.7694, 2.4384],\n",
      "        [2.8115, 2.5255],\n",
      "        [2.2752, 2.6733],\n",
      "        [2.7709, 3.0423],\n",
      "        [2.3400, 2.1529],\n",
      "        [2.7169, 2.6210],\n",
      "        [2.8655, 2.6861],\n",
      "        [2.5152, 2.3501],\n",
      "        [2.2777, 3.0073],\n",
      "        [2.9883, 1.8995],\n",
      "        [2.3285, 2.2902],\n",
      "        [2.6376, 2.8224],\n",
      "        [2.8106, 2.7514],\n",
      "        [2.5877, 2.4063],\n",
      "        [2.6510, 2.1451],\n",
      "        [2.5514, 2.5985],\n",
      "        [3.0527, 2.9096],\n",
      "        [2.2156, 1.9802]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3157, 2.8467],\n",
      "        [2.6176, 2.3594],\n",
      "        [2.5539, 1.9204],\n",
      "        [2.4173, 1.9648],\n",
      "        [2.2314, 2.5585],\n",
      "        [2.2842, 2.4917],\n",
      "        [2.7000, 2.3445],\n",
      "        [2.8563, 2.8674],\n",
      "        [2.4430, 2.7113],\n",
      "        [2.3321, 2.5338],\n",
      "        [2.3140, 2.1837],\n",
      "        [2.8549, 2.9441],\n",
      "        [2.5440, 2.2001],\n",
      "        [2.2477, 2.8487],\n",
      "        [2.6580, 2.4640],\n",
      "        [2.7192, 2.6242],\n",
      "        [2.6681, 2.9537],\n",
      "        [2.6869, 2.7303],\n",
      "        [2.2520, 2.1872],\n",
      "        [2.5260, 2.6502],\n",
      "        [2.6785, 2.4821],\n",
      "        [2.1062, 2.7946],\n",
      "        [2.2590, 2.6820],\n",
      "        [2.6400, 2.8304],\n",
      "        [2.5214, 2.6546],\n",
      "        [2.7479, 2.7471],\n",
      "        [2.4586, 2.0249],\n",
      "        [2.7852, 2.4108],\n",
      "        [2.6798, 1.7574],\n",
      "        [2.6396, 3.0517],\n",
      "        [2.6515, 2.6743],\n",
      "        [2.4190, 2.5762],\n",
      "        [2.4086, 2.3638],\n",
      "        [2.4541, 2.4250],\n",
      "        [2.5286, 2.2749],\n",
      "        [2.8214, 2.4908],\n",
      "        [2.5161, 2.3627],\n",
      "        [2.1900, 2.6413],\n",
      "        [2.9031, 2.5334],\n",
      "        [2.4597, 2.2062],\n",
      "        [2.2395, 2.6505],\n",
      "        [2.3885, 2.6986],\n",
      "        [2.2879, 2.3158],\n",
      "        [2.6830, 2.7521],\n",
      "        [2.5041, 2.5267],\n",
      "        [1.9789, 2.3652],\n",
      "        [2.4569, 2.5748],\n",
      "        [2.7494, 2.9256],\n",
      "        [2.5809, 2.7049],\n",
      "        [2.5491, 2.5137],\n",
      "        [2.0145, 2.9731],\n",
      "        [2.3519, 2.6676],\n",
      "        [2.4129, 3.1540],\n",
      "        [2.3989, 2.3131],\n",
      "        [2.3968, 2.6138],\n",
      "        [2.4596, 2.4926],\n",
      "        [2.0929, 2.8490],\n",
      "        [2.4783, 2.7287],\n",
      "        [2.2303, 2.7424],\n",
      "        [2.5543, 2.6458],\n",
      "        [2.6657, 2.5450],\n",
      "        [2.4696, 2.2095],\n",
      "        [2.2571, 2.5497],\n",
      "        [3.1830, 2.7394],\n",
      "        [2.6090, 2.8057],\n",
      "        [2.6695, 2.3289],\n",
      "        [2.6917, 2.1877],\n",
      "        [3.0428, 2.4427],\n",
      "        [2.4545, 2.3928],\n",
      "        [2.2770, 2.5486],\n",
      "        [2.4713, 2.1092],\n",
      "        [2.3581, 2.0282],\n",
      "        [2.4952, 2.8886],\n",
      "        [2.8284, 1.9873],\n",
      "        [2.9048, 2.4236],\n",
      "        [2.0203, 2.4864],\n",
      "        [2.2986, 2.5029],\n",
      "        [2.1629, 2.6469],\n",
      "        [2.5117, 2.7738],\n",
      "        [2.6884, 2.2180],\n",
      "        [2.7606, 2.6295],\n",
      "        [2.6344, 2.6603],\n",
      "        [2.4852, 2.3438],\n",
      "        [2.5659, 2.8650],\n",
      "        [2.5515, 2.6951],\n",
      "        [2.6770, 2.3285],\n",
      "        [2.9307, 2.7940],\n",
      "        [2.4861, 2.8255],\n",
      "        [2.5371, 2.7540],\n",
      "        [2.8266, 2.1288],\n",
      "        [1.9982, 2.2229],\n",
      "        [2.4085, 2.5022],\n",
      "        [2.2982, 2.4817],\n",
      "        [2.4291, 2.8203],\n",
      "        [2.3365, 2.8427],\n",
      "        [2.3618, 2.0730],\n",
      "        [2.5938, 2.5383],\n",
      "        [2.5712, 2.9067],\n",
      "        [2.1238, 2.3096],\n",
      "        [3.4729, 2.7503]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.1626, 2.7146],\n",
      "        [3.0799, 2.7302],\n",
      "        [2.4542, 2.6306],\n",
      "        [2.5533, 2.5533],\n",
      "        [2.9358, 2.7397],\n",
      "        [2.4779, 2.4916],\n",
      "        [2.1289, 2.5326],\n",
      "        [2.9441, 2.6796],\n",
      "        [2.4387, 2.7500],\n",
      "        [2.4932, 2.2015],\n",
      "        [2.7744, 2.9267],\n",
      "        [2.2828, 2.2273],\n",
      "        [2.8551, 2.2499],\n",
      "        [2.5798, 2.4866],\n",
      "        [2.4958, 2.5178],\n",
      "        [2.6302, 2.5313],\n",
      "        [2.6238, 2.8120],\n",
      "        [1.9808, 2.6841],\n",
      "        [2.7040, 2.4948],\n",
      "        [2.7572, 2.5530],\n",
      "        [2.4533, 2.8677],\n",
      "        [2.5318, 2.5952],\n",
      "        [2.3872, 2.7673],\n",
      "        [2.5893, 2.3388],\n",
      "        [2.8100, 2.4123],\n",
      "        [2.5245, 2.2447],\n",
      "        [2.6957, 2.9230],\n",
      "        [2.4505, 2.7717],\n",
      "        [2.1503, 2.4418],\n",
      "        [2.2950, 2.2478],\n",
      "        [2.5612, 2.5064],\n",
      "        [2.3698, 2.3532],\n",
      "        [2.6747, 2.5047],\n",
      "        [2.6316, 2.5135],\n",
      "        [2.6408, 2.2447],\n",
      "        [2.2097, 2.4055],\n",
      "        [2.9417, 2.5685],\n",
      "        [2.3355, 2.8929],\n",
      "        [2.5249, 3.3876],\n",
      "        [2.7439, 2.3593],\n",
      "        [2.4057, 2.6664],\n",
      "        [2.7122, 2.8720],\n",
      "        [2.6073, 2.7254],\n",
      "        [2.6055, 2.7461],\n",
      "        [2.3183, 2.6569],\n",
      "        [2.1992, 2.6217],\n",
      "        [2.9287, 2.5563],\n",
      "        [2.8003, 2.8319],\n",
      "        [2.4292, 2.5496],\n",
      "        [2.6026, 2.3495],\n",
      "        [2.4698, 2.2015],\n",
      "        [2.6566, 2.0643],\n",
      "        [2.3642, 2.5921],\n",
      "        [2.4543, 2.3309],\n",
      "        [2.6242, 2.4161],\n",
      "        [2.6370, 2.3996],\n",
      "        [2.9676, 2.1777],\n",
      "        [2.6830, 2.8552],\n",
      "        [2.2883, 2.6714],\n",
      "        [2.4295, 2.9520],\n",
      "        [2.5360, 2.4562],\n",
      "        [2.2839, 2.7890],\n",
      "        [2.3177, 2.9483],\n",
      "        [2.6942, 2.9600],\n",
      "        [3.0819, 2.2310],\n",
      "        [2.5848, 2.5081],\n",
      "        [2.7663, 2.2750],\n",
      "        [2.6218, 2.0591],\n",
      "        [2.5971, 2.2967],\n",
      "        [2.7125, 2.2010],\n",
      "        [2.5137, 2.8001],\n",
      "        [2.3893, 2.3286],\n",
      "        [2.3670, 2.6161],\n",
      "        [2.4022, 2.3536],\n",
      "        [2.5356, 2.5420],\n",
      "        [2.8720, 2.2909],\n",
      "        [2.9203, 2.3763],\n",
      "        [2.4113, 1.9738],\n",
      "        [2.6556, 2.3419],\n",
      "        [2.5796, 2.4992],\n",
      "        [2.2653, 2.2216],\n",
      "        [2.4563, 2.5566],\n",
      "        [2.2998, 2.0369],\n",
      "        [2.9274, 1.9979],\n",
      "        [2.9062, 2.6631],\n",
      "        [2.6579, 2.7917],\n",
      "        [2.3563, 1.8665],\n",
      "        [2.2661, 2.4912],\n",
      "        [2.2672, 2.8220],\n",
      "        [2.2786, 2.9497],\n",
      "        [2.7194, 2.7691],\n",
      "        [2.6281, 2.3686],\n",
      "        [2.4534, 2.3240],\n",
      "        [2.8713, 2.5092],\n",
      "        [2.1994, 2.8200],\n",
      "        [2.9805, 2.7127],\n",
      "        [2.0387, 2.5588],\n",
      "        [2.3010, 2.0502],\n",
      "        [2.8143, 2.4115],\n",
      "        [2.8210, 2.7521]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.4620, 2.4691],\n",
      "        [2.7967, 2.5224],\n",
      "        [2.2348, 2.5135],\n",
      "        [2.6191, 2.1708],\n",
      "        [2.3482, 2.5767],\n",
      "        [2.5522, 2.5056],\n",
      "        [2.0595, 2.6805],\n",
      "        [2.4138, 2.9486],\n",
      "        [2.6956, 2.8691],\n",
      "        [2.6116, 2.4716],\n",
      "        [2.4714, 2.2736],\n",
      "        [2.1323, 2.2743],\n",
      "        [2.1893, 2.5075],\n",
      "        [3.1130, 2.6623],\n",
      "        [2.6487, 2.5385],\n",
      "        [2.5531, 2.7626],\n",
      "        [2.7491, 2.2545],\n",
      "        [2.5330, 2.4240],\n",
      "        [2.6782, 2.7017],\n",
      "        [2.5068, 2.4289],\n",
      "        [2.5076, 2.4672],\n",
      "        [2.8550, 2.6078],\n",
      "        [2.3848, 2.6563],\n",
      "        [2.4474, 2.6758],\n",
      "        [2.7751, 2.6492],\n",
      "        [2.4974, 2.6133],\n",
      "        [2.5687, 2.7006],\n",
      "        [2.5429, 2.7433],\n",
      "        [2.5765, 2.7884],\n",
      "        [2.1373, 2.3863],\n",
      "        [2.9594, 2.8512],\n",
      "        [2.6488, 2.3430],\n",
      "        [2.5126, 2.4393],\n",
      "        [2.2675, 2.3319],\n",
      "        [2.6601, 2.5375],\n",
      "        [2.6306, 2.6124],\n",
      "        [2.2241, 2.3559],\n",
      "        [2.5170, 2.7517],\n",
      "        [2.5505, 2.4647],\n",
      "        [2.6707, 2.1353],\n",
      "        [2.4354, 2.3700],\n",
      "        [2.5400, 2.1634],\n",
      "        [2.4983, 2.1750],\n",
      "        [2.7493, 2.8112],\n",
      "        [2.3967, 2.7765],\n",
      "        [2.4907, 2.5479],\n",
      "        [2.7169, 2.6071],\n",
      "        [2.6090, 2.3833],\n",
      "        [2.0912, 2.3853],\n",
      "        [2.6595, 3.0055],\n",
      "        [2.8273, 2.2599],\n",
      "        [2.6306, 2.6409],\n",
      "        [2.3587, 2.8501],\n",
      "        [2.8173, 2.6191],\n",
      "        [2.5171, 2.4358],\n",
      "        [2.3489, 2.5763],\n",
      "        [2.2938, 2.2843],\n",
      "        [2.9339, 2.7640],\n",
      "        [2.6418, 2.6318],\n",
      "        [2.6263, 2.4414],\n",
      "        [2.1506, 2.7133],\n",
      "        [2.7609, 2.6464],\n",
      "        [2.3783, 2.3223],\n",
      "        [2.9188, 2.4779],\n",
      "        [2.5940, 2.2584],\n",
      "        [2.5332, 2.2551],\n",
      "        [2.8185, 2.8299],\n",
      "        [2.5791, 2.4627],\n",
      "        [2.4933, 2.8394],\n",
      "        [2.3665, 2.5773],\n",
      "        [2.3920, 2.3626],\n",
      "        [2.3942, 2.5861],\n",
      "        [2.3782, 2.7925],\n",
      "        [2.1739, 2.3610],\n",
      "        [2.5881, 2.3944],\n",
      "        [2.4972, 2.6752],\n",
      "        [2.2904, 2.6845],\n",
      "        [3.0563, 1.9930],\n",
      "        [2.7369, 2.7646],\n",
      "        [2.6116, 2.5760],\n",
      "        [2.7624, 2.5001],\n",
      "        [2.6471, 2.8793],\n",
      "        [2.6750, 2.2876],\n",
      "        [2.4919, 2.5253],\n",
      "        [2.4332, 2.7621],\n",
      "        [2.6342, 2.8980],\n",
      "        [2.3809, 2.8650],\n",
      "        [2.5129, 2.6632],\n",
      "        [1.9293, 2.6318],\n",
      "        [2.7090, 2.7537],\n",
      "        [2.4930, 2.2109],\n",
      "        [2.8044, 3.0562],\n",
      "        [2.4229, 2.5975],\n",
      "        [2.5441, 2.8153],\n",
      "        [2.4264, 2.2069],\n",
      "        [3.0558, 2.6588],\n",
      "        [2.6257, 2.4176],\n",
      "        [2.5951, 2.4056],\n",
      "        [1.8597, 2.1244],\n",
      "        [2.8953, 2.6186]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 70 complete in 0:03:13.545547; est. finish at 2021-11-29 21:55:57.332263\n",
      "Validation: 0.482 train | 0.47 dev\n",
      "### Epoch: 71 ###\n",
      "y:  tensor([1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3263, 2.5562],\n",
      "        [2.9658, 2.3892],\n",
      "        [2.7250, 3.1137],\n",
      "        [2.2701, 2.8137],\n",
      "        [2.8180, 2.1890],\n",
      "        [2.6104, 2.3204],\n",
      "        [2.5827, 2.6188],\n",
      "        [2.6791, 2.6270],\n",
      "        [2.6788, 2.2668],\n",
      "        [2.4587, 2.8056],\n",
      "        [2.5426, 2.8262],\n",
      "        [2.5784, 2.8558],\n",
      "        [2.7103, 2.6156],\n",
      "        [2.6719, 2.4517],\n",
      "        [2.1401, 2.2603],\n",
      "        [2.3449, 2.6044],\n",
      "        [2.9448, 2.6626],\n",
      "        [2.5932, 2.5295],\n",
      "        [2.2903, 2.8054],\n",
      "        [2.4558, 2.7076],\n",
      "        [2.6067, 2.3487],\n",
      "        [2.7342, 2.7192],\n",
      "        [2.7720, 2.4974],\n",
      "        [2.8383, 1.8857],\n",
      "        [2.7743, 2.7349],\n",
      "        [2.5875, 3.1759],\n",
      "        [2.8182, 2.3313],\n",
      "        [2.2922, 2.7258],\n",
      "        [2.9225, 2.1963],\n",
      "        [2.3766, 2.5533],\n",
      "        [2.6461, 2.5765],\n",
      "        [2.5024, 2.6832],\n",
      "        [2.6727, 2.5620],\n",
      "        [2.7359, 2.5286],\n",
      "        [2.2674, 2.4118],\n",
      "        [2.1650, 2.4441],\n",
      "        [2.9382, 2.1811],\n",
      "        [2.8352, 2.3543],\n",
      "        [2.2818, 2.5304],\n",
      "        [2.6625, 2.3825],\n",
      "        [2.2454, 3.1173],\n",
      "        [2.3385, 2.3128],\n",
      "        [2.1391, 2.0519],\n",
      "        [2.9203, 2.7447],\n",
      "        [2.7862, 2.6934],\n",
      "        [2.2196, 2.1994],\n",
      "        [2.4319, 2.5577],\n",
      "        [2.8182, 2.8945],\n",
      "        [2.5976, 3.0017],\n",
      "        [2.4787, 2.4349],\n",
      "        [2.2832, 2.2365],\n",
      "        [2.6829, 2.3962],\n",
      "        [2.6297, 2.7708],\n",
      "        [2.7038, 2.7463],\n",
      "        [2.3507, 2.5779],\n",
      "        [2.1378, 2.5998],\n",
      "        [2.4830, 2.7715],\n",
      "        [2.7132, 2.4256],\n",
      "        [2.6218, 2.1999],\n",
      "        [2.1781, 2.7425],\n",
      "        [2.8757, 2.3216],\n",
      "        [2.4505, 2.8701],\n",
      "        [2.5851, 2.6872],\n",
      "        [2.8221, 2.4074],\n",
      "        [2.1671, 2.6040],\n",
      "        [2.6481, 2.6729],\n",
      "        [2.2701, 2.1644],\n",
      "        [2.5751, 2.5629],\n",
      "        [2.7510, 2.1582],\n",
      "        [2.5475, 2.5257],\n",
      "        [2.4801, 2.5545],\n",
      "        [2.9112, 2.0851],\n",
      "        [2.8535, 2.6904],\n",
      "        [2.3045, 2.6451],\n",
      "        [3.1147, 2.5571],\n",
      "        [2.4888, 2.5542],\n",
      "        [2.2734, 2.8348],\n",
      "        [2.9740, 2.2781],\n",
      "        [2.4515, 2.6384],\n",
      "        [2.3889, 3.1701],\n",
      "        [2.2492, 2.8611],\n",
      "        [2.6067, 2.4284],\n",
      "        [2.6792, 2.2765],\n",
      "        [2.0870, 2.6121],\n",
      "        [2.6612, 2.6356],\n",
      "        [2.0495, 2.9104],\n",
      "        [1.9037, 2.1510],\n",
      "        [2.0072, 2.4321],\n",
      "        [2.2304, 2.2058],\n",
      "        [2.3682, 2.4531],\n",
      "        [2.3562, 2.5067],\n",
      "        [2.3724, 2.8016],\n",
      "        [2.5364, 2.3953],\n",
      "        [2.8519, 2.6108],\n",
      "        [2.7412, 2.5972],\n",
      "        [2.1704, 2.5873],\n",
      "        [2.4014, 2.7428],\n",
      "        [1.9876, 3.1475],\n",
      "        [2.5122, 2.3279],\n",
      "        [2.5529, 2.7607]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.2667, 2.7630],\n",
      "        [2.5505, 2.7612],\n",
      "        [2.7364, 2.7660],\n",
      "        [2.4080, 2.4601],\n",
      "        [2.5290, 2.4982],\n",
      "        [2.2947, 2.3422],\n",
      "        [2.4198, 2.6039],\n",
      "        [2.3660, 2.9661],\n",
      "        [2.4394, 2.0518],\n",
      "        [2.4314, 2.7644],\n",
      "        [2.5601, 2.6814],\n",
      "        [2.5725, 2.4614],\n",
      "        [2.3836, 1.7433],\n",
      "        [2.4344, 2.8183],\n",
      "        [2.6639, 1.9806],\n",
      "        [2.6987, 1.9075],\n",
      "        [2.5020, 2.7050],\n",
      "        [2.2255, 2.9303],\n",
      "        [2.2985, 2.6767],\n",
      "        [2.3901, 2.8504],\n",
      "        [2.1282, 2.8410],\n",
      "        [2.1579, 2.6753],\n",
      "        [2.6232, 2.3754],\n",
      "        [3.0733, 2.4306],\n",
      "        [1.9440, 2.6622],\n",
      "        [2.3947, 2.4190],\n",
      "        [2.7907, 2.5209],\n",
      "        [2.0966, 2.5293],\n",
      "        [2.4781, 2.7041],\n",
      "        [2.7048, 2.4184],\n",
      "        [2.2685, 2.9953],\n",
      "        [2.5552, 2.6904],\n",
      "        [2.3891, 2.4471],\n",
      "        [2.5171, 2.6077],\n",
      "        [2.7469, 2.3544],\n",
      "        [2.5801, 2.6070],\n",
      "        [2.8599, 2.3977],\n",
      "        [2.6285, 2.0285],\n",
      "        [2.5805, 2.7715],\n",
      "        [2.6472, 2.3888],\n",
      "        [2.4521, 2.6192],\n",
      "        [2.4797, 2.8150],\n",
      "        [2.7504, 2.4720],\n",
      "        [2.6201, 2.6815],\n",
      "        [2.3146, 2.5663],\n",
      "        [2.7127, 1.9076],\n",
      "        [2.5782, 2.3072],\n",
      "        [2.5682, 2.4238],\n",
      "        [2.6310, 2.8666],\n",
      "        [3.0058, 2.1130],\n",
      "        [2.9179, 2.8466],\n",
      "        [2.4674, 1.7414],\n",
      "        [2.8291, 2.6279],\n",
      "        [2.6471, 2.3980],\n",
      "        [2.5741, 2.7232],\n",
      "        [2.4705, 2.3811],\n",
      "        [2.4414, 2.6217],\n",
      "        [2.4414, 2.3404],\n",
      "        [2.6081, 2.2450],\n",
      "        [2.5904, 2.9471],\n",
      "        [2.4206, 1.8486],\n",
      "        [2.7965, 2.6286],\n",
      "        [2.3992, 2.4671],\n",
      "        [3.0314, 2.4532],\n",
      "        [2.3005, 2.6388],\n",
      "        [2.7671, 2.4050],\n",
      "        [2.7054, 2.6856],\n",
      "        [2.8688, 2.7801],\n",
      "        [2.6838, 2.4330],\n",
      "        [2.5928, 2.8665],\n",
      "        [2.4796, 2.7516],\n",
      "        [2.4867, 2.5434],\n",
      "        [2.4129, 2.8157],\n",
      "        [2.2376, 2.4272],\n",
      "        [3.2304, 2.9251],\n",
      "        [1.9858, 2.7051],\n",
      "        [2.6551, 2.9315],\n",
      "        [2.1377, 2.5640],\n",
      "        [2.5282, 2.9468],\n",
      "        [2.8136, 2.4682],\n",
      "        [2.3667, 2.0185],\n",
      "        [2.5206, 2.4509],\n",
      "        [2.2277, 2.2727],\n",
      "        [2.5886, 2.5854],\n",
      "        [2.6764, 2.6144],\n",
      "        [2.4080, 2.5278],\n",
      "        [2.6719, 2.2069],\n",
      "        [2.5003, 2.4931],\n",
      "        [2.5424, 2.7919],\n",
      "        [2.3631, 2.2556],\n",
      "        [2.7249, 2.2516],\n",
      "        [2.0493, 2.2841],\n",
      "        [2.0409, 2.4122],\n",
      "        [2.8080, 2.7417],\n",
      "        [2.6962, 2.4417],\n",
      "        [2.5664, 2.8049],\n",
      "        [2.4860, 2.4118],\n",
      "        [3.0628, 2.4639],\n",
      "        [2.9435, 2.2494],\n",
      "        [2.7981, 2.3074]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[3.0254, 2.3249],\n",
      "        [2.2067, 2.9540],\n",
      "        [2.6315, 2.9239],\n",
      "        [2.2902, 2.8008],\n",
      "        [2.5885, 2.6596],\n",
      "        [2.4987, 2.7200],\n",
      "        [2.6445, 2.6214],\n",
      "        [2.4687, 2.7997],\n",
      "        [2.5766, 2.4293],\n",
      "        [2.3979, 2.3465],\n",
      "        [2.5107, 2.5684],\n",
      "        [2.8842, 2.5657],\n",
      "        [2.2986, 2.6998],\n",
      "        [2.3993, 2.6866],\n",
      "        [2.3477, 2.1627],\n",
      "        [2.2195, 2.6563],\n",
      "        [2.4053, 2.4258],\n",
      "        [2.6218, 2.6395],\n",
      "        [2.6267, 2.4648],\n",
      "        [2.5830, 2.9778],\n",
      "        [2.1386, 2.3042],\n",
      "        [2.5565, 2.5460],\n",
      "        [2.5644, 2.7096],\n",
      "        [2.1802, 2.8131],\n",
      "        [2.3025, 2.5440],\n",
      "        [2.5750, 2.5736],\n",
      "        [2.4859, 2.4474],\n",
      "        [2.7794, 2.2921],\n",
      "        [1.9594, 2.4432],\n",
      "        [2.3749, 2.7013],\n",
      "        [2.6040, 2.7335],\n",
      "        [1.8540, 2.4813],\n",
      "        [2.8454, 3.0242],\n",
      "        [1.9909, 2.8387],\n",
      "        [2.3483, 2.5788],\n",
      "        [2.9157, 2.8235],\n",
      "        [2.2535, 2.4400],\n",
      "        [2.2759, 2.1789],\n",
      "        [2.4291, 2.3257],\n",
      "        [2.4675, 2.2138],\n",
      "        [2.4275, 2.5101],\n",
      "        [2.2254, 1.9781],\n",
      "        [2.5697, 1.8444],\n",
      "        [2.5354, 2.6518],\n",
      "        [2.8517, 2.7534],\n",
      "        [2.2368, 2.0706],\n",
      "        [2.6865, 2.4980],\n",
      "        [2.3324, 2.0229],\n",
      "        [2.4157, 2.2734],\n",
      "        [2.5491, 3.1075],\n",
      "        [2.4318, 2.6769],\n",
      "        [2.6390, 2.2465],\n",
      "        [2.9138, 2.5168],\n",
      "        [2.4222, 2.8854],\n",
      "        [2.4443, 2.4632],\n",
      "        [2.3913, 2.8488],\n",
      "        [2.4680, 2.4637],\n",
      "        [2.5507, 2.9394],\n",
      "        [2.4732, 2.6892],\n",
      "        [2.6477, 2.5221],\n",
      "        [2.5980, 3.0284],\n",
      "        [2.7735, 2.5475],\n",
      "        [2.7718, 2.8104],\n",
      "        [2.6380, 2.4843],\n",
      "        [2.4392, 2.6297],\n",
      "        [2.8006, 2.6865],\n",
      "        [2.3247, 2.1107],\n",
      "        [3.0560, 2.6250],\n",
      "        [2.3471, 2.8305],\n",
      "        [2.7369, 2.6534],\n",
      "        [1.7861, 2.8234],\n",
      "        [2.3623, 2.6736],\n",
      "        [2.5169, 2.3521],\n",
      "        [2.2909, 2.4268],\n",
      "        [2.1050, 2.7606],\n",
      "        [2.5928, 2.7311],\n",
      "        [2.6146, 2.6291],\n",
      "        [2.7133, 2.1993],\n",
      "        [2.3259, 2.4566],\n",
      "        [2.5497, 2.4682],\n",
      "        [2.3506, 2.5041],\n",
      "        [2.8239, 2.8524],\n",
      "        [2.4754, 2.4836],\n",
      "        [2.2665, 2.5141],\n",
      "        [2.2816, 2.5740],\n",
      "        [2.4320, 2.1868],\n",
      "        [2.6560, 2.4588],\n",
      "        [2.2375, 2.8475],\n",
      "        [2.3847, 2.6741],\n",
      "        [2.1347, 2.6668],\n",
      "        [2.2998, 2.4891],\n",
      "        [2.3300, 2.3333],\n",
      "        [2.1111, 2.5743],\n",
      "        [2.5451, 2.9160],\n",
      "        [2.3368, 2.6544],\n",
      "        [2.5016, 2.8412],\n",
      "        [2.8298, 2.5086],\n",
      "        [2.3831, 2.5436],\n",
      "        [2.3752, 2.7972],\n",
      "        [2.7567, 2.5418]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8430, 2.5043],\n",
      "        [2.4410, 2.6594],\n",
      "        [2.6116, 2.6186],\n",
      "        [2.4419, 2.5117],\n",
      "        [2.9437, 2.6379],\n",
      "        [2.6097, 2.1597],\n",
      "        [2.8194, 2.5728],\n",
      "        [2.3697, 2.3852],\n",
      "        [2.7970, 2.4887],\n",
      "        [2.4523, 2.5370],\n",
      "        [2.1910, 2.4183],\n",
      "        [2.3726, 2.8664],\n",
      "        [2.6507, 2.4536],\n",
      "        [2.7381, 2.5403],\n",
      "        [2.2520, 2.5540],\n",
      "        [2.2062, 2.4119],\n",
      "        [2.2010, 2.7064],\n",
      "        [2.7639, 2.7748],\n",
      "        [2.9413, 2.5373],\n",
      "        [2.5885, 2.6556],\n",
      "        [2.1696, 2.9627],\n",
      "        [2.6260, 2.6380],\n",
      "        [2.4944, 2.4765],\n",
      "        [2.6289, 2.2503],\n",
      "        [2.5619, 2.6488],\n",
      "        [2.5162, 2.8643],\n",
      "        [2.3188, 2.5311],\n",
      "        [2.7704, 2.0742],\n",
      "        [2.5549, 2.7976],\n",
      "        [2.6690, 2.2355],\n",
      "        [2.6482, 2.6950],\n",
      "        [2.5037, 2.2779],\n",
      "        [2.3447, 2.4385],\n",
      "        [2.3875, 2.6658],\n",
      "        [2.6354, 2.7831],\n",
      "        [2.3606, 2.5080],\n",
      "        [2.0933, 2.3616],\n",
      "        [2.8925, 2.1626],\n",
      "        [2.5967, 2.3355],\n",
      "        [2.0203, 2.0932],\n",
      "        [2.5717, 2.5776],\n",
      "        [2.4027, 2.7425],\n",
      "        [2.1347, 2.6817],\n",
      "        [2.6550, 2.7163],\n",
      "        [2.6404, 2.4832],\n",
      "        [2.5140, 2.7566],\n",
      "        [2.6450, 2.9620],\n",
      "        [2.6962, 2.5977],\n",
      "        [2.6824, 2.5222],\n",
      "        [2.6152, 2.7435],\n",
      "        [2.5021, 2.3588],\n",
      "        [2.5746, 2.0352],\n",
      "        [2.2702, 2.6366],\n",
      "        [2.4373, 1.9715],\n",
      "        [2.5674, 2.2509],\n",
      "        [2.6707, 2.8312],\n",
      "        [2.9867, 3.0053],\n",
      "        [2.5648, 2.9501],\n",
      "        [2.7933, 2.6402],\n",
      "        [2.5921, 2.8008],\n",
      "        [2.7131, 2.4481],\n",
      "        [2.6566, 2.3514],\n",
      "        [2.5392, 2.3052],\n",
      "        [2.1589, 2.6435],\n",
      "        [3.0179, 2.2623],\n",
      "        [2.4994, 2.5722],\n",
      "        [3.0674, 2.2157],\n",
      "        [2.3079, 2.9496],\n",
      "        [2.6720, 3.0641],\n",
      "        [2.6108, 2.5573],\n",
      "        [2.4338, 2.7417],\n",
      "        [2.6928, 2.7940],\n",
      "        [2.4261, 2.9754],\n",
      "        [2.5838, 2.2041],\n",
      "        [2.4849, 3.0855],\n",
      "        [2.9084, 2.5338],\n",
      "        [2.2904, 2.4563],\n",
      "        [2.5208, 2.7208],\n",
      "        [2.7346, 2.6339],\n",
      "        [2.3949, 2.8701],\n",
      "        [2.5521, 2.6702],\n",
      "        [2.3978, 1.9365],\n",
      "        [2.6919, 2.4201],\n",
      "        [2.3811, 2.5496],\n",
      "        [2.9439, 2.1026],\n",
      "        [2.8734, 2.7652],\n",
      "        [3.1525, 2.6961],\n",
      "        [2.5853, 2.6533],\n",
      "        [2.9824, 2.9395],\n",
      "        [2.5115, 2.5774],\n",
      "        [2.5537, 2.1986],\n",
      "        [2.8797, 2.5629],\n",
      "        [2.9113, 2.6067],\n",
      "        [2.6536, 2.8485],\n",
      "        [2.2393, 2.4267],\n",
      "        [2.5710, 1.9222],\n",
      "        [2.6724, 2.3498],\n",
      "        [2.4117, 2.2465],\n",
      "        [2.1274, 3.0978],\n",
      "        [2.5552, 3.1253]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.4428, 2.4995],\n",
      "        [3.0955, 2.9524],\n",
      "        [2.5948, 2.5820],\n",
      "        [2.1766, 2.5528],\n",
      "        [2.7214, 2.4064],\n",
      "        [2.8662, 2.2263],\n",
      "        [2.8709, 2.5583],\n",
      "        [2.6256, 3.1617],\n",
      "        [2.0236, 2.7421],\n",
      "        [2.5450, 2.4284],\n",
      "        [3.0565, 2.6637],\n",
      "        [2.7614, 2.2283],\n",
      "        [2.7367, 2.5296],\n",
      "        [2.8187, 2.4976],\n",
      "        [2.5467, 2.4466],\n",
      "        [2.5337, 2.1456],\n",
      "        [1.8317, 2.4085],\n",
      "        [2.5128, 2.7436],\n",
      "        [2.3881, 2.5926],\n",
      "        [2.8548, 2.4326],\n",
      "        [2.4216, 3.0380],\n",
      "        [2.5231, 2.6316],\n",
      "        [2.7050, 2.2253],\n",
      "        [2.5178, 2.8955],\n",
      "        [2.1508, 2.5370],\n",
      "        [2.7983, 2.9374],\n",
      "        [2.6945, 2.3939],\n",
      "        [2.4044, 2.3329],\n",
      "        [2.3855, 2.7272],\n",
      "        [2.4063, 2.9146],\n",
      "        [2.1949, 2.7411],\n",
      "        [1.9963, 2.4798],\n",
      "        [2.2950, 2.9978],\n",
      "        [2.5791, 2.2901],\n",
      "        [2.6070, 2.6067],\n",
      "        [2.2087, 2.2904],\n",
      "        [2.9023, 2.4213],\n",
      "        [3.0377, 2.2515],\n",
      "        [3.0873, 2.3178],\n",
      "        [2.2711, 2.5966],\n",
      "        [2.6328, 2.4784],\n",
      "        [2.4839, 2.0281],\n",
      "        [2.7097, 2.5907],\n",
      "        [3.0186, 2.3304],\n",
      "        [2.8164, 2.1441],\n",
      "        [2.1278, 2.8954],\n",
      "        [2.6914, 2.5351],\n",
      "        [2.7287, 2.4221],\n",
      "        [2.5606, 2.0607],\n",
      "        [2.8505, 2.8732],\n",
      "        [2.3681, 2.8658],\n",
      "        [2.8190, 2.6822],\n",
      "        [2.2678, 2.5274],\n",
      "        [2.2122, 2.5571],\n",
      "        [2.8001, 2.7289],\n",
      "        [2.8319, 2.7841],\n",
      "        [2.6326, 2.5377],\n",
      "        [2.6207, 2.4549],\n",
      "        [2.1365, 2.3577],\n",
      "        [2.2973, 2.8827],\n",
      "        [2.3061, 2.5355],\n",
      "        [2.4762, 2.3467],\n",
      "        [2.8992, 2.6963],\n",
      "        [2.3591, 2.7098],\n",
      "        [2.3379, 3.2327],\n",
      "        [2.5946, 2.8139],\n",
      "        [2.4031, 2.3108],\n",
      "        [2.4423, 3.0084],\n",
      "        [2.7188, 2.3698],\n",
      "        [2.8128, 2.5136],\n",
      "        [2.5489, 2.3300],\n",
      "        [2.6567, 3.1099],\n",
      "        [2.7313, 2.2253],\n",
      "        [2.4769, 2.7016],\n",
      "        [2.5598, 2.7113],\n",
      "        [2.5704, 2.6246],\n",
      "        [2.5397, 2.6627],\n",
      "        [2.5467, 2.5612],\n",
      "        [2.6571, 2.2390],\n",
      "        [2.5834, 2.7280],\n",
      "        [2.6394, 2.3846],\n",
      "        [2.4959, 2.8361],\n",
      "        [3.0137, 2.4412],\n",
      "        [2.2757, 2.5494],\n",
      "        [2.4909, 2.2804],\n",
      "        [2.9665, 2.4749],\n",
      "        [2.5253, 2.7087],\n",
      "        [2.6041, 2.6868],\n",
      "        [2.5802, 2.9671],\n",
      "        [2.3199, 2.5231],\n",
      "        [3.0067, 2.6920],\n",
      "        [2.5227, 2.5598],\n",
      "        [2.2885, 2.2023],\n",
      "        [2.1992, 2.9842],\n",
      "        [2.7104, 2.9658],\n",
      "        [2.7002, 2.8991],\n",
      "        [2.2112, 3.0785],\n",
      "        [2.5368, 2.2552],\n",
      "        [2.1445, 2.5103],\n",
      "        [2.6621, 2.6371]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 75 complete in 0:03:27.589335; est. finish at 2021-11-29 21:55:57.624463\n",
      "Validation: 0.504 train | 0.514 dev\n",
      "### Epoch: 76 ###\n",
      "y:  tensor([0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7068, 2.6977],\n",
      "        [2.8807, 2.7557],\n",
      "        [2.7291, 2.3206],\n",
      "        [2.3736, 2.6047],\n",
      "        [2.4380, 2.6715],\n",
      "        [2.2426, 2.9721],\n",
      "        [2.2368, 2.4401],\n",
      "        [2.2310, 2.5777],\n",
      "        [2.4128, 2.6949],\n",
      "        [2.7023, 2.7388],\n",
      "        [2.5613, 2.4380],\n",
      "        [2.5385, 2.7959],\n",
      "        [2.6639, 2.4720],\n",
      "        [2.1894, 2.0560],\n",
      "        [2.7589, 2.8759],\n",
      "        [2.7692, 2.6543],\n",
      "        [2.4227, 2.6919],\n",
      "        [2.7190, 2.5688],\n",
      "        [2.4889, 2.4398],\n",
      "        [2.5698, 2.2277],\n",
      "        [2.3789, 2.2494],\n",
      "        [2.8345, 2.6241],\n",
      "        [2.4696, 3.0370],\n",
      "        [2.8671, 2.6938],\n",
      "        [2.4724, 2.3743],\n",
      "        [2.1623, 2.1041],\n",
      "        [2.4740, 2.6452],\n",
      "        [2.7911, 2.7316],\n",
      "        [2.8096, 2.3357],\n",
      "        [2.6771, 2.6244],\n",
      "        [2.7243, 2.5646],\n",
      "        [2.6590, 2.5789],\n",
      "        [2.6047, 2.1091],\n",
      "        [2.1322, 2.4873],\n",
      "        [2.3079, 2.8288],\n",
      "        [2.7139, 2.7296],\n",
      "        [2.8901, 2.7613],\n",
      "        [2.9557, 3.0267],\n",
      "        [2.7968, 2.6772],\n",
      "        [2.2065, 2.5450],\n",
      "        [2.6275, 2.8063],\n",
      "        [2.0846, 2.5330],\n",
      "        [1.9391, 2.8413],\n",
      "        [2.7316, 2.9216],\n",
      "        [2.8146, 2.6736],\n",
      "        [2.7012, 2.4524],\n",
      "        [2.3081, 2.3192],\n",
      "        [2.3062, 2.4820],\n",
      "        [2.5282, 2.5980],\n",
      "        [2.5042, 1.9642],\n",
      "        [2.8281, 2.9764],\n",
      "        [2.1849, 2.5854],\n",
      "        [2.8203, 2.1897],\n",
      "        [2.6218, 3.0713],\n",
      "        [2.9243, 2.8587],\n",
      "        [2.6927, 2.5063],\n",
      "        [2.5695, 2.8242],\n",
      "        [2.7320, 2.4203],\n",
      "        [2.3974, 2.4409],\n",
      "        [2.3455, 2.9697],\n",
      "        [2.4569, 2.5661],\n",
      "        [2.6054, 2.6706],\n",
      "        [2.4321, 2.3747],\n",
      "        [2.1291, 2.6813],\n",
      "        [2.5800, 2.6340],\n",
      "        [2.3646, 2.5956],\n",
      "        [2.4558, 2.6385],\n",
      "        [3.1122, 2.5155],\n",
      "        [2.1403, 2.5454],\n",
      "        [2.4621, 3.4112],\n",
      "        [2.6712, 2.6082],\n",
      "        [2.6264, 2.2518],\n",
      "        [2.5037, 2.7282],\n",
      "        [2.0899, 2.5826],\n",
      "        [2.3339, 2.0520],\n",
      "        [2.7771, 2.4613],\n",
      "        [2.8166, 2.2329],\n",
      "        [2.8055, 2.6149],\n",
      "        [2.3894, 2.6029],\n",
      "        [2.6078, 2.7100],\n",
      "        [2.5640, 2.9457],\n",
      "        [2.2488, 2.3182],\n",
      "        [2.9680, 2.7140],\n",
      "        [2.8530, 2.5796],\n",
      "        [2.3293, 2.3640],\n",
      "        [2.4353, 2.5802],\n",
      "        [2.2932, 2.6247],\n",
      "        [2.4319, 2.6343],\n",
      "        [2.3979, 2.6000],\n",
      "        [2.4299, 2.2825],\n",
      "        [2.6807, 3.1237],\n",
      "        [2.6963, 2.4570],\n",
      "        [2.3077, 2.7779],\n",
      "        [2.5284, 3.3596],\n",
      "        [2.4016, 2.4424],\n",
      "        [2.8895, 2.5296],\n",
      "        [2.4470, 2.6996],\n",
      "        [2.1621, 2.5829],\n",
      "        [2.7014, 2.1217],\n",
      "        [2.8459, 2.5558]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7252, 2.2006],\n",
      "        [2.4062, 2.9687],\n",
      "        [2.3942, 3.0037],\n",
      "        [2.3026, 2.4969],\n",
      "        [2.4371, 2.6654],\n",
      "        [2.5918, 2.3513],\n",
      "        [2.5551, 2.8940],\n",
      "        [2.5689, 2.3745],\n",
      "        [2.7640, 2.4955],\n",
      "        [2.5407, 2.9978],\n",
      "        [2.8901, 2.5667],\n",
      "        [2.7131, 2.8353],\n",
      "        [2.0993, 2.4284],\n",
      "        [2.5490, 2.6736],\n",
      "        [2.5878, 2.6859],\n",
      "        [2.5552, 2.8259],\n",
      "        [2.6232, 3.3052],\n",
      "        [2.8730, 2.6039],\n",
      "        [2.2978, 2.7612],\n",
      "        [2.5793, 2.3052],\n",
      "        [2.4856, 3.0439],\n",
      "        [2.4211, 2.6427],\n",
      "        [2.3172, 2.7525],\n",
      "        [2.5513, 2.5577],\n",
      "        [2.6321, 2.9307],\n",
      "        [2.8208, 2.7652],\n",
      "        [2.4707, 2.9589],\n",
      "        [2.5999, 2.9363],\n",
      "        [2.6972, 2.6508],\n",
      "        [2.5575, 2.1687],\n",
      "        [2.1014, 2.7713],\n",
      "        [2.3538, 2.6879],\n",
      "        [2.8864, 2.6078],\n",
      "        [2.8286, 2.7464],\n",
      "        [2.8194, 2.2656],\n",
      "        [2.7020, 2.7675],\n",
      "        [2.8765, 2.5694],\n",
      "        [2.8329, 2.7475],\n",
      "        [2.4012, 2.5427],\n",
      "        [2.1528, 2.1019],\n",
      "        [2.7570, 2.4374],\n",
      "        [2.8649, 2.5908],\n",
      "        [2.5063, 2.7081],\n",
      "        [2.8757, 2.6625],\n",
      "        [2.9994, 3.1168],\n",
      "        [2.6427, 2.9633],\n",
      "        [2.8001, 2.3717],\n",
      "        [2.2137, 2.4741],\n",
      "        [2.4005, 2.1832],\n",
      "        [2.7805, 2.3674],\n",
      "        [2.3642, 2.6196],\n",
      "        [2.2411, 2.4541],\n",
      "        [2.8690, 2.7777],\n",
      "        [3.0590, 2.7316],\n",
      "        [2.0206, 2.7010],\n",
      "        [2.7512, 2.2598],\n",
      "        [2.7410, 2.4806],\n",
      "        [2.7036, 2.3310],\n",
      "        [2.4942, 2.5988],\n",
      "        [2.2011, 2.6345],\n",
      "        [2.4741, 2.9439],\n",
      "        [2.6742, 2.7081],\n",
      "        [2.1136, 2.4022],\n",
      "        [2.4704, 2.4304],\n",
      "        [2.3614, 2.9958],\n",
      "        [2.1932, 2.1876],\n",
      "        [2.6440, 2.3592],\n",
      "        [2.4303, 2.8297],\n",
      "        [2.4304, 2.3243],\n",
      "        [2.6999, 2.0783],\n",
      "        [2.4253, 2.0878],\n",
      "        [2.8351, 2.5182],\n",
      "        [2.4203, 2.4568],\n",
      "        [2.3386, 2.5225],\n",
      "        [2.3717, 2.4499],\n",
      "        [2.7118, 2.2060],\n",
      "        [2.3155, 2.2319],\n",
      "        [1.9161, 2.3708],\n",
      "        [2.5864, 2.7323],\n",
      "        [2.9054, 2.1406],\n",
      "        [2.5441, 2.4243],\n",
      "        [2.8687, 2.5154],\n",
      "        [2.5132, 2.3174],\n",
      "        [3.0330, 2.6290],\n",
      "        [2.2904, 2.4844],\n",
      "        [2.4663, 2.2328],\n",
      "        [2.9059, 2.2459],\n",
      "        [2.3966, 2.7740],\n",
      "        [2.9517, 2.4150],\n",
      "        [2.4598, 2.4540],\n",
      "        [3.1867, 2.4522],\n",
      "        [2.6420, 2.3630],\n",
      "        [2.2577, 2.6847],\n",
      "        [2.8343, 2.3841],\n",
      "        [2.4244, 2.9226],\n",
      "        [2.3803, 2.5235],\n",
      "        [2.7456, 2.5730],\n",
      "        [2.2957, 2.9218],\n",
      "        [2.6510, 2.9400],\n",
      "        [2.5677, 2.6926]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3844, 2.5455],\n",
      "        [2.6307, 2.5145],\n",
      "        [2.4020, 2.2361],\n",
      "        [2.7786, 2.4756],\n",
      "        [2.1361, 2.6605],\n",
      "        [2.8049, 2.3711],\n",
      "        [2.4614, 2.7890],\n",
      "        [2.4298, 2.3536],\n",
      "        [2.6058, 2.3792],\n",
      "        [2.6514, 2.6716],\n",
      "        [2.9107, 2.2852],\n",
      "        [2.8006, 2.7619],\n",
      "        [2.7200, 2.8134],\n",
      "        [2.5997, 2.6283],\n",
      "        [2.4214, 2.4589],\n",
      "        [2.8974, 2.5338],\n",
      "        [2.3918, 2.4054],\n",
      "        [2.0151, 2.5119],\n",
      "        [2.8233, 2.8021],\n",
      "        [1.9614, 2.8803],\n",
      "        [2.2959, 2.4041],\n",
      "        [2.8458, 2.5844],\n",
      "        [2.4231, 2.6908],\n",
      "        [2.7340, 2.7393],\n",
      "        [2.4817, 2.6145],\n",
      "        [2.5771, 2.5419],\n",
      "        [2.8298, 2.7215],\n",
      "        [2.2670, 2.8319],\n",
      "        [2.5379, 2.4962],\n",
      "        [2.7025, 2.4431],\n",
      "        [2.4016, 2.5487],\n",
      "        [2.4853, 2.8451],\n",
      "        [3.0183, 2.0049],\n",
      "        [2.8164, 2.6927],\n",
      "        [2.6507, 2.8149],\n",
      "        [3.0581, 2.4933],\n",
      "        [2.2352, 2.6003],\n",
      "        [2.5444, 2.4106],\n",
      "        [2.8951, 2.5466],\n",
      "        [2.7480, 2.8990],\n",
      "        [2.5867, 2.8712],\n",
      "        [2.7045, 2.2788],\n",
      "        [2.4097, 2.5537],\n",
      "        [2.7570, 2.5786],\n",
      "        [2.6665, 2.8483],\n",
      "        [2.1790, 2.9680],\n",
      "        [2.4548, 2.3226],\n",
      "        [2.4424, 2.6842],\n",
      "        [2.4728, 2.5387],\n",
      "        [2.8265, 3.1527],\n",
      "        [2.6876, 2.6840],\n",
      "        [2.6663, 2.6085],\n",
      "        [2.4415, 2.5187],\n",
      "        [2.6401, 2.6045],\n",
      "        [2.5998, 2.7747],\n",
      "        [2.6892, 2.4412],\n",
      "        [3.0835, 2.4179],\n",
      "        [2.5687, 2.4755],\n",
      "        [2.8710, 2.4954],\n",
      "        [2.3367, 2.6747],\n",
      "        [2.4294, 2.7666],\n",
      "        [2.3682, 2.4203],\n",
      "        [2.4801, 2.5792],\n",
      "        [2.5014, 2.6080],\n",
      "        [2.4306, 2.3258],\n",
      "        [3.0170, 2.7021],\n",
      "        [2.3638, 2.5047],\n",
      "        [2.6534, 2.6402],\n",
      "        [2.7077, 2.5035],\n",
      "        [2.6341, 2.4688],\n",
      "        [2.0619, 2.5793],\n",
      "        [2.7678, 2.5205],\n",
      "        [2.9309, 2.7401],\n",
      "        [2.2868, 2.0886],\n",
      "        [2.8066, 2.5792],\n",
      "        [2.6493, 2.8440],\n",
      "        [2.4005, 2.7709],\n",
      "        [2.9596, 2.6149],\n",
      "        [2.4883, 2.2575],\n",
      "        [2.5950, 2.2411],\n",
      "        [2.4089, 2.5961],\n",
      "        [2.6933, 2.8148],\n",
      "        [2.5142, 2.5224],\n",
      "        [2.3020, 2.0728],\n",
      "        [2.5462, 2.1839],\n",
      "        [2.8124, 2.2626],\n",
      "        [2.6313, 2.6978],\n",
      "        [2.3623, 2.3846],\n",
      "        [2.6433, 2.7348],\n",
      "        [2.6492, 2.2793],\n",
      "        [2.8966, 2.5759],\n",
      "        [2.0261, 2.4152],\n",
      "        [2.2884, 2.5053],\n",
      "        [2.3360, 2.7091],\n",
      "        [2.4220, 2.7595],\n",
      "        [2.7161, 2.5998],\n",
      "        [2.7013, 2.6761],\n",
      "        [2.2063, 2.2963],\n",
      "        [2.3075, 2.6245],\n",
      "        [2.5080, 2.5061]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6297, 2.3898],\n",
      "        [2.7653, 2.3149],\n",
      "        [2.6939, 2.2492],\n",
      "        [2.4460, 2.3775],\n",
      "        [2.6469, 2.6936],\n",
      "        [2.5287, 2.7625],\n",
      "        [2.3682, 2.6066],\n",
      "        [2.6287, 2.8320],\n",
      "        [2.8985, 2.9373],\n",
      "        [3.0326, 1.9088],\n",
      "        [2.0648, 2.9233],\n",
      "        [2.8433, 2.7863],\n",
      "        [2.5355, 2.8187],\n",
      "        [2.4060, 3.0316],\n",
      "        [2.0413, 2.3392],\n",
      "        [2.4615, 2.4993],\n",
      "        [2.1796, 2.6944],\n",
      "        [2.6736, 2.3931],\n",
      "        [2.5370, 2.7781],\n",
      "        [2.3664, 2.6608],\n",
      "        [2.5057, 2.8209],\n",
      "        [2.4565, 2.3549],\n",
      "        [2.3926, 2.5209],\n",
      "        [2.5444, 2.7469],\n",
      "        [2.3771, 2.6845],\n",
      "        [2.4250, 2.2909],\n",
      "        [2.9691, 2.5246],\n",
      "        [2.7394, 1.9195],\n",
      "        [2.7530, 2.6345],\n",
      "        [2.4175, 2.3769],\n",
      "        [2.2749, 2.8385],\n",
      "        [2.6313, 2.7323],\n",
      "        [2.3808, 3.0537],\n",
      "        [2.7798, 2.6689],\n",
      "        [2.6159, 2.2559],\n",
      "        [2.5547, 2.3938],\n",
      "        [2.6758, 2.5356],\n",
      "        [2.4885, 2.7760],\n",
      "        [2.6625, 2.4495],\n",
      "        [2.6966, 2.3767],\n",
      "        [2.6604, 2.3777],\n",
      "        [2.8333, 2.5734],\n",
      "        [2.7748, 2.9302],\n",
      "        [2.6246, 2.7122],\n",
      "        [2.6479, 2.6101],\n",
      "        [1.9411, 2.6821],\n",
      "        [2.5077, 2.4607],\n",
      "        [2.5926, 2.5495],\n",
      "        [2.3648, 2.1443],\n",
      "        [3.1435, 2.6902],\n",
      "        [2.6080, 1.9907],\n",
      "        [2.6626, 2.2725],\n",
      "        [2.9581, 2.6932],\n",
      "        [2.8126, 2.6146],\n",
      "        [2.5372, 2.8486],\n",
      "        [2.5389, 2.3788],\n",
      "        [2.6515, 2.8748],\n",
      "        [2.5646, 2.0996],\n",
      "        [2.5691, 2.7104],\n",
      "        [2.9633, 2.2526],\n",
      "        [2.8621, 2.6970],\n",
      "        [2.5253, 2.5218],\n",
      "        [2.5418, 2.7384],\n",
      "        [2.9065, 2.8708],\n",
      "        [2.5112, 2.5341],\n",
      "        [2.8937, 2.7356],\n",
      "        [3.0514, 2.1489],\n",
      "        [2.5862, 2.3508],\n",
      "        [2.2181, 2.3143],\n",
      "        [2.4227, 2.5112],\n",
      "        [2.4078, 2.5049],\n",
      "        [2.6884, 2.7067],\n",
      "        [2.5107, 2.4993],\n",
      "        [1.9952, 2.6750],\n",
      "        [2.2916, 2.8777],\n",
      "        [2.9021, 1.9214],\n",
      "        [2.6963, 2.9674],\n",
      "        [2.4434, 2.4688],\n",
      "        [2.4266, 3.1779],\n",
      "        [1.8985, 2.5688],\n",
      "        [2.2391, 2.4177],\n",
      "        [2.5731, 2.9293],\n",
      "        [2.3014, 2.4218],\n",
      "        [2.4572, 2.3068],\n",
      "        [2.6298, 2.8120],\n",
      "        [2.5181, 2.8812],\n",
      "        [2.4812, 2.6892],\n",
      "        [2.3902, 2.6646],\n",
      "        [2.5160, 2.9733],\n",
      "        [2.5700, 2.5159],\n",
      "        [2.2502, 2.8018],\n",
      "        [2.7875, 2.5568],\n",
      "        [2.5889, 2.6494],\n",
      "        [2.4572, 2.5580],\n",
      "        [2.6669, 2.8275],\n",
      "        [2.4941, 2.6560],\n",
      "        [2.7643, 2.5646],\n",
      "        [2.6417, 2.2801],\n",
      "        [2.8171, 2.9621],\n",
      "        [2.8134, 2.5955]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.1042, 2.7249],\n",
      "        [2.2198, 2.3146],\n",
      "        [3.0759, 2.9298],\n",
      "        [2.3859, 2.9756],\n",
      "        [2.7199, 2.7009],\n",
      "        [2.5172, 2.5235],\n",
      "        [2.8872, 2.6358],\n",
      "        [2.4085, 2.5760],\n",
      "        [2.6515, 2.8371],\n",
      "        [2.1890, 2.7582],\n",
      "        [2.8133, 2.2926],\n",
      "        [2.6049, 2.6557],\n",
      "        [2.6013, 2.5208],\n",
      "        [2.1274, 2.8456],\n",
      "        [2.6438, 2.5192],\n",
      "        [3.0097, 2.7205],\n",
      "        [2.5165, 2.3813],\n",
      "        [2.2622, 2.5629],\n",
      "        [2.6896, 2.8059],\n",
      "        [2.5157, 2.7302],\n",
      "        [2.0835, 2.4894],\n",
      "        [2.9331, 2.5384],\n",
      "        [1.9918, 2.6738],\n",
      "        [2.8735, 2.1137],\n",
      "        [2.4109, 2.6030],\n",
      "        [2.6202, 2.8172],\n",
      "        [2.7268, 2.6578],\n",
      "        [2.4511, 2.6235],\n",
      "        [3.0688, 2.5659],\n",
      "        [2.8337, 2.7459],\n",
      "        [2.6435, 2.8502],\n",
      "        [2.7462, 2.2652],\n",
      "        [2.6888, 2.3112],\n",
      "        [2.1916, 2.5959],\n",
      "        [2.3918, 2.4971],\n",
      "        [2.1259, 2.7383],\n",
      "        [2.2541, 2.6574],\n",
      "        [2.6108, 2.7318],\n",
      "        [3.0071, 2.6537],\n",
      "        [2.4899, 2.4026],\n",
      "        [2.0597, 2.5408],\n",
      "        [2.3806, 2.8135],\n",
      "        [2.8020, 2.5291],\n",
      "        [2.6119, 2.7263],\n",
      "        [2.1811, 2.4355],\n",
      "        [2.4439, 2.6832],\n",
      "        [2.4662, 2.8481],\n",
      "        [2.8694, 2.4799],\n",
      "        [2.6647, 2.1703],\n",
      "        [2.0842, 2.1829],\n",
      "        [2.7088, 2.3907],\n",
      "        [2.1606, 2.3559],\n",
      "        [2.7768, 2.5032],\n",
      "        [2.8903, 2.7103],\n",
      "        [2.6012, 2.7122],\n",
      "        [2.8031, 2.7318],\n",
      "        [2.5347, 3.1776],\n",
      "        [2.5968, 2.7903],\n",
      "        [2.3505, 2.3399],\n",
      "        [2.6058, 2.4138],\n",
      "        [2.5671, 2.7150],\n",
      "        [2.8085, 2.1669],\n",
      "        [2.8288, 2.2329],\n",
      "        [2.6170, 2.5408],\n",
      "        [2.6193, 2.6143],\n",
      "        [2.1136, 2.7000],\n",
      "        [2.4560, 2.5624],\n",
      "        [3.0739, 2.1300],\n",
      "        [2.5184, 2.3111],\n",
      "        [2.4243, 2.7805],\n",
      "        [2.5970, 2.5580],\n",
      "        [2.6747, 2.5733],\n",
      "        [2.6536, 2.9099],\n",
      "        [2.8262, 2.8962],\n",
      "        [2.7520, 2.5774],\n",
      "        [2.7397, 2.6292],\n",
      "        [2.6889, 2.6613],\n",
      "        [2.3797, 2.5853],\n",
      "        [2.9884, 2.8750],\n",
      "        [2.7916, 2.2903],\n",
      "        [1.7227, 2.0430],\n",
      "        [2.4798, 2.5299],\n",
      "        [2.3931, 2.2916],\n",
      "        [2.7865, 2.7129],\n",
      "        [2.6091, 2.7856],\n",
      "        [2.7242, 2.3277],\n",
      "        [2.3187, 2.6783],\n",
      "        [2.8353, 2.7346],\n",
      "        [2.2046, 2.6129],\n",
      "        [2.5315, 2.3754],\n",
      "        [2.5382, 2.7307],\n",
      "        [3.0049, 2.7152],\n",
      "        [2.6490, 2.2613],\n",
      "        [2.7841, 2.8247],\n",
      "        [2.5787, 2.2372],\n",
      "        [2.9055, 2.5814],\n",
      "        [2.7761, 2.4839],\n",
      "        [2.3885, 2.5273],\n",
      "        [2.8155, 2.5476],\n",
      "        [2.6465, 2.3285]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 80 complete in 0:03:43.595413; est. finish at 2021-11-29 21:56:00.332963\n",
      "Validation: 0.496 train | 0.498 dev\n",
      "### Epoch: 81 ###\n",
      "y:  tensor([0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.2852, 2.4608],\n",
      "        [2.7287, 2.6579],\n",
      "        [2.1294, 2.1939],\n",
      "        [2.6545, 2.7682],\n",
      "        [2.5816, 2.6922],\n",
      "        [2.7019, 2.1606],\n",
      "        [2.6725, 2.4077],\n",
      "        [2.7992, 2.8647],\n",
      "        [2.6978, 3.1252],\n",
      "        [2.6689, 2.4751],\n",
      "        [2.5151, 2.6842],\n",
      "        [2.5154, 2.5181],\n",
      "        [2.6755, 2.6935],\n",
      "        [2.4725, 2.3761],\n",
      "        [2.4987, 2.8139],\n",
      "        [2.8500, 2.1651],\n",
      "        [2.6616, 2.2240],\n",
      "        [2.4766, 2.4854],\n",
      "        [2.0659, 2.2408],\n",
      "        [2.3787, 2.6047],\n",
      "        [2.7995, 2.5416],\n",
      "        [2.3251, 2.7303],\n",
      "        [2.7591, 2.1255],\n",
      "        [2.5047, 2.1265],\n",
      "        [2.9704, 2.2742],\n",
      "        [2.7215, 2.7209],\n",
      "        [2.1466, 2.3220],\n",
      "        [2.4064, 2.1550],\n",
      "        [2.3082, 2.4358],\n",
      "        [2.4842, 2.6755],\n",
      "        [2.4223, 2.5309],\n",
      "        [2.4407, 2.6760],\n",
      "        [2.5761, 2.8437],\n",
      "        [2.2557, 2.5838],\n",
      "        [2.4008, 2.4369],\n",
      "        [2.3365, 2.5097],\n",
      "        [2.5942, 2.9650],\n",
      "        [2.3213, 2.4882],\n",
      "        [2.4937, 2.6889],\n",
      "        [2.6992, 2.5704],\n",
      "        [2.7924, 2.7555],\n",
      "        [2.6120, 2.6372],\n",
      "        [2.6926, 2.5942],\n",
      "        [2.3087, 2.4715],\n",
      "        [2.8127, 2.5234],\n",
      "        [2.6566, 3.0070],\n",
      "        [2.2457, 2.4512],\n",
      "        [2.6287, 2.7353],\n",
      "        [2.5209, 2.8452],\n",
      "        [2.4779, 2.5538],\n",
      "        [2.3313, 2.5722],\n",
      "        [2.8638, 2.2509],\n",
      "        [2.5264, 2.0488],\n",
      "        [2.5290, 2.6806],\n",
      "        [2.2031, 2.8957],\n",
      "        [2.4404, 2.8582],\n",
      "        [2.3990, 2.2269],\n",
      "        [2.2432, 2.5488],\n",
      "        [2.5529, 2.2830],\n",
      "        [2.6276, 2.5932],\n",
      "        [2.2695, 2.6116],\n",
      "        [2.6568, 2.7232],\n",
      "        [2.7762, 2.6266],\n",
      "        [2.4187, 2.3363],\n",
      "        [2.7190, 2.3201],\n",
      "        [2.9123, 2.7819],\n",
      "        [2.4879, 2.0751],\n",
      "        [1.9979, 2.6113],\n",
      "        [2.8524, 2.6115],\n",
      "        [2.3357, 2.4190],\n",
      "        [2.8733, 2.6493],\n",
      "        [2.3245, 2.5301],\n",
      "        [2.9432, 2.3521],\n",
      "        [2.7170, 2.5819],\n",
      "        [2.9032, 2.8441],\n",
      "        [2.8102, 2.8607],\n",
      "        [2.0703, 2.4709],\n",
      "        [2.3033, 2.3337],\n",
      "        [2.5399, 2.8934],\n",
      "        [2.4421, 2.6743],\n",
      "        [2.6460, 2.5800],\n",
      "        [2.9210, 2.5942],\n",
      "        [2.2839, 2.5345],\n",
      "        [2.6931, 2.3473],\n",
      "        [2.1756, 2.6019],\n",
      "        [2.6341, 2.7712],\n",
      "        [2.5161, 2.6219],\n",
      "        [2.3927, 2.7961],\n",
      "        [2.7675, 2.7822],\n",
      "        [2.8631, 2.2113],\n",
      "        [2.3565, 2.8705],\n",
      "        [2.4209, 2.8094],\n",
      "        [2.4734, 2.7602],\n",
      "        [2.6561, 2.4094],\n",
      "        [2.5592, 2.9030],\n",
      "        [2.7656, 2.7072],\n",
      "        [2.6952, 2.3855],\n",
      "        [2.9716, 2.2777],\n",
      "        [2.1714, 2.6519],\n",
      "        [2.2127, 1.8637]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.1496, 2.2723],\n",
      "        [2.9710, 2.6710],\n",
      "        [2.4901, 2.8388],\n",
      "        [2.3610, 2.7391],\n",
      "        [2.2739, 2.9674],\n",
      "        [2.5679, 2.2760],\n",
      "        [2.2130, 2.4752],\n",
      "        [2.3996, 2.3014],\n",
      "        [2.7783, 2.1360],\n",
      "        [2.4919, 2.2411],\n",
      "        [2.7389, 2.5889],\n",
      "        [2.5689, 2.6865],\n",
      "        [2.8025, 2.2491],\n",
      "        [2.6575, 2.3380],\n",
      "        [2.6088, 2.5800],\n",
      "        [2.8923, 2.2301],\n",
      "        [2.3581, 2.5738],\n",
      "        [2.5100, 2.5560],\n",
      "        [3.0074, 2.5252],\n",
      "        [2.6072, 2.6961],\n",
      "        [2.5808, 2.6915],\n",
      "        [3.0700, 2.8744],\n",
      "        [2.8805, 2.4189],\n",
      "        [2.2031, 1.9693],\n",
      "        [2.4728, 2.5440],\n",
      "        [2.4434, 2.8297],\n",
      "        [2.5534, 2.3337],\n",
      "        [2.2468, 2.3871],\n",
      "        [2.4516, 2.5473],\n",
      "        [2.5619, 2.8358],\n",
      "        [2.1999, 2.3343],\n",
      "        [2.6578, 2.9056],\n",
      "        [2.9387, 1.9663],\n",
      "        [2.0868, 2.2243],\n",
      "        [2.6844, 2.8440],\n",
      "        [2.2860, 2.4704],\n",
      "        [2.6264, 2.7441],\n",
      "        [2.3127, 2.3192],\n",
      "        [2.4670, 2.8658],\n",
      "        [2.9627, 2.3342],\n",
      "        [2.4658, 2.9045],\n",
      "        [3.1101, 2.6950],\n",
      "        [2.8800, 2.5111],\n",
      "        [2.2578, 2.7272],\n",
      "        [2.4643, 2.4982],\n",
      "        [2.6268, 2.3936],\n",
      "        [2.6247, 2.5452],\n",
      "        [2.5186, 2.7036],\n",
      "        [2.6826, 2.8104],\n",
      "        [2.4492, 2.1677],\n",
      "        [2.6654, 2.7260],\n",
      "        [2.6938, 2.5948],\n",
      "        [2.5509, 3.0728],\n",
      "        [3.0204, 2.4183],\n",
      "        [2.1634, 2.6762],\n",
      "        [2.4837, 2.5874],\n",
      "        [2.2132, 2.7532],\n",
      "        [3.0452, 2.5579],\n",
      "        [2.2548, 2.2384],\n",
      "        [3.0469, 2.4819],\n",
      "        [2.6007, 3.0165],\n",
      "        [2.4036, 2.6341],\n",
      "        [2.6563, 2.7112],\n",
      "        [2.7354, 2.0264],\n",
      "        [2.6575, 3.0178],\n",
      "        [2.8089, 2.6744],\n",
      "        [2.5239, 2.7645],\n",
      "        [2.8114, 2.6010],\n",
      "        [2.4787, 2.7073],\n",
      "        [2.6224, 2.7262],\n",
      "        [1.8417, 2.8087],\n",
      "        [2.4969, 2.7893],\n",
      "        [2.6644, 2.5242],\n",
      "        [2.8007, 2.5769],\n",
      "        [2.4262, 2.7413],\n",
      "        [2.6564, 2.6981],\n",
      "        [2.5055, 2.2056],\n",
      "        [2.3796, 2.1416],\n",
      "        [2.7070, 2.3984],\n",
      "        [2.1799, 2.6450],\n",
      "        [2.7315, 2.8371],\n",
      "        [2.6292, 2.8664],\n",
      "        [2.6962, 2.4595],\n",
      "        [2.8426, 2.3883],\n",
      "        [2.6257, 2.7287],\n",
      "        [2.5046, 2.6849],\n",
      "        [2.4396, 2.8264],\n",
      "        [2.8393, 2.3391],\n",
      "        [2.7552, 2.3114],\n",
      "        [2.9101, 2.5153],\n",
      "        [2.7845, 2.2033],\n",
      "        [2.6518, 2.1792],\n",
      "        [2.7826, 2.4665],\n",
      "        [2.9115, 2.5974],\n",
      "        [2.4773, 3.2116],\n",
      "        [3.1373, 2.0943],\n",
      "        [2.8658, 2.7340],\n",
      "        [2.8168, 2.4080],\n",
      "        [2.2694, 2.5591],\n",
      "        [2.5804, 2.3197]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.4894, 2.2518],\n",
      "        [2.6793, 2.5557],\n",
      "        [2.3272, 2.7257],\n",
      "        [2.7122, 2.3418],\n",
      "        [2.4455, 2.5472],\n",
      "        [3.0702, 2.2358],\n",
      "        [2.7524, 2.5025],\n",
      "        [2.7340, 2.8342],\n",
      "        [2.6582, 2.2169],\n",
      "        [2.4255, 2.5645],\n",
      "        [2.6734, 2.7364],\n",
      "        [2.3819, 1.9271],\n",
      "        [2.1312, 2.7046],\n",
      "        [2.8214, 2.6335],\n",
      "        [2.2876, 2.8854],\n",
      "        [2.6905, 2.1369],\n",
      "        [2.1098, 2.3424],\n",
      "        [2.6575, 2.8789],\n",
      "        [2.1328, 2.5362],\n",
      "        [2.5980, 2.7007],\n",
      "        [2.3196, 2.3995],\n",
      "        [1.9182, 2.8192],\n",
      "        [1.8978, 2.7067],\n",
      "        [2.2455, 2.6003],\n",
      "        [2.6512, 2.5571],\n",
      "        [2.8134, 2.8121],\n",
      "        [2.6455, 2.7023],\n",
      "        [2.8105, 2.3630],\n",
      "        [2.2880, 2.6368],\n",
      "        [2.2786, 2.7083],\n",
      "        [2.7495, 2.7090],\n",
      "        [2.1470, 2.3605],\n",
      "        [2.8245, 2.2339],\n",
      "        [3.1441, 2.3201],\n",
      "        [2.0776, 2.6194],\n",
      "        [2.9019, 2.1411],\n",
      "        [2.8015, 2.7122],\n",
      "        [2.4544, 2.2477],\n",
      "        [2.6707, 2.8285],\n",
      "        [2.2022, 2.8985],\n",
      "        [2.8560, 2.4331],\n",
      "        [2.6310, 2.9193],\n",
      "        [2.2543, 2.8761],\n",
      "        [2.0224, 2.5274],\n",
      "        [2.8074, 2.4073],\n",
      "        [2.1110, 2.8688],\n",
      "        [2.6293, 2.3747],\n",
      "        [2.3849, 2.5641],\n",
      "        [2.5762, 2.6254],\n",
      "        [2.3781, 2.2685],\n",
      "        [2.7426, 2.4949],\n",
      "        [2.5223, 2.6879],\n",
      "        [2.5183, 2.3702],\n",
      "        [2.2963, 2.7098],\n",
      "        [2.0766, 2.5408],\n",
      "        [2.3456, 2.4760],\n",
      "        [2.3794, 2.5755],\n",
      "        [2.8055, 2.8104],\n",
      "        [2.7889, 2.8982],\n",
      "        [2.2591, 2.4653],\n",
      "        [2.3409, 2.6219],\n",
      "        [2.7854, 2.7077],\n",
      "        [2.2211, 2.3188],\n",
      "        [2.0553, 2.2871],\n",
      "        [2.4350, 2.4276],\n",
      "        [2.6798, 2.3620],\n",
      "        [2.7453, 2.7288],\n",
      "        [2.6283, 2.6774],\n",
      "        [2.6114, 2.4376],\n",
      "        [2.3227, 2.5589],\n",
      "        [2.4140, 2.4044],\n",
      "        [2.5716, 2.3863],\n",
      "        [2.2022, 1.6668],\n",
      "        [2.6358, 3.0952],\n",
      "        [2.3137, 2.5285],\n",
      "        [2.8887, 2.2596],\n",
      "        [2.4459, 2.5599],\n",
      "        [2.9475, 2.5779],\n",
      "        [2.5567, 2.7502],\n",
      "        [2.9024, 2.3759],\n",
      "        [2.7442, 2.7519],\n",
      "        [2.6317, 2.6513],\n",
      "        [2.4306, 2.3569],\n",
      "        [2.5584, 2.6164],\n",
      "        [2.5959, 2.5822],\n",
      "        [2.7874, 2.0865],\n",
      "        [2.4049, 3.3047],\n",
      "        [2.4793, 2.2323],\n",
      "        [2.5280, 2.0563],\n",
      "        [2.6205, 2.7783],\n",
      "        [2.5970, 2.5922],\n",
      "        [2.9305, 2.8964],\n",
      "        [2.7405, 2.3630],\n",
      "        [2.5777, 2.5102],\n",
      "        [2.0910, 2.4252],\n",
      "        [3.0205, 2.5010],\n",
      "        [1.7561, 2.7256],\n",
      "        [2.6275, 2.9542],\n",
      "        [2.4590, 2.4851],\n",
      "        [1.7580, 2.7428]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7939, 2.5300],\n",
      "        [2.8759, 2.1478],\n",
      "        [2.6836, 2.3828],\n",
      "        [2.8155, 2.3653],\n",
      "        [2.6985, 2.6465],\n",
      "        [2.4272, 2.5981],\n",
      "        [2.1803, 2.5475],\n",
      "        [2.6706, 2.4452],\n",
      "        [2.3297, 2.7293],\n",
      "        [2.4188, 3.1054],\n",
      "        [2.5897, 2.5210],\n",
      "        [2.5097, 1.9989],\n",
      "        [2.6455, 2.5438],\n",
      "        [2.6197, 2.7276],\n",
      "        [2.4873, 2.6314],\n",
      "        [2.3500, 2.6228],\n",
      "        [2.9928, 2.4807],\n",
      "        [2.8399, 2.9126],\n",
      "        [2.2800, 2.1320],\n",
      "        [2.2876, 2.8881],\n",
      "        [2.5119, 2.7050],\n",
      "        [2.8504, 2.5804],\n",
      "        [1.9675, 2.5503],\n",
      "        [2.9200, 2.8881],\n",
      "        [2.3900, 2.5065],\n",
      "        [2.1802, 2.2551],\n",
      "        [2.6952, 2.7368],\n",
      "        [2.8359, 2.7148],\n",
      "        [2.3003, 2.6336],\n",
      "        [2.0424, 2.7658],\n",
      "        [2.4257, 2.6386],\n",
      "        [2.6925, 2.9238],\n",
      "        [2.4014, 2.3371],\n",
      "        [2.7742, 3.0143],\n",
      "        [2.5564, 2.3599],\n",
      "        [2.8126, 2.6810],\n",
      "        [2.8363, 2.3146],\n",
      "        [2.5495, 2.7934],\n",
      "        [2.4136, 2.5244],\n",
      "        [2.8246, 2.8755],\n",
      "        [2.4607, 2.4798],\n",
      "        [2.3230, 2.5943],\n",
      "        [2.9184, 2.2634],\n",
      "        [3.0862, 2.0683],\n",
      "        [2.7435, 2.6539],\n",
      "        [3.0175, 2.7374],\n",
      "        [2.4998, 2.3152],\n",
      "        [2.1646, 2.7566],\n",
      "        [2.0591, 3.0246],\n",
      "        [2.5316, 2.3389],\n",
      "        [2.5381, 2.3988],\n",
      "        [2.7335, 2.3236],\n",
      "        [2.7073, 2.7902],\n",
      "        [3.0678, 2.3275],\n",
      "        [3.0819, 2.5404],\n",
      "        [2.5751, 2.4116],\n",
      "        [2.4734, 2.5871],\n",
      "        [2.8265, 2.2938],\n",
      "        [2.3385, 2.2794],\n",
      "        [2.5923, 2.3176],\n",
      "        [2.9579, 2.6196],\n",
      "        [2.4142, 2.2433],\n",
      "        [2.5629, 2.4723],\n",
      "        [2.8964, 2.2777],\n",
      "        [2.7679, 2.4789],\n",
      "        [2.7229, 2.4287],\n",
      "        [2.9581, 2.7073],\n",
      "        [2.8316, 2.6008],\n",
      "        [2.5722, 2.6187],\n",
      "        [2.6761, 2.3336],\n",
      "        [3.1983, 2.5775],\n",
      "        [2.9448, 2.4478],\n",
      "        [2.2181, 2.7119],\n",
      "        [2.9106, 2.6296],\n",
      "        [1.8450, 2.5861],\n",
      "        [2.5548, 2.8715],\n",
      "        [2.3959, 2.3651],\n",
      "        [2.5919, 1.9880],\n",
      "        [2.7682, 2.5598],\n",
      "        [2.4307, 2.6742],\n",
      "        [2.5551, 2.6034],\n",
      "        [2.8866, 2.5379],\n",
      "        [2.1828, 1.9327],\n",
      "        [2.4034, 2.6583],\n",
      "        [2.6686, 2.5206],\n",
      "        [1.9793, 2.7536],\n",
      "        [2.5794, 2.7054],\n",
      "        [2.2238, 2.5916],\n",
      "        [2.4624, 2.3499],\n",
      "        [2.1392, 2.6760],\n",
      "        [2.6001, 2.6661],\n",
      "        [2.4610, 2.9867],\n",
      "        [2.5101, 2.4418],\n",
      "        [2.6461, 2.8922],\n",
      "        [2.6307, 2.4674],\n",
      "        [2.5941, 2.2667],\n",
      "        [2.3602, 2.5740],\n",
      "        [2.9714, 2.5788],\n",
      "        [2.5551, 2.7204],\n",
      "        [2.4967, 2.5676]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.2597, 2.4434],\n",
      "        [3.0696, 2.7800],\n",
      "        [2.6487, 2.4034],\n",
      "        [2.5356, 2.3843],\n",
      "        [2.2356, 2.7598],\n",
      "        [2.4888, 2.3896],\n",
      "        [2.5812, 2.4522],\n",
      "        [2.4111, 2.5641],\n",
      "        [2.8481, 2.6850],\n",
      "        [2.8399, 2.3681],\n",
      "        [2.4990, 2.8311],\n",
      "        [2.7080, 2.2761],\n",
      "        [2.6174, 2.2119],\n",
      "        [2.4591, 2.2320],\n",
      "        [2.6897, 2.4475],\n",
      "        [2.6449, 2.4628],\n",
      "        [2.4844, 2.3174],\n",
      "        [2.9080, 2.3309],\n",
      "        [2.9690, 2.3205],\n",
      "        [2.7201, 2.7043],\n",
      "        [2.9224, 2.4979],\n",
      "        [2.8586, 2.1199],\n",
      "        [2.5981, 2.2208],\n",
      "        [2.3898, 2.3320],\n",
      "        [2.3126, 2.5410],\n",
      "        [2.9421, 2.5397],\n",
      "        [2.3229, 2.6864],\n",
      "        [2.4438, 2.7532],\n",
      "        [2.2490, 2.6257],\n",
      "        [2.6086, 2.7913],\n",
      "        [2.5357, 2.8892],\n",
      "        [2.6396, 3.0340],\n",
      "        [3.0121, 2.5914],\n",
      "        [2.5473, 2.8471],\n",
      "        [2.3625, 2.0432],\n",
      "        [2.4160, 2.5388],\n",
      "        [2.9278, 2.5956],\n",
      "        [2.9183, 2.8591],\n",
      "        [2.4141, 2.3612],\n",
      "        [3.1766, 2.7832],\n",
      "        [2.5267, 2.5571],\n",
      "        [2.5695, 2.5701],\n",
      "        [2.6237, 2.5518],\n",
      "        [2.5708, 2.0812],\n",
      "        [2.4057, 2.6996],\n",
      "        [2.4341, 2.0814],\n",
      "        [2.7908, 2.4628],\n",
      "        [3.0226, 2.6089],\n",
      "        [2.6059, 2.4522],\n",
      "        [2.7691, 2.3063],\n",
      "        [2.6292, 2.5149],\n",
      "        [2.2031, 2.4996],\n",
      "        [2.3209, 2.5340],\n",
      "        [2.3340, 2.4908],\n",
      "        [2.3033, 2.5784],\n",
      "        [2.6597, 2.2606],\n",
      "        [3.2411, 3.1614],\n",
      "        [2.4928, 2.3329],\n",
      "        [2.4015, 2.3247],\n",
      "        [2.3310, 2.4009],\n",
      "        [2.2293, 2.4107],\n",
      "        [2.8527, 2.7775],\n",
      "        [2.1757, 2.3915],\n",
      "        [2.4653, 2.8360],\n",
      "        [2.5057, 2.8347],\n",
      "        [2.4915, 2.3630],\n",
      "        [2.7542, 2.2140],\n",
      "        [2.3857, 2.4462],\n",
      "        [2.5190, 2.6697],\n",
      "        [2.1777, 2.7766],\n",
      "        [2.4622, 3.2024],\n",
      "        [2.4354, 2.8102],\n",
      "        [2.8039, 2.5288],\n",
      "        [2.6193, 2.8304],\n",
      "        [2.2456, 2.6546],\n",
      "        [2.1867, 2.2214],\n",
      "        [2.8189, 2.5548],\n",
      "        [2.2836, 2.0220],\n",
      "        [2.6467, 2.6732],\n",
      "        [2.6098, 2.5878],\n",
      "        [2.8387, 2.2094],\n",
      "        [2.3273, 2.6351],\n",
      "        [2.4218, 2.7637],\n",
      "        [2.5571, 2.6517],\n",
      "        [2.6339, 2.7640],\n",
      "        [2.3232, 2.4604],\n",
      "        [3.0849, 2.7889],\n",
      "        [2.4636, 2.4511],\n",
      "        [2.6214, 2.4113],\n",
      "        [2.4738, 2.1376],\n",
      "        [2.7000, 2.1985],\n",
      "        [2.8446, 2.4806],\n",
      "        [2.5572, 2.6588],\n",
      "        [2.2815, 2.4328],\n",
      "        [2.3830, 2.7622],\n",
      "        [2.6870, 2.3859],\n",
      "        [2.3310, 3.2163],\n",
      "        [2.6514, 2.7625],\n",
      "        [2.3171, 2.6576],\n",
      "        [2.1161, 2.3359]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 85 complete in 0:03:58.904295; est. finish at 2021-11-29 21:56:01.902563\n",
      "Validation: 0.486 train | 0.436 dev\n",
      "### Epoch: 86 ###\n",
      "y:  tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8167, 2.4832],\n",
      "        [2.6921, 2.6491],\n",
      "        [2.7875, 3.1114],\n",
      "        [2.7860, 2.4217],\n",
      "        [2.8493, 2.7055],\n",
      "        [3.0126, 2.4726],\n",
      "        [2.8589, 2.4324],\n",
      "        [2.6742, 2.7102],\n",
      "        [2.5871, 2.9236],\n",
      "        [2.4818, 2.6286],\n",
      "        [2.8434, 2.5394],\n",
      "        [3.0345, 3.1835],\n",
      "        [2.8283, 2.6366],\n",
      "        [2.2607, 2.4075],\n",
      "        [2.2341, 2.5013],\n",
      "        [2.5737, 2.6580],\n",
      "        [2.6627, 2.4618],\n",
      "        [2.6250, 2.4634],\n",
      "        [2.5601, 2.5668],\n",
      "        [2.1186, 2.6902],\n",
      "        [2.2236, 2.4894],\n",
      "        [3.0396, 2.9682],\n",
      "        [2.4722, 2.7078],\n",
      "        [2.3543, 2.7179],\n",
      "        [2.6498, 2.4892],\n",
      "        [2.8005, 2.5457],\n",
      "        [2.8879, 2.2627],\n",
      "        [2.9521, 2.2191],\n",
      "        [2.4109, 2.0922],\n",
      "        [2.5595, 2.4045],\n",
      "        [2.8640, 2.7361],\n",
      "        [2.7771, 3.0946],\n",
      "        [2.6447, 2.8410],\n",
      "        [2.3979, 2.3047],\n",
      "        [2.3860, 3.0350],\n",
      "        [2.1897, 2.1480],\n",
      "        [2.5299, 2.9535],\n",
      "        [2.6995, 2.6204],\n",
      "        [3.0247, 2.3096],\n",
      "        [2.5628, 2.8426],\n",
      "        [2.6126, 2.5286],\n",
      "        [2.2598, 2.3918],\n",
      "        [2.7546, 2.9592],\n",
      "        [2.3925, 2.8026],\n",
      "        [2.5518, 2.5168],\n",
      "        [2.4643, 2.8658],\n",
      "        [2.4900, 2.5652],\n",
      "        [2.5868, 2.0331],\n",
      "        [2.3379, 2.3664],\n",
      "        [1.7838, 2.6627],\n",
      "        [2.2078, 2.8785],\n",
      "        [2.5066, 2.6106],\n",
      "        [2.0939, 2.5693],\n",
      "        [2.4860, 3.0565],\n",
      "        [2.8874, 2.9690],\n",
      "        [2.2634, 2.7119],\n",
      "        [2.3102, 2.3838],\n",
      "        [2.1050, 2.5492],\n",
      "        [2.6681, 2.0577],\n",
      "        [2.2155, 2.6413],\n",
      "        [2.6039, 2.2801],\n",
      "        [2.5051, 2.8018],\n",
      "        [3.0992, 2.2405],\n",
      "        [2.3468, 2.7217],\n",
      "        [2.8185, 2.3928],\n",
      "        [2.7263, 2.4232],\n",
      "        [2.3783, 2.5746],\n",
      "        [2.6702, 2.5147],\n",
      "        [2.6109, 2.8938],\n",
      "        [2.5242, 2.5974],\n",
      "        [2.4690, 2.8864],\n",
      "        [2.6467, 2.8229],\n",
      "        [2.6562, 2.8018],\n",
      "        [2.4259, 1.8971],\n",
      "        [2.7765, 2.5852],\n",
      "        [2.5043, 2.5383],\n",
      "        [3.0039, 2.3322],\n",
      "        [2.4181, 2.4138],\n",
      "        [2.7731, 2.2964],\n",
      "        [2.5726, 2.6652],\n",
      "        [2.6792, 2.3976],\n",
      "        [2.3568, 2.3829],\n",
      "        [2.9358, 2.2850],\n",
      "        [2.5771, 2.9316],\n",
      "        [2.2778, 2.7271],\n",
      "        [2.6514, 2.3832],\n",
      "        [2.6814, 2.6376],\n",
      "        [2.5091, 2.3015],\n",
      "        [2.4432, 2.1650],\n",
      "        [1.6882, 1.8325],\n",
      "        [2.7188, 2.5142],\n",
      "        [3.2899, 2.1361],\n",
      "        [2.5834, 2.5301],\n",
      "        [2.8497, 2.3779],\n",
      "        [2.2304, 2.0694],\n",
      "        [2.4454, 2.1485],\n",
      "        [2.2444, 2.5815],\n",
      "        [1.8457, 2.3595],\n",
      "        [2.7798, 2.5974],\n",
      "        [2.6311, 2.4827]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8985, 2.8366],\n",
      "        [2.2410, 2.6528],\n",
      "        [2.7892, 2.7928],\n",
      "        [2.1899, 2.5868],\n",
      "        [2.6631, 2.1652],\n",
      "        [2.4211, 2.5333],\n",
      "        [2.4440, 2.8543],\n",
      "        [2.7702, 2.8280],\n",
      "        [2.4743, 2.7386],\n",
      "        [2.7929, 2.7481],\n",
      "        [2.2252, 2.8151],\n",
      "        [2.5148, 3.0351],\n",
      "        [2.7448, 2.4629],\n",
      "        [2.8846, 2.6118],\n",
      "        [2.6657, 2.4836],\n",
      "        [1.9240, 2.3606],\n",
      "        [2.6644, 2.6012],\n",
      "        [2.5353, 2.3881],\n",
      "        [1.8861, 2.4109],\n",
      "        [2.7499, 2.9404],\n",
      "        [2.1481, 2.3867],\n",
      "        [2.4785, 2.2861],\n",
      "        [2.7947, 2.4888],\n",
      "        [2.6600, 2.4523],\n",
      "        [2.0389, 2.6145],\n",
      "        [2.6700, 2.6654],\n",
      "        [2.4897, 2.8665],\n",
      "        [2.6467, 2.5831],\n",
      "        [2.5731, 2.7884],\n",
      "        [2.8099, 2.0725],\n",
      "        [2.1272, 2.6178],\n",
      "        [2.6261, 2.1374],\n",
      "        [2.9791, 2.6863],\n",
      "        [2.5522, 2.5388],\n",
      "        [2.6098, 1.9681],\n",
      "        [2.6927, 2.5364],\n",
      "        [2.7108, 2.5388],\n",
      "        [2.3921, 2.9349],\n",
      "        [2.7252, 2.8851],\n",
      "        [2.0993, 2.1267],\n",
      "        [2.4029, 2.7808],\n",
      "        [2.2775, 2.7759],\n",
      "        [2.5216, 2.3259],\n",
      "        [2.6674, 2.2919],\n",
      "        [2.3950, 2.0639],\n",
      "        [2.0119, 2.4412],\n",
      "        [2.4821, 2.7820],\n",
      "        [2.0744, 2.8603],\n",
      "        [2.8728, 2.7549],\n",
      "        [2.3240, 2.2015],\n",
      "        [2.5553, 2.8119],\n",
      "        [2.7031, 2.7851],\n",
      "        [3.0351, 2.4903],\n",
      "        [3.2944, 2.7180],\n",
      "        [2.8752, 2.5439],\n",
      "        [2.6446, 2.7166],\n",
      "        [2.6557, 2.2117],\n",
      "        [2.3355, 2.5027],\n",
      "        [2.6368, 2.2752],\n",
      "        [2.9881, 2.6008],\n",
      "        [2.7356, 2.7549],\n",
      "        [2.6055, 2.9227],\n",
      "        [3.1164, 2.2427],\n",
      "        [2.6881, 2.9762],\n",
      "        [2.7806, 2.7092],\n",
      "        [2.5563, 2.2993],\n",
      "        [2.3933, 2.8561],\n",
      "        [2.6490, 2.6011],\n",
      "        [2.3396, 2.9298],\n",
      "        [2.1423, 2.4713],\n",
      "        [2.4294, 2.4317],\n",
      "        [2.2749, 2.7568],\n",
      "        [2.5722, 2.7444],\n",
      "        [2.6249, 2.0590],\n",
      "        [2.3185, 2.4365],\n",
      "        [2.4554, 3.1972],\n",
      "        [2.6322, 2.5676],\n",
      "        [2.0859, 2.7928],\n",
      "        [2.5875, 2.3723],\n",
      "        [2.5909, 2.7954],\n",
      "        [2.3158, 2.8110],\n",
      "        [2.4224, 2.6259],\n",
      "        [2.6389, 2.7148],\n",
      "        [2.5478, 2.4190],\n",
      "        [2.4527, 2.5987],\n",
      "        [3.1458, 2.4159],\n",
      "        [2.4835, 2.7488],\n",
      "        [2.9089, 2.1157],\n",
      "        [2.1774, 2.9733],\n",
      "        [2.4494, 2.8830],\n",
      "        [2.4892, 2.0950],\n",
      "        [2.5311, 2.0688],\n",
      "        [2.3575, 2.7581],\n",
      "        [2.9736, 2.6274],\n",
      "        [2.4083, 3.0585],\n",
      "        [2.8512, 2.4695],\n",
      "        [2.2322, 2.0194],\n",
      "        [2.8012, 2.2900],\n",
      "        [2.4293, 2.2634],\n",
      "        [2.1343, 3.1332]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.8503, 2.5010],\n",
      "        [2.6507, 2.4868],\n",
      "        [2.7545, 2.7440],\n",
      "        [1.9787, 2.8804],\n",
      "        [3.1367, 2.8137],\n",
      "        [2.2687, 2.6857],\n",
      "        [2.4821, 2.7348],\n",
      "        [2.4972, 2.0870],\n",
      "        [2.2200, 2.2328],\n",
      "        [2.4056, 2.7189],\n",
      "        [2.7056, 2.5659],\n",
      "        [2.1060, 2.8253],\n",
      "        [2.9604, 2.6823],\n",
      "        [2.3939, 2.6634],\n",
      "        [2.6087, 2.4590],\n",
      "        [2.8608, 2.7304],\n",
      "        [2.5978, 2.4822],\n",
      "        [3.1487, 2.2500],\n",
      "        [2.4903, 2.5238],\n",
      "        [2.5970, 2.7132],\n",
      "        [2.3292, 2.2489],\n",
      "        [2.4786, 2.5106],\n",
      "        [2.4409, 2.7490],\n",
      "        [2.8006, 2.4813],\n",
      "        [2.6457, 2.4571],\n",
      "        [2.4410, 2.7783],\n",
      "        [2.2680, 2.4180],\n",
      "        [2.1938, 2.6829],\n",
      "        [2.0661, 2.4135],\n",
      "        [2.5186, 2.7707],\n",
      "        [2.7413, 2.2820],\n",
      "        [2.6683, 2.4867],\n",
      "        [2.8203, 2.8586],\n",
      "        [3.0409, 2.7963],\n",
      "        [2.4321, 2.8776],\n",
      "        [2.1718, 2.8311],\n",
      "        [2.1113, 2.3222],\n",
      "        [2.5966, 2.6343],\n",
      "        [2.3521, 2.8032],\n",
      "        [2.6926, 2.7267],\n",
      "        [2.5228, 2.6692],\n",
      "        [2.1512, 2.3160],\n",
      "        [2.6162, 2.5831],\n",
      "        [2.6324, 2.2682],\n",
      "        [2.4516, 2.6604],\n",
      "        [2.7490, 2.1463],\n",
      "        [2.3755, 3.1530],\n",
      "        [2.8474, 2.6888],\n",
      "        [2.3606, 2.4606],\n",
      "        [2.6819, 2.4778],\n",
      "        [2.7299, 2.2869],\n",
      "        [2.5244, 2.2769],\n",
      "        [2.3179, 2.8152],\n",
      "        [2.6535, 2.6142],\n",
      "        [2.5574, 2.1500],\n",
      "        [2.3233, 2.5126],\n",
      "        [2.9177, 2.4428],\n",
      "        [2.9143, 2.5967],\n",
      "        [2.8019, 2.8033],\n",
      "        [2.4333, 2.6826],\n",
      "        [3.0010, 2.7280],\n",
      "        [2.6841, 2.6124],\n",
      "        [2.5133, 2.3066],\n",
      "        [2.4557, 2.5150],\n",
      "        [2.6983, 2.7007],\n",
      "        [2.2139, 2.4886],\n",
      "        [2.5043, 2.3764],\n",
      "        [2.7325, 2.0782],\n",
      "        [2.8617, 2.5467],\n",
      "        [2.5217, 2.3206],\n",
      "        [2.4331, 2.4357],\n",
      "        [2.5456, 2.3744],\n",
      "        [2.5290, 2.6070],\n",
      "        [2.4280, 2.3210],\n",
      "        [2.6806, 2.4770],\n",
      "        [1.9312, 2.6887],\n",
      "        [2.1596, 2.3990],\n",
      "        [3.0283, 2.5505],\n",
      "        [2.5440, 2.1889],\n",
      "        [2.8575, 2.5057],\n",
      "        [1.9858, 2.7988],\n",
      "        [3.0842, 2.3856],\n",
      "        [2.4513, 2.6051],\n",
      "        [2.3227, 2.6297],\n",
      "        [2.2332, 2.9775],\n",
      "        [2.3209, 2.6989],\n",
      "        [2.3186, 2.9710],\n",
      "        [2.3922, 2.1150],\n",
      "        [2.9401, 2.4825],\n",
      "        [2.3246, 2.9945],\n",
      "        [2.0702, 2.5252],\n",
      "        [2.5241, 2.4430],\n",
      "        [2.4268, 2.2743],\n",
      "        [2.7835, 2.8645],\n",
      "        [2.6558, 3.1262],\n",
      "        [2.9554, 2.5161],\n",
      "        [2.2066, 2.4090],\n",
      "        [2.4928, 2.3188],\n",
      "        [2.6916, 2.4535],\n",
      "        [2.3192, 2.7757]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7682, 2.7635],\n",
      "        [2.1611, 2.6478],\n",
      "        [2.2049, 2.0286],\n",
      "        [2.5854, 2.7170],\n",
      "        [2.3964, 2.2644],\n",
      "        [2.5679, 2.6608],\n",
      "        [2.3917, 2.1752],\n",
      "        [2.5953, 2.0886],\n",
      "        [2.6601, 2.4487],\n",
      "        [2.3608, 2.1790],\n",
      "        [2.6699, 2.5497],\n",
      "        [2.4823, 2.5180],\n",
      "        [2.9773, 2.6636],\n",
      "        [2.8127, 1.9115],\n",
      "        [2.5895, 2.5531],\n",
      "        [2.6474, 2.3830],\n",
      "        [2.1401, 2.1007],\n",
      "        [2.2136, 2.6456],\n",
      "        [2.8677, 2.1763],\n",
      "        [2.5814, 2.3082],\n",
      "        [2.8080, 2.4125],\n",
      "        [2.7504, 2.6439],\n",
      "        [2.6701, 2.5487],\n",
      "        [2.5840, 2.3054],\n",
      "        [2.5940, 2.4153],\n",
      "        [2.4946, 2.9023],\n",
      "        [2.5324, 2.7577],\n",
      "        [2.5157, 2.4278],\n",
      "        [2.2599, 2.6812],\n",
      "        [2.9635, 2.6919],\n",
      "        [2.6620, 2.6003],\n",
      "        [2.2409, 2.5540],\n",
      "        [2.5734, 2.3671],\n",
      "        [2.6322, 2.6007],\n",
      "        [2.4000, 2.8768],\n",
      "        [2.5976, 2.5052],\n",
      "        [2.4643, 2.5789],\n",
      "        [2.7364, 2.4542],\n",
      "        [2.4937, 2.7452],\n",
      "        [2.7776, 2.2423],\n",
      "        [2.5529, 2.6401],\n",
      "        [2.8103, 2.8525],\n",
      "        [1.7623, 2.6647],\n",
      "        [2.6144, 2.7776],\n",
      "        [2.5654, 2.5097],\n",
      "        [2.4822, 2.2836],\n",
      "        [2.9062, 2.2885],\n",
      "        [2.6379, 2.5096],\n",
      "        [2.6017, 2.8795],\n",
      "        [2.2561, 3.0507],\n",
      "        [2.6467, 2.5308],\n",
      "        [2.4103, 2.7371],\n",
      "        [2.2070, 3.0241],\n",
      "        [2.0510, 2.6085],\n",
      "        [2.6577, 2.3447],\n",
      "        [2.6197, 2.3619],\n",
      "        [2.4031, 2.9872],\n",
      "        [2.4287, 2.3639],\n",
      "        [2.3433, 2.2133],\n",
      "        [2.3500, 3.0412],\n",
      "        [2.7810, 2.2376],\n",
      "        [2.4908, 2.5493],\n",
      "        [2.4530, 2.3694],\n",
      "        [2.5460, 2.6436],\n",
      "        [1.9895, 2.8960],\n",
      "        [2.2509, 2.8451],\n",
      "        [2.6937, 2.4359],\n",
      "        [2.8577, 2.3710],\n",
      "        [2.7166, 3.2273],\n",
      "        [2.4956, 3.2466],\n",
      "        [3.0260, 2.7655],\n",
      "        [2.6117, 2.4710],\n",
      "        [2.4124, 2.7727],\n",
      "        [2.1384, 2.4983],\n",
      "        [2.9622, 2.3182],\n",
      "        [2.1977, 2.2276],\n",
      "        [2.7457, 2.5156],\n",
      "        [2.6871, 2.4329],\n",
      "        [2.2663, 2.3234],\n",
      "        [2.3159, 2.4786],\n",
      "        [1.9112, 2.5452],\n",
      "        [2.5068, 2.2316],\n",
      "        [2.2256, 2.3900],\n",
      "        [2.2978, 1.9944],\n",
      "        [2.9137, 2.9034],\n",
      "        [2.4021, 2.4949],\n",
      "        [2.4616, 2.3619],\n",
      "        [3.0438, 2.8140],\n",
      "        [2.5148, 2.7854],\n",
      "        [2.4766, 2.5349],\n",
      "        [2.6235, 2.5971],\n",
      "        [2.4926, 2.9129],\n",
      "        [2.7524, 2.6023],\n",
      "        [3.3707, 2.4336],\n",
      "        [2.8266, 2.4932],\n",
      "        [2.3471, 3.0576],\n",
      "        [2.5715, 2.3203],\n",
      "        [3.0952, 2.7551],\n",
      "        [2.5643, 2.7637],\n",
      "        [2.2813, 2.3322]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.2215, 2.5289],\n",
      "        [2.5739, 2.7266],\n",
      "        [2.0208, 2.6247],\n",
      "        [2.8596, 2.2906],\n",
      "        [2.3643, 2.9127],\n",
      "        [2.5174, 2.6011],\n",
      "        [2.6883, 2.5279],\n",
      "        [2.6413, 2.7505],\n",
      "        [3.1348, 2.7869],\n",
      "        [2.4923, 2.5272],\n",
      "        [2.3542, 2.5148],\n",
      "        [2.1545, 2.7553],\n",
      "        [2.9790, 2.5029],\n",
      "        [2.2355, 2.1750],\n",
      "        [2.3778, 2.5593],\n",
      "        [2.8628, 2.2407],\n",
      "        [2.3234, 2.4148],\n",
      "        [2.6617, 2.6232],\n",
      "        [2.8141, 2.9290],\n",
      "        [2.7467, 2.8375],\n",
      "        [2.5395, 2.5472],\n",
      "        [2.3816, 2.5477],\n",
      "        [2.5454, 2.4665],\n",
      "        [2.4898, 2.7050],\n",
      "        [2.0271, 2.2905],\n",
      "        [2.5480, 2.8200],\n",
      "        [2.3777, 2.5855],\n",
      "        [2.1670, 2.2212],\n",
      "        [2.5164, 2.5803],\n",
      "        [2.5609, 2.8647],\n",
      "        [2.5411, 2.5184],\n",
      "        [2.1994, 2.5698],\n",
      "        [2.5239, 2.5838],\n",
      "        [2.6987, 2.2312],\n",
      "        [2.3698, 2.3099],\n",
      "        [2.7429, 2.5056],\n",
      "        [2.1547, 2.6712],\n",
      "        [2.7090, 2.6865],\n",
      "        [2.0374, 2.4020],\n",
      "        [2.7698, 2.7329],\n",
      "        [2.4334, 2.5772],\n",
      "        [2.0249, 2.7212],\n",
      "        [2.7065, 2.3473],\n",
      "        [2.4123, 2.7200],\n",
      "        [2.4541, 2.6049],\n",
      "        [2.4656, 2.7989],\n",
      "        [2.7060, 2.2107],\n",
      "        [3.0114, 2.3557],\n",
      "        [2.7937, 2.5097],\n",
      "        [3.3689, 2.8359],\n",
      "        [2.4668, 3.0018],\n",
      "        [2.3346, 2.8373],\n",
      "        [2.3735, 2.5133],\n",
      "        [2.4265, 2.7009],\n",
      "        [2.8231, 2.4431],\n",
      "        [2.5307, 2.5233],\n",
      "        [2.7187, 2.3547],\n",
      "        [2.6359, 3.2914],\n",
      "        [2.7476, 3.1975],\n",
      "        [2.8311, 2.9516],\n",
      "        [2.0616, 2.5103],\n",
      "        [2.3815, 3.1148],\n",
      "        [2.2651, 2.7286],\n",
      "        [2.8262, 2.3761],\n",
      "        [2.0677, 2.3122],\n",
      "        [2.8611, 2.6705],\n",
      "        [2.6182, 2.5157],\n",
      "        [2.5189, 2.4305],\n",
      "        [2.4657, 3.0233],\n",
      "        [2.5591, 2.3014],\n",
      "        [2.2766, 2.5145],\n",
      "        [2.4842, 2.4586],\n",
      "        [2.7076, 2.3659],\n",
      "        [2.4869, 2.0124],\n",
      "        [2.5940, 2.7370],\n",
      "        [2.4975, 2.9480],\n",
      "        [2.7315, 2.5288],\n",
      "        [2.8254, 2.9201],\n",
      "        [2.4273, 2.3806],\n",
      "        [2.8690, 2.8136],\n",
      "        [2.5216, 2.8526],\n",
      "        [2.3986, 2.3122],\n",
      "        [2.5597, 2.5239],\n",
      "        [2.7749, 2.4073],\n",
      "        [2.0449, 2.5800],\n",
      "        [2.0464, 2.0112],\n",
      "        [2.5108, 2.5577],\n",
      "        [2.4307, 2.3011],\n",
      "        [2.8173, 2.5206],\n",
      "        [2.8820, 3.0099],\n",
      "        [2.5764, 2.4809],\n",
      "        [2.1253, 2.6033],\n",
      "        [2.6501, 2.7479],\n",
      "        [2.1891, 3.1141],\n",
      "        [2.5083, 2.3905],\n",
      "        [2.8799, 2.2514],\n",
      "        [2.8142, 2.8436],\n",
      "        [2.6136, 2.5342],\n",
      "        [2.5773, 2.4504],\n",
      "        [2.4496, 2.4129]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 90 complete in 0:04:10.620993; est. finish at 2021-11-29 21:55:59.306463\n",
      "Validation: 0.506 train | 0.464 dev\n",
      "### Epoch: 91 ###\n",
      "y:  tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6628, 2.5982],\n",
      "        [2.7525, 2.9847],\n",
      "        [2.8360, 2.5479],\n",
      "        [2.7121, 2.1528],\n",
      "        [2.3266, 2.2604],\n",
      "        [2.4932, 2.4472],\n",
      "        [2.6412, 2.2204],\n",
      "        [2.5949, 2.0548],\n",
      "        [2.7448, 3.1177],\n",
      "        [2.3293, 2.4237],\n",
      "        [2.6112, 2.5303],\n",
      "        [2.2937, 2.7135],\n",
      "        [2.0861, 2.0734],\n",
      "        [2.7083, 2.7496],\n",
      "        [2.8846, 2.6552],\n",
      "        [2.4036, 2.1603],\n",
      "        [2.8750, 2.5108],\n",
      "        [2.3604, 3.0988],\n",
      "        [2.5348, 2.3455],\n",
      "        [2.7126, 2.5114],\n",
      "        [2.6416, 2.4985],\n",
      "        [2.6749, 2.8836],\n",
      "        [2.3116, 2.7065],\n",
      "        [2.1762, 2.4420],\n",
      "        [2.8184, 2.5062],\n",
      "        [2.5993, 2.3238],\n",
      "        [2.5937, 2.6176],\n",
      "        [2.4575, 2.7978],\n",
      "        [3.1298, 2.6138],\n",
      "        [2.4445, 2.6241],\n",
      "        [2.0878, 2.4470],\n",
      "        [2.6774, 2.1590],\n",
      "        [2.2040, 2.2404],\n",
      "        [2.0378, 1.9979],\n",
      "        [2.3931, 2.3552],\n",
      "        [2.0084, 2.4277],\n",
      "        [2.6325, 2.6576],\n",
      "        [2.5985, 2.2433],\n",
      "        [2.4962, 2.8449],\n",
      "        [2.8836, 2.4473],\n",
      "        [2.3772, 2.3218],\n",
      "        [2.2847, 2.4925],\n",
      "        [2.6140, 2.7315],\n",
      "        [2.6268, 2.4706],\n",
      "        [2.1677, 2.3897],\n",
      "        [2.5071, 2.7655],\n",
      "        [2.9711, 2.1018],\n",
      "        [2.4239, 2.3724],\n",
      "        [2.3362, 2.5476],\n",
      "        [2.6557, 2.4788],\n",
      "        [2.5335, 2.6654],\n",
      "        [2.2088, 2.3513],\n",
      "        [2.4128, 2.6704],\n",
      "        [2.8867, 2.8245],\n",
      "        [2.3688, 2.3563],\n",
      "        [2.5509, 2.6456],\n",
      "        [2.9037, 2.8667],\n",
      "        [2.8600, 2.3380],\n",
      "        [2.6397, 2.5192],\n",
      "        [2.3020, 2.4114],\n",
      "        [2.8509, 2.2114],\n",
      "        [2.8777, 2.5894],\n",
      "        [2.6151, 2.5960],\n",
      "        [2.7452, 2.3541],\n",
      "        [2.7771, 2.7306],\n",
      "        [2.3980, 2.5733],\n",
      "        [2.8324, 2.2810],\n",
      "        [2.8928, 2.4462],\n",
      "        [2.4170, 2.5787],\n",
      "        [2.6892, 2.2725],\n",
      "        [2.7202, 2.6881],\n",
      "        [2.4759, 1.8929],\n",
      "        [2.7901, 2.6714],\n",
      "        [2.3813, 2.6799],\n",
      "        [2.6513, 2.9314],\n",
      "        [2.9875, 2.6670],\n",
      "        [1.9523, 2.6325],\n",
      "        [2.8567, 2.6188],\n",
      "        [2.5496, 2.6695],\n",
      "        [2.4806, 2.4470],\n",
      "        [1.8608, 2.6532],\n",
      "        [2.5504, 2.6808],\n",
      "        [2.6454, 3.0725],\n",
      "        [2.3652, 2.3604],\n",
      "        [2.8463, 2.6139],\n",
      "        [2.5828, 2.1567],\n",
      "        [3.0062, 2.1471],\n",
      "        [2.6433, 2.8678],\n",
      "        [2.5791, 2.3674],\n",
      "        [2.6722, 2.1479],\n",
      "        [2.6780, 2.5150],\n",
      "        [3.0942, 2.4590],\n",
      "        [2.6267, 2.3826],\n",
      "        [2.9984, 2.8362],\n",
      "        [2.2633, 2.6694],\n",
      "        [2.5470, 2.9263],\n",
      "        [2.6117, 2.7144],\n",
      "        [2.3150, 2.2462],\n",
      "        [2.2565, 2.6912],\n",
      "        [2.4851, 1.9977]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7290, 2.6374],\n",
      "        [2.8254, 2.0153],\n",
      "        [2.5082, 2.4136],\n",
      "        [2.2095, 2.6431],\n",
      "        [2.5793, 2.0804],\n",
      "        [2.3805, 2.4691],\n",
      "        [2.6205, 2.8291],\n",
      "        [2.6958, 2.5124],\n",
      "        [2.6904, 2.5848],\n",
      "        [2.6670, 2.5972],\n",
      "        [2.7087, 2.4381],\n",
      "        [2.3202, 2.8159],\n",
      "        [2.4660, 2.4030],\n",
      "        [2.0763, 2.7271],\n",
      "        [2.8912, 2.4690],\n",
      "        [2.8586, 2.6690],\n",
      "        [2.3374, 2.5901],\n",
      "        [2.6214, 2.5860],\n",
      "        [2.3749, 2.4574],\n",
      "        [2.7089, 2.8444],\n",
      "        [2.4913, 2.7455],\n",
      "        [2.3658, 2.4567],\n",
      "        [2.9817, 2.6054],\n",
      "        [2.3264, 2.5945],\n",
      "        [2.4457, 2.8259],\n",
      "        [2.1644, 2.4632],\n",
      "        [2.6085, 2.3022],\n",
      "        [2.9352, 2.8110],\n",
      "        [2.3638, 3.0799],\n",
      "        [2.7365, 2.3071],\n",
      "        [2.4798, 2.6248],\n",
      "        [2.5084, 2.9703],\n",
      "        [2.0210, 2.6331],\n",
      "        [2.3353, 2.8091],\n",
      "        [2.4359, 2.8989],\n",
      "        [2.8675, 2.1765],\n",
      "        [2.6123, 2.6538],\n",
      "        [2.7927, 2.4345],\n",
      "        [2.8909, 2.6848],\n",
      "        [2.5118, 2.6245],\n",
      "        [2.7503, 2.5589],\n",
      "        [2.3361, 2.7928],\n",
      "        [2.2497, 2.4213],\n",
      "        [2.3415, 2.5051],\n",
      "        [2.3374, 2.4002],\n",
      "        [2.4692, 2.3911],\n",
      "        [3.4035, 2.5878],\n",
      "        [2.5431, 2.7989],\n",
      "        [2.4111, 2.1532],\n",
      "        [2.3824, 2.3819],\n",
      "        [2.5455, 2.4388],\n",
      "        [2.5461, 2.5843],\n",
      "        [2.2782, 2.3631],\n",
      "        [2.4840, 1.9622],\n",
      "        [2.5600, 2.2058],\n",
      "        [2.8990, 2.7669],\n",
      "        [2.9058, 2.7233],\n",
      "        [2.4380, 2.5798],\n",
      "        [2.4013, 2.9464],\n",
      "        [2.7088, 2.5206],\n",
      "        [2.4043, 2.2980],\n",
      "        [2.8433, 3.0250],\n",
      "        [2.6713, 2.2386],\n",
      "        [2.4529, 2.6821],\n",
      "        [2.4819, 2.5726],\n",
      "        [2.3897, 2.4257],\n",
      "        [2.7746, 2.5308],\n",
      "        [2.5162, 2.5215],\n",
      "        [2.4499, 2.2690],\n",
      "        [1.9670, 2.8887],\n",
      "        [2.2180, 3.1162],\n",
      "        [2.9998, 2.5558],\n",
      "        [2.8095, 2.6464],\n",
      "        [2.4828, 2.4275],\n",
      "        [2.8034, 2.3507],\n",
      "        [2.6736, 2.6179],\n",
      "        [2.4653, 2.4048],\n",
      "        [2.4760, 2.7263],\n",
      "        [2.6766, 3.0223],\n",
      "        [2.7987, 2.9646],\n",
      "        [2.6728, 2.4605],\n",
      "        [2.5411, 2.3164],\n",
      "        [2.9605, 2.1370],\n",
      "        [2.4184, 2.8301],\n",
      "        [2.8901, 2.4369],\n",
      "        [2.5120, 2.3877],\n",
      "        [2.0030, 2.5739],\n",
      "        [2.7089, 1.9912],\n",
      "        [2.6466, 2.1504],\n",
      "        [2.3896, 2.7879],\n",
      "        [2.6008, 2.2510],\n",
      "        [2.9456, 1.9565],\n",
      "        [2.7020, 2.3798],\n",
      "        [2.0725, 2.3169],\n",
      "        [3.1300, 2.3903],\n",
      "        [2.7055, 1.8581],\n",
      "        [2.6862, 2.6284],\n",
      "        [2.3066, 2.6749],\n",
      "        [2.9106, 2.8091],\n",
      "        [2.4122, 2.4973]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6893, 2.7567],\n",
      "        [2.7448, 2.4236],\n",
      "        [2.3200, 2.4673],\n",
      "        [2.5364, 2.8204],\n",
      "        [2.3627, 3.0462],\n",
      "        [2.6235, 2.8588],\n",
      "        [2.4174, 2.7958],\n",
      "        [2.9029, 2.3719],\n",
      "        [2.2371, 2.3058],\n",
      "        [2.7736, 2.9906],\n",
      "        [2.4118, 2.5215],\n",
      "        [2.3035, 2.5804],\n",
      "        [2.8496, 2.6256],\n",
      "        [2.6057, 3.1087],\n",
      "        [2.5075, 2.9390],\n",
      "        [2.9553, 2.1237],\n",
      "        [2.4666, 2.6544],\n",
      "        [1.9909, 2.5254],\n",
      "        [2.3322, 2.2810],\n",
      "        [2.7558, 2.7931],\n",
      "        [2.2935, 2.3642],\n",
      "        [2.8470, 2.2452],\n",
      "        [2.6012, 2.6507],\n",
      "        [2.7126, 2.7782],\n",
      "        [2.7004, 2.3962],\n",
      "        [2.4367, 2.2426],\n",
      "        [2.6691, 2.5733],\n",
      "        [2.8781, 2.2630],\n",
      "        [2.9364, 2.2473],\n",
      "        [2.6465, 2.2254],\n",
      "        [2.2008, 2.2045],\n",
      "        [2.3703, 2.5158],\n",
      "        [2.5013, 2.5848],\n",
      "        [2.7795, 2.1744],\n",
      "        [2.2419, 2.5658],\n",
      "        [2.6143, 2.3969],\n",
      "        [2.7499, 2.2421],\n",
      "        [2.7751, 2.4082],\n",
      "        [2.5130, 2.2963],\n",
      "        [2.8861, 2.4598],\n",
      "        [2.3096, 2.7259],\n",
      "        [2.4822, 2.1252],\n",
      "        [2.6818, 2.2520],\n",
      "        [2.3935, 2.6589],\n",
      "        [2.5149, 2.1170],\n",
      "        [2.4889, 2.3875],\n",
      "        [2.3485, 2.5809],\n",
      "        [2.6336, 2.6375],\n",
      "        [2.4722, 2.4864],\n",
      "        [2.3418, 2.3705],\n",
      "        [2.4422, 2.4723],\n",
      "        [2.8745, 2.3191],\n",
      "        [2.1044, 3.0531],\n",
      "        [2.2501, 2.8570],\n",
      "        [2.7800, 2.4016],\n",
      "        [2.7020, 2.7536],\n",
      "        [2.5595, 2.8350],\n",
      "        [2.4291, 2.3333],\n",
      "        [2.7666, 2.6416],\n",
      "        [2.5321, 2.6505],\n",
      "        [2.4373, 2.7186],\n",
      "        [2.5765, 2.6296],\n",
      "        [2.5214, 2.8240],\n",
      "        [2.1245, 2.6759],\n",
      "        [2.4532, 2.4677],\n",
      "        [2.1407, 2.2886],\n",
      "        [2.8001, 2.5238],\n",
      "        [2.3280, 2.1961],\n",
      "        [2.2459, 1.8745],\n",
      "        [2.3965, 2.6172],\n",
      "        [2.1871, 2.4622],\n",
      "        [2.8082, 2.7929],\n",
      "        [2.5774, 2.8407],\n",
      "        [2.6348, 2.9993],\n",
      "        [2.6133, 2.4641],\n",
      "        [2.5174, 2.6995],\n",
      "        [2.7616, 2.2048],\n",
      "        [2.4831, 2.6776],\n",
      "        [2.2451, 2.9507],\n",
      "        [2.5135, 2.3701],\n",
      "        [2.6456, 2.5119],\n",
      "        [2.8561, 2.4860],\n",
      "        [2.6465, 2.4404],\n",
      "        [2.7395, 2.8267],\n",
      "        [2.3394, 2.5333],\n",
      "        [2.5823, 2.5459],\n",
      "        [2.6148, 2.6646],\n",
      "        [2.5959, 2.5923],\n",
      "        [2.1844, 2.9585],\n",
      "        [2.5455, 2.8982],\n",
      "        [2.4947, 2.3443],\n",
      "        [2.5920, 2.6285],\n",
      "        [2.1953, 2.6598],\n",
      "        [2.4642, 2.5933],\n",
      "        [2.5282, 2.4276],\n",
      "        [2.5836, 2.1330],\n",
      "        [2.5718, 2.6615],\n",
      "        [2.5694, 2.7079],\n",
      "        [2.2504, 2.0445],\n",
      "        [2.9246, 2.9101]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.7346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.7017, 2.4849],\n",
      "        [2.4240, 2.5224],\n",
      "        [2.6216, 3.0488],\n",
      "        [2.6148, 2.7203],\n",
      "        [2.3286, 2.8494],\n",
      "        [2.2854, 2.7730],\n",
      "        [2.2571, 2.5866],\n",
      "        [2.7645, 2.3913],\n",
      "        [2.6710, 3.0792],\n",
      "        [2.8650, 2.6079],\n",
      "        [2.1566, 2.9109],\n",
      "        [2.6517, 2.3755],\n",
      "        [2.3657, 2.5918],\n",
      "        [2.7676, 2.4281],\n",
      "        [2.6137, 2.6542],\n",
      "        [2.4601, 2.4637],\n",
      "        [2.5498, 2.8271],\n",
      "        [2.3546, 2.7489],\n",
      "        [2.4891, 3.0433],\n",
      "        [2.4090, 2.0964],\n",
      "        [2.2041, 2.8196],\n",
      "        [2.6195, 2.4889],\n",
      "        [2.5694, 2.3823],\n",
      "        [3.4611, 2.6171],\n",
      "        [1.9774, 2.3442],\n",
      "        [2.1767, 2.2656],\n",
      "        [2.5192, 2.4609],\n",
      "        [2.4731, 2.3188],\n",
      "        [2.3747, 2.7098],\n",
      "        [2.3154, 2.1134],\n",
      "        [2.6440, 2.6305],\n",
      "        [2.9722, 2.1601],\n",
      "        [2.5070, 2.2780],\n",
      "        [2.3591, 2.4480],\n",
      "        [1.9271, 2.6509],\n",
      "        [2.6517, 2.2995],\n",
      "        [2.6465, 2.4793],\n",
      "        [2.4014, 2.4174],\n",
      "        [2.6063, 2.8938],\n",
      "        [2.4239, 2.7659],\n",
      "        [2.7482, 2.3182],\n",
      "        [2.4840, 2.8479],\n",
      "        [2.7109, 2.3211],\n",
      "        [1.8496, 2.8434],\n",
      "        [2.3852, 2.6192],\n",
      "        [2.3245, 1.9878],\n",
      "        [2.5670, 2.4943],\n",
      "        [2.5845, 2.6685],\n",
      "        [2.5087, 2.5957],\n",
      "        [2.1706, 2.6112],\n",
      "        [2.6142, 2.8783],\n",
      "        [2.5012, 2.5691],\n",
      "        [2.4296, 2.5208],\n",
      "        [2.6260, 2.4902],\n",
      "        [2.5539, 2.6435],\n",
      "        [2.4079, 2.6796],\n",
      "        [2.1893, 2.2826],\n",
      "        [3.1315, 2.2869],\n",
      "        [2.9120, 2.9663],\n",
      "        [2.4493, 2.7784],\n",
      "        [2.5892, 2.3220],\n",
      "        [2.7657, 2.5441],\n",
      "        [2.2046, 2.5414],\n",
      "        [2.5595, 2.8489],\n",
      "        [2.2756, 2.3835],\n",
      "        [2.4091, 3.0218],\n",
      "        [2.3165, 2.7557],\n",
      "        [2.9593, 2.6523],\n",
      "        [2.5439, 2.4677],\n",
      "        [2.2220, 2.7579],\n",
      "        [2.4982, 3.0345],\n",
      "        [2.2590, 2.2742],\n",
      "        [2.2998, 2.4258],\n",
      "        [2.4448, 2.6518],\n",
      "        [2.5961, 2.3359],\n",
      "        [3.1321, 2.5373],\n",
      "        [2.2473, 2.5834],\n",
      "        [2.3986, 3.0225],\n",
      "        [2.2293, 2.2862],\n",
      "        [2.8216, 2.5347],\n",
      "        [2.3667, 2.0005],\n",
      "        [2.5186, 2.3731],\n",
      "        [2.2850, 2.1931],\n",
      "        [2.5009, 2.4633],\n",
      "        [2.5587, 2.7186],\n",
      "        [2.2899, 3.0358],\n",
      "        [2.5637, 2.5974],\n",
      "        [2.1585, 2.6985],\n",
      "        [2.6947, 2.7611],\n",
      "        [2.3115, 2.2250],\n",
      "        [2.3628, 2.5053],\n",
      "        [2.6549, 2.3096],\n",
      "        [2.5819, 2.4304],\n",
      "        [2.7150, 2.3221],\n",
      "        [2.8409, 2.0059],\n",
      "        [2.6256, 2.4821],\n",
      "        [2.8351, 2.8001],\n",
      "        [2.5449, 2.6678],\n",
      "        [2.7924, 2.8647],\n",
      "        [2.4561, 2.3785]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5709, 2.0647],\n",
      "        [2.5306, 2.5397],\n",
      "        [2.7919, 2.6862],\n",
      "        [2.7157, 2.4815],\n",
      "        [2.1440, 2.3478],\n",
      "        [2.6973, 2.7382],\n",
      "        [2.8505, 2.5918],\n",
      "        [2.6066, 2.5410],\n",
      "        [2.1976, 2.2833],\n",
      "        [2.3698, 1.8446],\n",
      "        [2.3081, 2.5353],\n",
      "        [2.5338, 2.5178],\n",
      "        [2.9680, 2.6011],\n",
      "        [2.7297, 2.0711],\n",
      "        [2.6206, 2.9156],\n",
      "        [2.4198, 2.5038],\n",
      "        [2.4670, 2.4716],\n",
      "        [3.0076, 2.0664],\n",
      "        [2.3535, 2.9894],\n",
      "        [2.2534, 2.6158],\n",
      "        [2.7753, 2.8386],\n",
      "        [2.3013, 2.3716],\n",
      "        [3.2156, 2.5425],\n",
      "        [2.7455, 2.3001],\n",
      "        [2.3585, 2.3948],\n",
      "        [2.3358, 2.7529],\n",
      "        [2.6714, 1.8745],\n",
      "        [2.3312, 2.2460],\n",
      "        [3.0753, 2.3572],\n",
      "        [2.1730, 2.9346],\n",
      "        [2.7041, 2.5812],\n",
      "        [2.3953, 2.3619],\n",
      "        [2.6332, 2.2523],\n",
      "        [3.1926, 2.3346],\n",
      "        [2.5720, 2.1154],\n",
      "        [2.5972, 2.6256],\n",
      "        [2.9133, 2.8732],\n",
      "        [2.3776, 2.5422],\n",
      "        [2.9338, 2.5986],\n",
      "        [2.6741, 2.5039],\n",
      "        [2.2571, 2.7578],\n",
      "        [2.1930, 2.4449],\n",
      "        [2.8059, 2.4449],\n",
      "        [2.2812, 2.8590],\n",
      "        [2.7069, 2.2811],\n",
      "        [2.8172, 2.8769],\n",
      "        [2.5245, 2.2220],\n",
      "        [2.4308, 2.2097],\n",
      "        [2.5479, 2.8268],\n",
      "        [2.3002, 2.4434],\n",
      "        [2.5937, 2.3545],\n",
      "        [2.8971, 2.4645],\n",
      "        [2.7872, 2.6185],\n",
      "        [2.7104, 2.5070],\n",
      "        [2.5468, 2.3964],\n",
      "        [2.1148, 2.4513],\n",
      "        [2.8010, 2.7724],\n",
      "        [2.2987, 2.1498],\n",
      "        [2.8032, 2.2852],\n",
      "        [2.4498, 2.7617],\n",
      "        [2.5196, 2.7929],\n",
      "        [2.9050, 2.5950],\n",
      "        [2.5733, 2.8574],\n",
      "        [2.5044, 2.5952],\n",
      "        [2.6758, 2.5779],\n",
      "        [2.4601, 2.4504],\n",
      "        [2.7927, 1.8964],\n",
      "        [2.2749, 3.1700],\n",
      "        [2.4963, 2.5019],\n",
      "        [2.7463, 2.5901],\n",
      "        [2.7382, 2.5898],\n",
      "        [2.4051, 2.1787],\n",
      "        [2.7285, 2.5512],\n",
      "        [2.6264, 2.7768],\n",
      "        [2.3304, 3.0195],\n",
      "        [1.9475, 2.8464],\n",
      "        [2.6613, 2.4335],\n",
      "        [2.3180, 2.7352],\n",
      "        [2.1527, 2.8276],\n",
      "        [2.1125, 3.0722],\n",
      "        [2.7249, 2.5389],\n",
      "        [3.3448, 2.7269],\n",
      "        [2.3710, 2.8742],\n",
      "        [2.4440, 2.4889],\n",
      "        [2.4143, 2.0599],\n",
      "        [2.2662, 2.4032],\n",
      "        [2.6417, 2.4166],\n",
      "        [2.9420, 2.5687],\n",
      "        [2.3849, 2.2078],\n",
      "        [2.8349, 2.3661],\n",
      "        [2.2815, 2.6866],\n",
      "        [2.8763, 2.8531],\n",
      "        [2.9049, 1.9668],\n",
      "        [2.9133, 2.4860],\n",
      "        [2.5655, 2.7015],\n",
      "        [2.3958, 2.7359],\n",
      "        [2.3346, 2.0506],\n",
      "        [2.4991, 2.5718],\n",
      "        [2.9127, 2.4076],\n",
      "        [2.5017, 2.4287]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 95 complete in 0:04:22.643041; est. finish at 2021-11-29 21:55:57.305063\n",
      "Validation: 0.466 train | 0.514 dev\n",
      "### Epoch: 96 ###\n",
      "y:  tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6511, 2.3031],\n",
      "        [2.5463, 2.6223],\n",
      "        [2.6821, 2.6786],\n",
      "        [2.4965, 2.4005],\n",
      "        [2.4309, 2.2673],\n",
      "        [2.8579, 2.3422],\n",
      "        [2.9197, 2.7637],\n",
      "        [2.9916, 2.5876],\n",
      "        [2.7990, 2.5297],\n",
      "        [2.6975, 2.8117],\n",
      "        [2.6022, 2.4005],\n",
      "        [2.6055, 2.4577],\n",
      "        [2.4965, 2.3593],\n",
      "        [2.5368, 2.8859],\n",
      "        [2.8367, 2.1800],\n",
      "        [2.3911, 2.1818],\n",
      "        [2.3158, 2.5367],\n",
      "        [2.6374, 2.7074],\n",
      "        [2.6364, 2.6510],\n",
      "        [2.8046, 2.3446],\n",
      "        [2.3119, 2.5265],\n",
      "        [2.5587, 2.8053],\n",
      "        [2.0350, 2.5811],\n",
      "        [1.9881, 2.7473],\n",
      "        [2.4593, 2.8085],\n",
      "        [2.2890, 2.7727],\n",
      "        [2.5224, 2.7747],\n",
      "        [2.4004, 2.5602],\n",
      "        [2.6381, 2.5708],\n",
      "        [2.7588, 2.3274],\n",
      "        [2.2611, 2.5154],\n",
      "        [2.2766, 2.4708],\n",
      "        [2.5663, 2.6592],\n",
      "        [2.5414, 2.3398],\n",
      "        [2.9673, 2.6846],\n",
      "        [2.7254, 2.3947],\n",
      "        [2.9432, 2.8869],\n",
      "        [1.9081, 2.4916],\n",
      "        [2.8453, 2.5785],\n",
      "        [2.4843, 2.6748],\n",
      "        [2.8525, 2.8857],\n",
      "        [2.7711, 2.5266],\n",
      "        [2.1625, 2.8661],\n",
      "        [2.7852, 2.5462],\n",
      "        [2.6326, 2.4039],\n",
      "        [2.5788, 2.0775],\n",
      "        [2.1808, 2.6390],\n",
      "        [2.8836, 2.5576],\n",
      "        [2.4199, 2.1478],\n",
      "        [2.5242, 2.4213],\n",
      "        [1.9432, 2.7314],\n",
      "        [2.8510, 2.7854],\n",
      "        [2.3394, 2.4554],\n",
      "        [2.4977, 3.1513],\n",
      "        [2.5633, 2.6732],\n",
      "        [2.9468, 2.2550],\n",
      "        [2.4939, 2.6531],\n",
      "        [2.5660, 2.7742],\n",
      "        [2.4289, 2.6814],\n",
      "        [2.6033, 2.5292],\n",
      "        [2.3201, 2.3111],\n",
      "        [2.7795, 2.6470],\n",
      "        [2.6594, 2.6707],\n",
      "        [2.3619, 2.4991],\n",
      "        [2.3565, 2.6390],\n",
      "        [2.5033, 2.6328],\n",
      "        [2.1790, 3.2347],\n",
      "        [2.7594, 2.5525],\n",
      "        [2.2929, 2.2594],\n",
      "        [2.7305, 2.3828],\n",
      "        [2.3765, 2.3148],\n",
      "        [2.6667, 2.5332],\n",
      "        [2.6437, 2.4008],\n",
      "        [2.3439, 2.3711],\n",
      "        [2.4242, 2.4128],\n",
      "        [2.8352, 2.6670],\n",
      "        [2.3900, 2.7073],\n",
      "        [2.5808, 2.2298],\n",
      "        [3.0290, 2.3582],\n",
      "        [2.4845, 2.5930],\n",
      "        [2.2104, 2.3317],\n",
      "        [2.1925, 2.4786],\n",
      "        [2.5341, 2.4090],\n",
      "        [2.8819, 2.6364],\n",
      "        [2.0985, 2.6797],\n",
      "        [2.8330, 2.4006],\n",
      "        [2.5751, 2.4160],\n",
      "        [2.8242, 2.7794],\n",
      "        [2.4724, 2.3378],\n",
      "        [2.5257, 2.6571],\n",
      "        [2.5281, 2.0608],\n",
      "        [2.4467, 2.2637],\n",
      "        [2.6530, 2.6612],\n",
      "        [2.9607, 2.7790],\n",
      "        [2.3457, 2.6874],\n",
      "        [2.8935, 2.6329],\n",
      "        [2.2160, 2.3697],\n",
      "        [2.9658, 2.9867],\n",
      "        [2.5752, 2.4056],\n",
      "        [2.3152, 2.6400]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.5857, 2.3053],\n",
      "        [2.9665, 2.8104],\n",
      "        [2.3361, 2.3114],\n",
      "        [2.5778, 2.8599],\n",
      "        [2.8442, 3.2296],\n",
      "        [2.4412, 2.4544],\n",
      "        [2.2305, 2.3776],\n",
      "        [2.6661, 2.6659],\n",
      "        [2.7031, 2.2399],\n",
      "        [2.9668, 2.4358],\n",
      "        [2.4611, 2.6100],\n",
      "        [2.4278, 2.3337],\n",
      "        [2.6528, 2.8197],\n",
      "        [2.1832, 2.7964],\n",
      "        [2.0607, 2.6458],\n",
      "        [2.4986, 2.7688],\n",
      "        [2.7914, 2.2421],\n",
      "        [2.1765, 2.6771],\n",
      "        [2.5158, 2.5898],\n",
      "        [2.6446, 2.6949],\n",
      "        [2.3538, 2.6171],\n",
      "        [2.6062, 2.1827],\n",
      "        [2.5490, 2.6606],\n",
      "        [2.5156, 2.2133],\n",
      "        [2.5065, 2.6615],\n",
      "        [2.7058, 2.2803],\n",
      "        [2.4448, 2.4709],\n",
      "        [2.4442, 2.3169],\n",
      "        [2.7395, 2.8327],\n",
      "        [2.3299, 2.2228],\n",
      "        [2.6789, 2.5101],\n",
      "        [2.3616, 2.4208],\n",
      "        [2.2493, 2.2656],\n",
      "        [2.7511, 2.5166],\n",
      "        [2.6083, 2.5633],\n",
      "        [2.8046, 2.8800],\n",
      "        [2.3901, 2.5805],\n",
      "        [2.2928, 2.4019],\n",
      "        [2.6259, 2.6072],\n",
      "        [2.4349, 2.9278],\n",
      "        [2.4353, 2.3779],\n",
      "        [2.3981, 2.5094],\n",
      "        [2.2248, 2.4475],\n",
      "        [2.3031, 2.3163],\n",
      "        [2.8820, 2.1674],\n",
      "        [2.5868, 2.6020],\n",
      "        [2.5775, 2.9237],\n",
      "        [2.4934, 2.7433],\n",
      "        [2.4403, 2.8150],\n",
      "        [2.5753, 2.5163],\n",
      "        [2.5629, 2.7412],\n",
      "        [2.3132, 3.2341],\n",
      "        [2.7901, 2.6928],\n",
      "        [2.4163, 2.7241],\n",
      "        [2.9282, 2.2435],\n",
      "        [2.6886, 2.3582],\n",
      "        [2.1584, 2.3018],\n",
      "        [1.8558, 2.5127],\n",
      "        [2.3972, 2.5568],\n",
      "        [2.0933, 2.4655],\n",
      "        [2.0204, 2.9850],\n",
      "        [2.4893, 2.5436],\n",
      "        [2.5724, 2.5259],\n",
      "        [2.8540, 2.6422],\n",
      "        [2.7329, 2.4172],\n",
      "        [2.5174, 2.5131],\n",
      "        [2.4455, 2.4384],\n",
      "        [2.5185, 2.8132],\n",
      "        [2.9373, 2.5682],\n",
      "        [2.5062, 2.1839],\n",
      "        [2.2401, 2.1620],\n",
      "        [2.7041, 2.8365],\n",
      "        [2.6936, 2.4527],\n",
      "        [2.7807, 2.4998],\n",
      "        [2.3316, 2.4460],\n",
      "        [2.6873, 2.2735],\n",
      "        [2.6149, 2.6840],\n",
      "        [2.6937, 2.4592],\n",
      "        [2.1507, 2.5600],\n",
      "        [2.1661, 2.8495],\n",
      "        [2.6752, 2.4846],\n",
      "        [2.3454, 2.6569],\n",
      "        [2.6004, 2.6862],\n",
      "        [2.3711, 2.8367],\n",
      "        [2.6000, 2.4359],\n",
      "        [2.6770, 2.1678],\n",
      "        [2.3607, 2.4534],\n",
      "        [2.6241, 2.4516],\n",
      "        [2.3387, 2.1771],\n",
      "        [2.4230, 2.6841],\n",
      "        [2.7501, 2.8212],\n",
      "        [2.1250, 2.3439],\n",
      "        [2.7410, 2.5404],\n",
      "        [2.8258, 2.6816],\n",
      "        [2.5439, 2.5133],\n",
      "        [2.0800, 2.4174],\n",
      "        [2.9440, 2.2659],\n",
      "        [2.9076, 2.4701],\n",
      "        [2.6584, 2.5433],\n",
      "        [2.3049, 2.9558]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.7060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.3996, 2.6202],\n",
      "        [2.6695, 2.8216],\n",
      "        [2.5847, 2.8061],\n",
      "        [2.5785, 3.1780],\n",
      "        [3.0746, 2.6156],\n",
      "        [2.2408, 2.9632],\n",
      "        [2.3990, 2.6228],\n",
      "        [2.6931, 2.5470],\n",
      "        [3.0482, 2.4969],\n",
      "        [2.7709, 2.7096],\n",
      "        [2.6926, 2.7916],\n",
      "        [2.4890, 2.3873],\n",
      "        [3.0317, 2.3212],\n",
      "        [2.8497, 2.6627],\n",
      "        [2.4795, 2.2043],\n",
      "        [1.8708, 2.3114],\n",
      "        [2.4286, 2.8743],\n",
      "        [2.6802, 2.6913],\n",
      "        [2.7854, 2.4359],\n",
      "        [2.6670, 2.4870],\n",
      "        [2.4690, 2.6948],\n",
      "        [2.3459, 2.4962],\n",
      "        [2.6353, 2.5092],\n",
      "        [2.6371, 3.0191],\n",
      "        [2.2097, 2.5958],\n",
      "        [2.3773, 2.4995],\n",
      "        [2.3064, 2.9766],\n",
      "        [2.5566, 2.4613],\n",
      "        [2.5678, 2.6264],\n",
      "        [2.3061, 2.4218],\n",
      "        [2.4733, 2.2527],\n",
      "        [2.8682, 2.5498],\n",
      "        [2.7140, 2.2826],\n",
      "        [2.7648, 2.6985],\n",
      "        [1.9350, 2.3958],\n",
      "        [2.9528, 2.7531],\n",
      "        [2.7088, 2.5599],\n",
      "        [2.3168, 2.5469],\n",
      "        [3.0466, 2.4559],\n",
      "        [2.7829, 2.4642],\n",
      "        [2.6007, 3.0888],\n",
      "        [2.4471, 2.2619],\n",
      "        [2.4259, 2.0222],\n",
      "        [2.3470, 2.7752],\n",
      "        [2.5612, 2.3636],\n",
      "        [2.9533, 2.7772],\n",
      "        [2.6633, 2.2643],\n",
      "        [2.5332, 2.6889],\n",
      "        [2.4419, 2.8728],\n",
      "        [2.5869, 2.6956],\n",
      "        [2.7655, 2.7675],\n",
      "        [3.4529, 2.8502],\n",
      "        [3.1212, 2.0908],\n",
      "        [2.3904, 2.5481],\n",
      "        [2.1687, 2.4759],\n",
      "        [3.1309, 1.9754],\n",
      "        [2.0979, 2.2519],\n",
      "        [2.3938, 2.4720],\n",
      "        [2.9575, 2.6140],\n",
      "        [2.5435, 2.2317],\n",
      "        [2.9070, 2.4467],\n",
      "        [2.7538, 3.2202],\n",
      "        [2.4358, 2.9876],\n",
      "        [2.6086, 2.2890],\n",
      "        [2.4281, 2.2974],\n",
      "        [2.2297, 2.9035],\n",
      "        [2.4756, 2.9914],\n",
      "        [2.5865, 2.6225],\n",
      "        [2.4981, 2.8302],\n",
      "        [2.1806, 2.7703],\n",
      "        [2.4373, 2.6517],\n",
      "        [2.0723, 2.7884],\n",
      "        [2.4069, 2.8978],\n",
      "        [2.6827, 1.9905],\n",
      "        [2.3369, 2.2576],\n",
      "        [2.8416, 2.8403],\n",
      "        [2.7319, 2.7898],\n",
      "        [2.1944, 2.5925],\n",
      "        [2.5132, 2.4155],\n",
      "        [2.9155, 2.2576],\n",
      "        [2.3424, 2.6099],\n",
      "        [2.5476, 2.3080],\n",
      "        [2.7454, 2.5776],\n",
      "        [2.6965, 2.1679],\n",
      "        [2.6207, 3.2811],\n",
      "        [2.4676, 2.5947],\n",
      "        [2.4427, 2.3278],\n",
      "        [2.3434, 2.3056],\n",
      "        [2.6614, 2.5700],\n",
      "        [2.7672, 2.4255],\n",
      "        [2.2273, 2.7506],\n",
      "        [2.6136, 2.7024],\n",
      "        [2.4913, 3.0666],\n",
      "        [3.0835, 2.6751],\n",
      "        [2.7985, 2.8432],\n",
      "        [2.3388, 3.0517],\n",
      "        [2.6217, 2.2620],\n",
      "        [2.8737, 2.4973],\n",
      "        [2.1711, 2.2452],\n",
      "        [2.9561, 2.2600]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0], device='cuda:0')\n",
      "out.loss:  tensor(0.6936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6408, 2.5104],\n",
      "        [2.5800, 2.1110],\n",
      "        [2.1742, 2.4974],\n",
      "        [2.7016, 2.7774],\n",
      "        [2.5178, 2.4699],\n",
      "        [2.3903, 2.0651],\n",
      "        [2.4216, 2.5311],\n",
      "        [2.4682, 2.4184],\n",
      "        [2.6771, 2.7221],\n",
      "        [2.6445, 2.0316],\n",
      "        [2.3759, 2.2109],\n",
      "        [2.5983, 2.6968],\n",
      "        [2.4964, 2.0809],\n",
      "        [2.3161, 2.4248],\n",
      "        [2.6840, 2.3049],\n",
      "        [2.3522, 2.4894],\n",
      "        [2.5935, 2.5191],\n",
      "        [2.5521, 2.5476],\n",
      "        [2.6874, 2.6936],\n",
      "        [2.8317, 2.4358],\n",
      "        [2.8319, 2.4106],\n",
      "        [2.6531, 2.8746],\n",
      "        [2.5343, 2.6239],\n",
      "        [2.5105, 2.7410],\n",
      "        [2.4975, 2.9418],\n",
      "        [2.3938, 2.5326],\n",
      "        [2.6977, 2.2216],\n",
      "        [2.3694, 2.5638],\n",
      "        [2.6661, 2.4830],\n",
      "        [2.3844, 2.5224],\n",
      "        [2.6355, 2.7190],\n",
      "        [2.4727, 2.4241],\n",
      "        [2.7547, 2.7507],\n",
      "        [3.1323, 2.3622],\n",
      "        [2.5156, 2.3753],\n",
      "        [2.5539, 2.5753],\n",
      "        [2.0593, 2.6403],\n",
      "        [2.5770, 2.6731],\n",
      "        [2.4771, 2.7524],\n",
      "        [2.4883, 2.4628],\n",
      "        [3.3448, 2.5213],\n",
      "        [1.7160, 2.6164],\n",
      "        [2.5001, 2.5366],\n",
      "        [2.2732, 2.4322],\n",
      "        [2.5407, 2.5684],\n",
      "        [2.4443, 2.2120],\n",
      "        [2.4754, 2.6924],\n",
      "        [2.4960, 2.9046],\n",
      "        [2.6941, 2.2618],\n",
      "        [2.3222, 2.4671],\n",
      "        [2.1871, 2.5639],\n",
      "        [2.5388, 2.6136],\n",
      "        [2.3583, 2.7384],\n",
      "        [2.2714, 2.3198],\n",
      "        [2.5445, 2.6349],\n",
      "        [2.6465, 2.3313],\n",
      "        [2.3930, 2.4799],\n",
      "        [2.4998, 2.3554],\n",
      "        [2.8419, 2.7156],\n",
      "        [2.3563, 2.8736],\n",
      "        [3.0339, 2.5174],\n",
      "        [2.1641, 2.7130],\n",
      "        [2.7843, 2.4314],\n",
      "        [2.2383, 2.3368],\n",
      "        [2.9322, 2.2915],\n",
      "        [2.5504, 2.5018],\n",
      "        [2.2677, 3.0654],\n",
      "        [2.3533, 2.7245],\n",
      "        [2.3733, 2.6367],\n",
      "        [2.6988, 2.6003],\n",
      "        [2.4147, 2.9550],\n",
      "        [2.5198, 2.4072],\n",
      "        [2.6320, 2.6870],\n",
      "        [2.4212, 2.4632],\n",
      "        [2.5090, 2.5446],\n",
      "        [2.6982, 2.6830],\n",
      "        [2.3495, 2.6688],\n",
      "        [2.3265, 2.7967],\n",
      "        [2.8954, 2.4387],\n",
      "        [2.4106, 2.6884],\n",
      "        [2.3434, 2.7448],\n",
      "        [2.6993, 2.8777],\n",
      "        [3.0241, 2.5269],\n",
      "        [2.4211, 2.2947],\n",
      "        [2.5920, 2.4642],\n",
      "        [2.8155, 2.6897],\n",
      "        [2.2151, 2.5022],\n",
      "        [2.4741, 2.5182],\n",
      "        [2.7167, 2.4640],\n",
      "        [2.4251, 2.7422],\n",
      "        [2.6834, 2.5054],\n",
      "        [2.8420, 2.6102],\n",
      "        [2.8160, 2.4932],\n",
      "        [2.4495, 2.8206],\n",
      "        [2.8059, 2.6371],\n",
      "        [2.5519, 2.1793],\n",
      "        [2.0924, 2.8808],\n",
      "        [2.4526, 2.7037],\n",
      "        [2.6104, 1.9898],\n",
      "        [2.3985, 2.7809]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "y:  tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1], device='cuda:0')\n",
      "out.loss:  tensor(0.6851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "out.logits:  tensor([[2.6206, 2.3545],\n",
      "        [2.6723, 2.3718],\n",
      "        [2.5599, 2.7283],\n",
      "        [2.6970, 2.2674],\n",
      "        [2.4902, 2.2374],\n",
      "        [2.3198, 2.5379],\n",
      "        [2.3035, 2.8372],\n",
      "        [2.3537, 2.3730],\n",
      "        [2.4890, 2.5658],\n",
      "        [2.2325, 2.3998],\n",
      "        [2.7376, 2.2102],\n",
      "        [2.5308, 2.7085],\n",
      "        [2.4815, 2.1646],\n",
      "        [2.6004, 2.8073],\n",
      "        [2.8420, 2.6523],\n",
      "        [2.4286, 1.7664],\n",
      "        [2.7321, 2.3286],\n",
      "        [2.7747, 2.4712],\n",
      "        [2.6298, 2.4262],\n",
      "        [2.3573, 2.4665],\n",
      "        [2.5361, 2.4120],\n",
      "        [2.8491, 2.1563],\n",
      "        [2.5592, 2.9543],\n",
      "        [1.5943, 2.6624],\n",
      "        [2.6680, 2.4848],\n",
      "        [2.6112, 2.9368],\n",
      "        [2.3507, 2.3547],\n",
      "        [2.7013, 2.5800],\n",
      "        [2.2701, 2.9282],\n",
      "        [1.9437, 2.6965],\n",
      "        [2.5537, 2.4114],\n",
      "        [2.5148, 2.6090],\n",
      "        [2.4216, 3.0194],\n",
      "        [2.1725, 2.5469],\n",
      "        [2.3863, 2.4413],\n",
      "        [2.4998, 2.5789],\n",
      "        [2.5856, 2.4741],\n",
      "        [2.1078, 2.5530],\n",
      "        [2.2700, 2.5230],\n",
      "        [2.7747, 1.9644],\n",
      "        [2.4952, 2.4908],\n",
      "        [2.6921, 2.9125],\n",
      "        [2.7468, 2.1696],\n",
      "        [2.6314, 2.7411],\n",
      "        [2.0630, 2.7159],\n",
      "        [2.5590, 1.9533],\n",
      "        [2.3449, 2.8467],\n",
      "        [2.7632, 2.8145],\n",
      "        [2.3161, 2.6405],\n",
      "        [2.6100, 2.4711],\n",
      "        [2.7240, 2.9215],\n",
      "        [2.5468, 2.9850],\n",
      "        [2.7464, 2.4533],\n",
      "        [2.8598, 2.4875],\n",
      "        [2.3648, 2.7810],\n",
      "        [2.5978, 2.7709],\n",
      "        [2.3409, 2.6423],\n",
      "        [2.7893, 2.5234],\n",
      "        [2.6358, 3.0831],\n",
      "        [2.9366, 2.1115],\n",
      "        [2.4479, 2.2290],\n",
      "        [2.1954, 2.3534],\n",
      "        [2.7782, 2.4660],\n",
      "        [2.6735, 2.6562],\n",
      "        [2.4891, 2.4403],\n",
      "        [2.8964, 2.4422],\n",
      "        [2.3936, 2.6545],\n",
      "        [2.7141, 2.2674],\n",
      "        [2.6808, 2.3367],\n",
      "        [2.8135, 2.2043],\n",
      "        [2.1348, 2.7135],\n",
      "        [2.8972, 3.0019],\n",
      "        [2.9477, 2.7579],\n",
      "        [2.2437, 2.3721],\n",
      "        [2.3047, 2.5316],\n",
      "        [2.5104, 2.6810],\n",
      "        [1.9963, 2.3155],\n",
      "        [2.3292, 2.3568],\n",
      "        [2.6269, 2.7380],\n",
      "        [2.4087, 2.4588],\n",
      "        [2.3816, 2.7542],\n",
      "        [2.7517, 2.4024],\n",
      "        [2.2165, 2.6136],\n",
      "        [2.7036, 2.2110],\n",
      "        [2.5484, 2.6603],\n",
      "        [2.8806, 2.7664],\n",
      "        [2.9569, 3.0510],\n",
      "        [2.5631, 2.8590],\n",
      "        [2.4666, 2.9531],\n",
      "        [2.4699, 2.7785],\n",
      "        [2.7047, 2.3445],\n",
      "        [2.5358, 2.4974],\n",
      "        [2.8032, 2.3566],\n",
      "        [3.0834, 2.6023],\n",
      "        [2.4510, 2.1625],\n",
      "        [2.6245, 2.3098],\n",
      "        [2.6355, 2.5425],\n",
      "        [2.0714, 2.7602],\n",
      "        [2.2705, 2.3208],\n",
      "        [2.6268, 2.4391]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Epoch 100 complete in 0:04:33.939259; est. finish at 2021-11-29 21:55:54.777963\n",
      "Validation: 0.564 train | 0.522 dev\n",
      "Training completed in 0:04:33.939259\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "teacup = RobertaForMultipleChoice(config)\n",
    "teacup.to(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 3) Now we train our model\n",
    "start_time = datetime.now()\n",
    "epochs = 100\n",
    "report_per = 5\n",
    "\n",
    "# optimizer & LR decay scheduler\n",
    "# optimizer = AdamW(teacup.parameters(), lr=3e-5)\n",
    "optimizer = AdamW(teacup.parameters(), lr=1e-2)\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "# lr_scheduler = get_scheduler(\n",
    "#     \"linear\",\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=0,\n",
    "#     num_training_steps=num_training_steps\n",
    "# )\n",
    "\n",
    "dev_acc = np.zeros(epochs // report_per)\n",
    "train_acc = np.zeros(epochs // report_per)\n",
    "\n",
    "print('Beginning training loop')\n",
    "for i in range(epochs):\n",
    "        \n",
    "    if i % report_per == 0:\n",
    "        print('### Epoch: ' + str(i+1) + ' ###')\n",
    "        \n",
    "    # train loop\n",
    "    teacup.train()\n",
    "    for batch in train_dataloader:\n",
    "        # get batch predictions\n",
    "        (X, mask), y = batch\n",
    "        \n",
    "        out = teacup(input_ids=X, attention_mask=mask, labels=y)\n",
    "        \n",
    "        \n",
    "        # backpropagate loss\n",
    "        out.loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # record train acc\n",
    "        if (i + 1) % report_per == 0:\n",
    "            print(\"y: \", y)\n",
    "            print(\"out.loss: \", out.loss)\n",
    "            print(\"out.logits: \", out.logits)\n",
    "            train_acc[i // report_per] += float(torch.sum(torch.argmax(out.logits, dim=1) == y))\n",
    "            \n",
    "        del out\n",
    "        \n",
    "    del X\n",
    "    del mask\n",
    "    del y\n",
    "    \n",
    "    # validate\n",
    "    if (i + 1) % report_per == 0:\n",
    "        teacup.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in dev_dataloader:\n",
    "                (X, mask), y = batch\n",
    "                out = teacup(input_ids=X, attention_mask=mask, labels=y)\n",
    "                dev_acc[i // report_per] += float(torch.sum(torch.argmax(out.logits, dim=1) == y))\n",
    "                \n",
    "            dev_acc[i // report_per] /= len(dev_data)\n",
    "            train_acc[i // report_per] /= len(train_data)\n",
    "            \n",
    "        epoch_time = datetime.now() - start_time\n",
    "        print(f'Epoch {i + 1} complete in {str(epoch_time)};',\n",
    "              f'est. finish at {str(start_time + (epoch_time / (i + 1) * epochs))}')\n",
    "        print(f'Validation: {train_acc[i // report_per]} train | {dev_acc[i // report_per]} dev')\n",
    "        # clear_output(wait=True)\n",
    "        \n",
    "end_time = datetime.now()\n",
    "print(f'Training completed in {str(end_time - start_time)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52 , 0.498, 0.502, 0.46 , 0.494, 0.516, 0.518, 0.504, 0.508,\n",
       "       0.5  , 0.502, 0.496, 0.518, 0.47 , 0.514, 0.498, 0.436, 0.464,\n",
       "       0.514, 0.522])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BVT plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax2 = ax.twinx()\n",
    "ax.plot(train_acc, label='train', color='blue')\n",
    "ax2.plot(dev_acc, label='dev', color='red')\n",
    "\n",
    "ax.legend()\n",
    "ax2.legend()\n",
    "ax.set_ylabel('Train acc')\n",
    "ax2.set_ylabel('Dev acc')\n",
    "ax.set_xlabel('Training epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External code for seq. classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search/hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, train_len, dev_dataloader, dev_len, epochs, report_per, lr, batch_size, decay):\n",
    "    \n",
    "    # initialize model\n",
    "    teacup = RobertaForMultipleChoice(RobertaConfig.from_pretrained('roberta-base', \n",
    "                                                                            num_labels=2))\n",
    "    teacup.to(device)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 3) Now we train our model. \n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # optimizer & LR decay scheduler\n",
    "    optimizer = AdamW(teacup.parameters(), lr=lr)\n",
    "    num_training_steps = epochs * len(train_dataloader)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        decay,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    dev_acc = np.zeros(epochs // report_per)\n",
    "    train_acc = np.zeros(epochs // report_per)\n",
    "\n",
    "    print('Beginning training loop')\n",
    "    for i in range(epochs):\n",
    "\n",
    "        # train loop\n",
    "        teacup.train()\n",
    "        for batch in train_dataloader:\n",
    "            # get batch predictions\n",
    "            (X, mask), y = batch\n",
    "            out = teacup(input_ids=X, attention_mask=mask, labels=y)\n",
    "\n",
    "            # backpropagate loss\n",
    "            out.loss.backward()\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # record train acc\n",
    "            if (i + 1) % report_per == 0:\n",
    "                train_acc[i // report_per] += float(torch.sum(torch.argmax(out.logits, dim=1) == y))\n",
    "\n",
    "            del out\n",
    "\n",
    "        del X\n",
    "        del mask\n",
    "        del y\n",
    "\n",
    "        # validate\n",
    "        if (i + 1) % report_per == 0:\n",
    "            teacup.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch in dev_dataloader:\n",
    "                    (X, mask), y = batch\n",
    "                    out = teacup(input_ids=X, attention_mask=mask, labels=y)\n",
    "                    dev_acc[i // report_per] += float(torch.sum(torch.argmax(out.logits, dim=1) == y))\n",
    "\n",
    "                dev_acc[i // report_per] /= dev_len\n",
    "                train_acc[i // report_per] /= train_len\n",
    "\n",
    "            epoch_time = datetime.now() - start_time\n",
    "            print(f'Epoch {i + 1} complete in {str(epoch_time)};',\n",
    "                  f'est. finish at {str(start_time + (epoch_time / (i + 1) * epochs))}')\n",
    "            print(f'Validation: {train_acc[i // report_per]} train | {dev_acc[i // report_per]} dev')\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print(f'Training completed in {str(end_time - start_time)}')\n",
    "    \n",
    "    return dev_acc, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(dev_accs, train_accs, epochs, report_per, lrs, batch_sizes, decays):\n",
    "    for batch_size in batch_sizes:\n",
    "        \n",
    "        # load data\n",
    "        train_data = CopaDataset('data/train.jsonl')\n",
    "        train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        print(f'Training data loaded (length {len(train_data)})')\n",
    "        dev_data = CopaDataset('data/dev.jsonl')\n",
    "        dev_dataloader = DataLoader(dev_data, batch_size=100, shuffle=True)\n",
    "        print(f'Dev data loaded (length {len(dev_data)})')\n",
    "        \n",
    "        for lr in lrs:\n",
    "                for decay in decays:\n",
    "                    print(f'Training lr={lr}, batch size={batch_size}, decay={decay}')\n",
    "                    dev_acc, train_acc = train(train_dataloader, len(train_data), \n",
    "                                               dev_dataloader, len(dev_data),\n",
    "                                               epochs, report_per, \n",
    "                                               lr, batch_size, decay)\n",
    "                    dev_accs[(lr, batch_size, decay)] = dev_acc\n",
    "                    train_accs[(lr, batch_size, decay)] = train_acc\n",
    "                    \n",
    "        train_data.clear()\n",
    "        dev_data.clear()\n",
    "        del train_data\n",
    "        del dev_data\n",
    "        del train_dataloader\n",
    "        del dev_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0:01:07.761930\n"
     ]
    }
   ],
   "source": [
    "# initialize grid search\n",
    "lrs = [5e-5, 3e-5]\n",
    "batch_sizes = [8, 16]\n",
    "decays = ['linear', 'polynomial']\n",
    "dev_accs = dict()\n",
    "train_accs = dict()\n",
    "grid_search(dev_accs, train_accs, 5, 1, lrs, batch_sizes, decays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(5e-05, 8, 'linear'): array([0.38, 0.38, 0.38, 0.38, 0.4 ]),\n",
       " (5e-05, 8, 'polynomial'): array([0.52, 0.48, 0.5 , 0.48, 0.48]),\n",
       " (3e-05, 8, 'linear'): array([0.44, 0.48, 0.48, 0.48, 0.46]),\n",
       " (3e-05, 8, 'polynomial'): array([0.4 , 0.44, 0.4 , 0.42, 0.4 ]),\n",
       " (5e-05, 16, 'linear'): array([0.36, 0.4 , 0.46, 0.44, 0.42]),\n",
       " (5e-05, 16, 'polynomial'): array([0.38, 0.32, 0.34, 0.38, 0.34]),\n",
       " (3e-05, 16, 'linear'): array([0.58, 0.5 , 0.46, 0.46, 0.46]),\n",
       " (3e-05, 16, 'polynomial'): array([0.5 , 0.48, 0.48, 0.44, 0.48])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, axes = plt.subplots(ncols=2, nrows=4, figsize=(16, 16))\n",
    "col_dict = {'linear': 0, 'polynomial': 1}\n",
    "row_dict = {(5e-5, 8): 0, (3e-5, 8): 1, (5e-5, 16): 2, (3e-5, 16): 3}\n",
    "\n",
    "for item in dev_accs:\n",
    "    idx1 = col_dict[item[2]]\n",
    "    idx2 = row_dict[(item[0], item[1])]\n",
    "    axes[idx2][idx1].plot(dev_accs[item], label='dev', color='tab:orange')\n",
    "    axes[idx2][idx1].plot(train_accs[item], label='train', color='tab:blue')\n",
    "    axes[idx2][idx1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
